<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>编程 on 一塘</title>
    <link>http://localhost:1313/categories/%E7%BC%96%E7%A8%8B/</link>
    <description>Recent content in 编程 on 一塘</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 19 Apr 2024 12:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/%E7%BC%96%E7%A8%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>人人都是开发者「转」</title>
      <link>http://localhost:1313/post/ai/%E4%BA%BA%E4%BA%BA%E9%83%BD%E6%98%AF%E5%BC%80%E5%8F%91%E8%80%85/</link>
      <pubDate>Fri, 19 Apr 2024 12:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/ai/%E4%BA%BA%E4%BA%BA%E9%83%BD%E6%98%AF%E5%BC%80%E5%8F%91%E8%80%85/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;“自然语言会成为下一代的编程语言，人人都能成为开发者。”&lt;/p&gt;&#xA;&lt;p&gt;4月16日，Create 2024百度AI开发者大会在深圳召开，百度创始人、董事长兼首席执行官李彦宏发表了《人人都是开发者》的主题演讲，描述了一个不再局限于编码技能的世界，而是以自然语言为媒介，人人都能参与创造的时代。&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h2 id=&#34;演讲稿&#34;&gt;演讲稿&lt;/h2&gt;&#xA;&lt;p&gt;大家好，欢迎参加Create 2024百度AI开发者大会，这是Create大会首次在粤港澳大湾区举办。今天现场来了5000多位开发者和科技爱好者。&lt;/p&gt;&#xA;&lt;p&gt;过去这一年，我跟很多创业者、开发者交流，感觉大家都处在一种“FOMO”状态，也就是Fear of Missing Out，既兴奋、又害怕错过。确实，大模型和生成式AI，将彻底改变开发者这个群体。&lt;/p&gt;&#xA;&lt;p&gt;过去，开发者用代码改变世界；未来，自然语言将成为新的通用编程语言，你只要会说话，就可以成为一名开发者，用自己的创造力改变世界。&lt;/p&gt;&#xA;&lt;p&gt;这一天并不遥远，我们看到，因为有了强大的基础大模型，有了很多低门槛，甚至零门槛的开发工具，开发者的生产力大大提高了。&lt;/p&gt;&#xA;&lt;p&gt;比如，基于文心大模型的智能代码助手Comate，不仅支持100多种语言和所有主流IDE平台，可以推荐代码、生成代码注释、查找代码缺陷、给出优化方案，还可以深度解读代码库、关联私域知识生成新的代码。上岗一年多，Comate已经走入了喜马拉雅、三菱电梯、软通动力等上万家企业，生成的代码采纳率达到了46%，百度每天新增的代码中，已经有27%是由Comate生成的。&lt;/p&gt;&#xA;&lt;p&gt;今天，你不会写代码，也可以做出一个AI应用；不用编程，也可以做出一个智能体。AI正在掀起一场创造力革命，未来开发应用就像拍个短视频一样简单，人人都是开发者，人人都是创造者。&lt;/p&gt;&#xA;&lt;p&gt;作为一家技术公司，百度的角色定位，就是尽可能地为大家提供所需的开发工具，不断提升整个社会的创造力。具体来说，我们提供1个强大的基础模型系列，就是文心大模型系列，这包括旗舰版的ERNIE3.5， ERNIE4.0， 也包括轻量版的ERNIE Speed、Lite、Tiny等等。&lt;/p&gt;&#xA;&lt;p&gt;我们还提供基于大模型来开发各种应用的工具，包括智能体开发工具AgentBuilder，AI原生应用开发工具AppBuilder，以及各种尺寸的模型定制工具ModelBuilder。这三个工具，都代表了先进生产力。下面，我会给大家一一展示。&lt;/p&gt;&#xA;&lt;h2 id=&#34;文心一言用户超2亿文心大模型40工具版发布&#34;&gt;文心一言用户超2亿，文心大模型4.0工具版发布&lt;/h2&gt;&#xA;&lt;p&gt;首先讲一下，文心一言和文心大模型的最新进展：&lt;/p&gt;&#xA;&lt;p&gt;文心一言从去年3月16日发布，到今天是一年零一个月的时间。我们的用户数突破了2亿，API日均调用量也突破了2亿，服务的客户数达到了8.5万，利用千帆平台开发的AI原生应用数超过了19万。&lt;/p&gt;&#xA;&lt;p&gt;我们看看，大家都在用文心一言做什么？&lt;/p&gt;&#xA;&lt;p&gt;视频中的真人真事只是冰山一角。我们可以看到，文心一言正在改变更多人的工作和生活。&lt;/p&gt;&#xA;&lt;p&gt;支撑文心一言的基座模型，就是文心大模型。过去一年，它经历了从3.0版本到3.5，再到4.0版本的进化。文心4.0在理解、生成、逻辑、记忆四大能力方面，均达到了业界领军水平。&lt;/p&gt;&#xA;&lt;p&gt;近几个月来，文心大模型在代码生成、代码解释、代码优化等通用能力方面实现了进一步的显著提升，达到国际领先水平。&lt;/p&gt;&#xA;&lt;p&gt;今天，我们正式发布文心大模型4.0的工具版，现在，大家可以在工具版上，体验代码解释器功能，通过自然语言交互，就能实现对复杂数据和文件的处理与分析，还可以生成图表或文件，能够快速洞察数据中的特点、分析变化趋势、为后续的决策提供高效精准的支撑。&lt;/p&gt;&#xA;&lt;p&gt;文心大模型已经成为了中国最领先、应用最广泛的AI基础模型。&lt;/p&gt;&#xA;&lt;p&gt;不仅如此，相比一年前，文心大模型的算法训练效率提升到了原来的5.1倍，周均训练有效率达到98.8%，推理性能提升了105倍，推理的成本降到了原来的1%。&lt;/p&gt;&#xA;&lt;p&gt;也就是说，客户原来一天调用1万次，同样成本现在可以调用100万次。媒体可能不会因为成本下降99%而兴奋。但是企业也好，开发者也好，一旦用起来，最关注的就是效果和成本。&lt;/p&gt;&#xA;&lt;p&gt;我们能在提升性能的同时，把推理成本降到1%，正是因为百度在芯片、框架、模型、应用这四层架构上有着全栈的布局，通过端到端优化，不断地把成本打下来，让更多人都可以高效、低价地用大模型来做AI应用。&lt;/p&gt;&#xA;&lt;p&gt;毫无疑问，大模型相关的话题，在2024年依然会很热，各类技术突破还会不断涌现。媒体也会继续热衷于用“震撼发布”“史诗级更新”这样的标题进行渲染。但我想强调的是，大模型本身并不直接创造价值，基于大模型开发出来的AI应用才能满足真实的市场需求。&lt;/p&gt;&#xA;&lt;h2 id=&#34;分享开发ai原生应用的具体思路和工具踩了无数的坑交了高昂学费&#34;&gt;分享开发AI原生应用的具体思路和工具：“踩了无数的坑，交了高昂学费”&lt;/h2&gt;&#xA;&lt;p&gt;今天我想跟大家分享的是一些基于大模型开发AI原生应用的具体思路和工具。这是我们百度根据过去一年的实践，踩了无数的坑，交了高昂的学费换来的。&lt;/p&gt;&#xA;&lt;p&gt;第一是MoE。未来大型的AI原生应用基本都是MoE架构，这里所说的MoE不是一般的学术概念，而是大小模型的混用，不依赖一个模型来解决所有问题。但什么时候调用小模型、什么时候调用大模型、什么时候不调用模型，这都是有技术含量的，要针对应用的不同场景做匹配。&lt;/p&gt;&#xA;&lt;p&gt;第二是小模型。小模型推理成本低，响应速度快，在一些特定场景中，经过SFT精调后的小模型，它的使用效果可以媲美大模型。这就是我们发布Speed，Lite、Tiny三个轻量模型的原因。我们通过大模型，压缩蒸馏出来一个基础模型，然后再用数据去训练，这比从头开始训小模型，效果要好很多，比基于开源模型训出来的模型效果更好，速度更快，成本更低。&lt;/p&gt;&#xA;&lt;p&gt;第三是智能体。智能体是当下很热的一个话题，随着智能体能力的提升，会不断催生出大量新的应用。智能体机制，包括理解、规划、反思和进化，它让机器像人一样思考和行动，可以自主完成复杂任务，在环境中持续学习、实现自我迭代和进化。在一些复杂系统中，我们还可以让不同的智能体互动，相互协作，更高质量地完成任务。这些智能体能力，我们已经开发出来了，并且向开发者全面开放。&lt;/p&gt;&#xA;&lt;p&gt;在MoE、小模型、智能体这三个方向上，百度都已经给大家做好了“开箱即用”的工具。下面，我就给大家介绍三种不同的工具，分别是：智能体开发工具AgentBuilder、AI原生应用开发工具AppBuilder、各种尺寸的模型定制工具ModelBuilder。&lt;/p&gt;&#xA;&lt;h2 id=&#34;智能体开发工具agentbuilder&#34;&gt;智能体开发工具AgentBuilder&lt;/h2&gt;&#xA;&lt;p&gt;首先是智能体开发工具AgentBuilder。智能体可能是未来离每个人最近、最主流的大模型使用方式，基于强大的基础模型，智能体可以批量生成，应用在各种各样的场景。&lt;/p&gt;&#xA;&lt;p&gt;百度刚刚升级了文心智能体平台。截至目前，已经有3万多个智能体被创建、5万多名开发者和上万家企业入驻。我们的目标是，让每个人、每个组织都成为智能体的开发者，打造国内最完整的智能体生态。&lt;/p&gt;&#xA;&lt;p&gt;那如何实现这个目标呢？就是给大家提供零门槛的智能体开发工具AgentBuilder。&lt;/p&gt;&#xA;&lt;p&gt;下面我们就先以“新加坡旅游局”为例一起看看，一个智能体是如何做出来的。&lt;/p&gt;&#xA;&lt;p&gt;首先，我们打开文心智能体平台，创建页面有着零代码、低代码两种模式，新手可以直接选择“零代码模式”，用自然语言，几句话就能创建一个智能体。&lt;/p&gt;&#xA;&lt;p&gt;我们先给智能体起名叫“新加坡旅游局”，然后在设定里写明需要打造旅游方案、解答问题，提供酒店门票预订服务，这些设定都是用来指导智能体的，告诉它都能做什么。&lt;/p&gt;&#xA;&lt;p&gt;如果只需要基础智能体，平台会自动完成填写。但我们希望“新加坡旅游局”是一个专业的智能体，所以要进行高级配置。我可以把新加坡百科词条和官网链接都添加到知识库里，让它每天更新。然后添加一些工具，如酒店查询、景点门票购买等，增强它的服务能力。目前我们已经跟携程合作，提供了酒店、景点、票务等旅游服务工具。这样，一个新加坡旅游局的智能体就做好了，可以进一步预览、调优。&lt;/p&gt;&#xA;&lt;p&gt;现在打开百度APP，搜索“什么时候去新加坡人最少”，因为大家出去旅游都想避开人潮。智能体会综合多个来源的信息，生成一个答案，“1-3月人最少”。我们还可以点击智能体，和它进一步互动，比如去新加坡旅游的注意事项，推荐新加坡排名前三的酒店，还能让它直接预订新加坡环球影城的门票，一站式解决需求，大大节省了用户时间。&lt;/p&gt;&#xA;&lt;p&gt;除了新加坡之外，大连、沈阳等文旅类智能体也都在文心智能体平台上线，还有知识类、创作类、学习类、娱乐类等各式各样的智能体，这些都是用AgentBuilder做出来的。&lt;/p&gt;&#xA;&lt;p&gt;去年文心一言刚发布的时候，我就说过，文心一言会影响到每一家公司。因为它强大的自然语言理解能力、表达能力、推理能力，可以使任何一个公司都离自己的客户更近。&lt;/p&gt;&#xA;&lt;p&gt;今天，每一个商家、每一个客户，都能在百度拥有专属的智能体。整个过程完全不需要编程，通过类似提示词的信息输入，和简单的几步操作调优，就能迅速生成一个智能体，成为7X24小时在线的金牌业务员。&lt;/p&gt;&#xA;&lt;p&gt;我们来看一下，一个商家智能体是怎么做出来的。&lt;/p&gt;&#xA;&lt;p&gt;启德教育是家知名教育企业，在全国有60多家分支机构，还有很多海外分公司，覆盖国家广，对接待的话术要求很高。如何能全天24小时回复客户的咨询，并且提高接待水平、降低经营成本呢？&lt;/p&gt;&#xA;&lt;p&gt;启德教育利用百度的AgentBuilder，打造了专属的智能体。&lt;/p&gt;&#xA;&lt;p&gt;我们来看看，如何打造一个具备基本能力的智能体。很简单，在平台上填写智能体的头像、名称、经营业务范围和欢迎语，再设置一些需要用户提供的信息，比如年龄、学历。5分钟、零门槛，一个智能体就做好了。&lt;/p&gt;&#xA;&lt;p&gt;启德教育还希望这个智能体是个懂业务、懂学生的留学顾问。它可以针对学生的不同情况，比如想去美国还是澳洲、是硕士还是学士、雅思和托福考了多少分等等，做出专业分析，给出精准回答。我们可以通过添加知识、角色、工具这几大模块，来打造一个更高级的智能体。&lt;/p&gt;&#xA;&lt;p&gt;在知识模块中，上传私域知识，让平台实时解析，自动生成对话语料；在角色模块，把一些不在经营范围内的留学国家，增加到过滤方案中，可以提高用户线索的有效率；在工具模块，加入预约到店等服务。通过这样几步简单操作，一个拥有专业能力的启德教育智能体就做好了。&lt;/p&gt;&#xA;&lt;p&gt;现在，我们来搜索“澳洲留学申请条件”，可以看到智能体快速给出了需要的语言能力、专业选择等七大必备条件，还给能出相应的留学咨询方案，对各种难题都有问必答、有求必应。&lt;/p&gt;&#xA;&lt;p&gt;启德教育智能体非常的受欢迎，上线第一周，就成功分发了155万次，与用户交互了5.8万次，线索转化量直线增长、有效线索的转化成本明显降低，经营效率大幅提升。&lt;/p&gt;&#xA;&lt;p&gt;下面，我再给大家介绍一个家居行业的智能体。&lt;/p&gt;&#xA;&lt;p&gt;索菲亚是专注全屋定制的家居品牌。就像刚刚展示的，它也可以通过填写极其简单的信息，创建出一个基础的商家智能体。但对于家居行业，消费者的线下体验更重要，所以索菲亚希望能在线上打造出一个金牌销售，还原线下的接待体验。&lt;/p&gt;&#xA;&lt;p&gt;因此在进一步的设置中，它在角色模块，选择了数字人作为展示方式，然后给数字人选取了合适的背景和声音，并且结合平台的智能解析能力，自动总结了一套销售话术。最终打造出一位温柔亲切、话术专业的金牌销售，她能24小时满足用户的各种需求，提供高水准的服务体验。&lt;/p&gt;&#xA;&lt;p&gt;当百度搜索用户有装修诉求时，索菲亚智能体会利用文心大模型的能力，优先给出问题的答案。除此之外，她还会主动与客户确认具体需求，如装修类型、预算等，并推荐附近的线下门店。&lt;/p&gt;&#xA;&lt;p&gt;索菲亚商家智能体上线以来，有效线索成本下降了30%。也就是说，它获得一个有效客户，如果过去的成本是100块，现在只需要70块了。&lt;/p&gt;&#xA;&lt;p&gt;目前，已有超过1万个百度的客户拥有了商家智能体，涵盖了教育培训、房产家居、机械设备、商务服务等超过30个行业。&lt;/p&gt;&#xA;&lt;p&gt;上面，通过三个Demo，我展示了开发者和商家，如何利用AgentBuilder，制作不同行业智能体的过程。&lt;/p&gt;&#xA;&lt;p&gt;现在，制作一个智能体，真的就是分分钟的事。但问题来了！如果没流量、没分发、找不到、没人用，那么开发者和商家就没有收益，没有收益就没有动力。怎么解决这个痛点呢？&lt;/p&gt;</description>
    </item>
    <item>
      <title>「转」window软件运行时间</title>
      <link>http://localhost:1313/post/soft_run_time/</link>
      <pubDate>Fri, 15 Apr 2022 12:39:04 +0000</pubDate>
      <guid>http://localhost:1313/post/soft_run_time/</guid>
      <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;&#xA;&lt;p&gt;对关注性能的程序开发人员而言，一个好的计时部件既是益友，也是良师。计时器既可以作为程序组件帮助程序员精确的控制程序进程，又是一件有力的调试武器，在有经验的程序员手里可以尽快的确定程序的性能瓶颈，或者对不同的算法作出有说服力的性能比较。&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;p&gt;在Windows平台下，常用的计时器有两种，一种是&lt;code&gt;timeGetTime&lt;/code&gt;多媒体计时器，它可以提供毫秒级的计时。但这个精度对很多应用场合而言还是太粗糙了。另一种是&lt;code&gt;QueryPerformanceCount&lt;/code&gt;计数器，随系统的不同可以提供微秒级的计数。对于实时图形处理、多媒体数据流处理、或者实时系统构造的程序员，善用&lt;code&gt;QueryPerformanceCount/QueryPerformanceFrequency&lt;/code&gt;是一项基本功。&lt;/p&gt;&#xA;&lt;p&gt;本文要介绍的，是另一种直接利用&lt;code&gt;Pentium CPU&lt;/code&gt;内部时间戳进行计时的高精度计时手段。以下讨论主要得益于&lt;code&gt;《Windows图形编程》&lt;/code&gt;一书，第15页－17页，有兴趣的读者可以直接参考该书。关于RDTSC指令的详细讨论，可以参考Intel产品手册。本文仅仅作抛砖之用。&lt;/p&gt;&#xA;&lt;p&gt;在 &lt;code&gt;Intel Pentium&lt;/code&gt;以上级别的CPU中，有一个称为“时间戳（Time   Stamp）”的部件，它以64位无符号整型数的格式，记录了自CPU上电以来所经过的时钟周期数。由于目前的CPU主频都非常高，因此这个部件可以达到纳秒级的计时精度。这个精确性是上述两种方法所无法比拟的。&lt;/p&gt;&#xA;&lt;p&gt;在Pentium以上的CPU中，提供了一条机器指令RDTSC（Read Time   Stamp Counter）来读取这个时间戳的数字，并将其保存在EDX:EAX寄存器对中。由于&lt;code&gt;EDX:EAX&lt;/code&gt;寄存器对恰好是Win32平台下C++语言保存函数返回值的寄存器，所以我们可以把这条指令看成是一个普通的函数调用。像这样：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  inline   unsigned   __int64   GetCycleCount()   &#xA;  {   &#xA;    __asm   RDTSC   &#xA;  }   &#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但是不行，因为RDTSC不被C++的内嵌汇编器直接支持，所以我们要用_emit伪指令直接嵌入该指令的机器码形式&lt;code&gt;0X0F&lt;/code&gt;、&lt;code&gt;0X31&lt;/code&gt;，如下：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  inline   unsigned   __int64   GetCycleCount()   &#xA;  {   &#xA;    __asm   _emit   0x0F   &#xA;    __asm   _emit   0x31   &#xA;  }   &#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以后在需要计数器的场合，可以像使用普通的Win32   API一样，调用两次GetCycleCount函数，比较两个返回值的差，像这样：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  unsigned   long   t;   &#xA;  t   =   (unsigned   long)GetCycleCount();   &#xA;  //Do   Something   time-intensive   ...   &#xA;  t   -=   (unsigned   long)GetCycleCount();   &#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;《Windows图形编程》&lt;/code&gt;第15页编写了一个类，把这个计数器封装起来。有兴趣的读者可以去参考那个类的代码。作者为了更精确的定时，做了一点小小的改进，把执行&lt;code&gt;RDTSC&lt;/code&gt;指令的时间，通过连续两次调用&lt;code&gt;GetCycleCount&lt;/code&gt;函数计算出来并保存了起来，以后每次计时结束后，都从实际得到的计数中减掉这一小段时间，以得到更准确的计时数字。但我个人觉得这一点点改进意义不大。在我的机器上实测，这条指令大概花掉了几十到100多个周期，在&lt;code&gt;Celeron 800MHz&lt;/code&gt;的机器上，这不过是十分之一微秒的时间。对大多数应用来说，这点时间完全可以忽略不计；而对那些确实要精确到纳秒数量级的应用来说，这个补偿也过于粗糙了。&lt;/p&gt;&#xA;&lt;p&gt;这个方法的优点是：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;高精度。可以直接达到纳秒级的计时精度（在1GHz的CPU上每个时钟周期就是一纳秒），这是其他计时方法所难以企及的。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;成本低。&lt;code&gt;timeGetTime&lt;/code&gt;函数需要链接多媒体库 &lt;code&gt;winmm.lib&lt;/code&gt;，&lt;code&gt;QueryPerformance*&lt;/code&gt;函数根据MSDN的说明，需要硬件的支持（虽然我还没有见过不支持的机器）和KERNEL库的支持，所以二者都只能在Windows平台下使用（关于DOS平台下的高精度计时问题，可以参考&lt;code&gt;《图形程序开发人员指南》&lt;/code&gt;，里面有关于控制定时器8253的详细说明）。但&lt;code&gt;RDTSC&lt;/code&gt;指令是一条CPU指令，凡是i386平台下Pentium以上的机器均支持，甚至没有平台的限制（我相信i386版本UNIX和Linux下这个方法同样适用，但没有条件试验），而且函数调用的开销是最小的。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;具有和CPU主频直接对应的速率关系。一个计数相当于1/(CPU主频Hz数)秒，这样只要知道了CPU的主频，可以直接计算出时间。这和   &lt;code&gt;QueryPerformanceCount&lt;/code&gt;不同，后者需要通过&lt;code&gt;QueryPerformanceFrequency&lt;/code&gt;获取当前计数器每秒的计数次数才能换算成时间。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这个方法的缺点是：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;现有的C/C++编译器多数不直接支持使用RDTSC指令，需要用直接嵌入机器码的方式编程，比较麻烦。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;数据抖动比较厉害。其实对任何计量手段而言，精度和稳定性永远是一对矛盾。如果用低精度的&lt;code&gt;timeGetTime&lt;/code&gt;来计时，基本上每次计时的结果都是相同的；而&lt;code&gt;RDTSC&lt;/code&gt;指令每次结果都不一样，经常有几百甚至上千的差距。这是这种方法高精度本身固有的矛盾。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;关于这个方法计时的最大长度，我们可以简单的用下列公式计算：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;自CPU上电以来的秒数   =   RDTSC读出的周期数   /   CPU主频速率（Hz）   &#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;64位无符号整数所能表达的最大数字是&lt;code&gt;1.8×10^19&lt;/code&gt;，在我的&lt;code&gt;Celeron   800&lt;/code&gt;上可以计时大约700年（书中说可以在200MHz的Pentium上计时117年，这个数字不知道是怎么得出来的，与我的计算有出入）。无论如何，我们大可不必关心溢出的问题。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
