<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>「转」「译」Face Detection – OpenCV, Dlib and Deep Learning ( C++ / Python ) | 一塘</title>
<link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css><link rel=stylesheet href=/css/dark.css></head><body><nav><ul class=menu><li><a href=/about/>一塘</a></li><li><a href=/post/>博客</a></li><li><a href=/categories/>分类</a></li><li><a href=/tags/>标签</a></li><li style=float:right;position:relative;margin-left:1em><input type=text id=search-box placeholder=搜索文章... style="padding:.3em .6em;border-radius:4px;border:1px solid #ccc;width:150px;min-width:100px;max-width:250px"><ul id=search-results style="position:absolute;top:100%;right:0;background:#fff;border:1px solid #ccc;max-height:300px;overflow-y:auto;display:none;z-index:1000;list-style:none;padding:0;margin:0;width:250px"></ul></li><style>.search-item{padding:.4em .6em}.search-link{display:block;font-weight:500;text-decoration:none;color:#007acc}.search-snippet{font-size:.85em;color:#555;margin-top:.2em;line-height:1.4}.search-highlight{background:rgba(255,235,59,.5);padding:0 .15em;border-radius:3px}.search-item:hover{background-color:rgba(0,0,0,5%)}@media(prefers-color-scheme:dark){.search-link{color:#4fc3f7}.search-snippet{color:#aaa}.search-item:hover{background-color:rgba(104,99,99,.273)}.search-highlight{background:rgba(255,193,7,.35)}}</style><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.6.2/fuse.min.js></script><script>fetch("/post/index.json").then(e=>e.json()).then(e=>{const o=new Fuse(e,{keys:[{name:"title",weight:2},{name:"summary",weight:1},{name:"content",weight:.7}],threshold:.3,ignoreLocation:!0,minMatchCharLength:2}),n=document.getElementById("search-box"),t=document.getElementById("search-results");function s(e,t){if(!e)return"";const n=t.replace(/[.*+?^${}()|[\]\\]/g,"\\$&"),s=new RegExp(`(${n})`,"gi");return e.replace(s,'<mark class="search-highlight">$1</mark>')}function i(e,t,n=80){const s=e.toLowerCase().indexOf(t.toLowerCase());if(s===-1)return e.slice(0,n)+"…";const o=Math.max(0,s-n/2),i=Math.min(e.length,s+n/2);return"…"+e.slice(o,i)+"…"}n.addEventListener("input",function(){const e=this.value.trim();if(!e){t.style.display="none",t.innerHTML="";return}const n=o.search(e);t.innerHTML=n.slice(0,8).map(t=>{const n=t.item,o=i(n.content||n.summary||"",e);return`
          <li class="search-item">
            <a href="${n.permalink}" class="search-link">
              ${s(n.title,e)}
            </a>
            <div class="search-snippet">
              ${s(o,e)}
            </div>
          </li>
        `}).join(""),t.style.display=n.length?"block":"none"}),document.addEventListener("click",e=>{!n.contains(e.target)&&!t.contains(e.target)&&(t.style.display="none")})})</script></ul><hr></nav><div class=article-meta><h1><span class=title>「转」「译」Face Detection – OpenCV, Dlib and Deep Learning ( C++ / Python )</span></h1></div><div class=post-stats style=text-align:right>2018/11/12</div><main><p><strong>前言</strong>
本文为翻译文章。原文地址 <a href=https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/>https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/</a></p><p>在这篇文章中，作者讨论使用了OpenCV或Dlib的多种人脸检测的代码，并给出性能分析。作者使用的 Face Detector 包括以下四个，后面分别给出 c++ 和 python 实现。</p><ol><li>OpenCV 的 Haar Cascade Face Detector</li><li>OpenCV 的 Deep Learning based Face Detector</li><li>Dlib 的 HoG Face Detector</li><li>Dlib 的 Deep Learning based Face Detector</li></ol><p>作者限于篇幅没有对对理论进行深入解读，只讨论框架的使用，同时分享一些应用上的选择权衡的经验。</p><p>结论：在多数场景中，我们提前不知道图片大小，因此 选用 OpenCV – DNN 相当快也很精确，甚至对于小人脸也不错，各种人脸角度也可以。选用这个在大多情况下是最优的。</p><p><a href=https://github.com/spmallick/learnopencv/tree/master/FaceDetectionComparison>code FaceDetectionComparison</a> 说明：为了使文章显得简洁一些，在文中只提供关键的代码片段。在github项目中详细代码，包括每个方法独立的代码和整合在一起的cpp和py文件（run-all.py 和 run-all.cpp），同时里面也有运行代码所使用的人脸检测模型。</p><center><iframe width=100% height=360 frameborder=0 src="http://v.qq.com/iframe/player.html?vid=k07615vrzj8&tiny=0&auto=0" allowfullscreen></iframe></center>> 实验的图片尺寸是 image size 300×300<h2 id=1-opencv-haar>1. OpenCV-Haar</h2><p>在2001年，Viola 和 Jones提出Haar Cascade 特征为基础的 Face Detector，在以后的多年内都是最优的人脸检测算法。以他们的算法为基础人们做了很多改进。OpenCV提供了很多Haar特征的模型算法，更多的Haar特征模型 <strong><a href=https://github.com/opencv/opencv/tree/master/data/haarcascades>here</a></strong></p><h3 id=代码>代码</h3><h4 id=python>Python</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>faceCascade <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>CascadeClassifier(<span style=color:#e6db74>&#39;./haarcascade_frontalface_default.xml&#39;</span>)
</span></span><span style=display:flex><span>faces <span style=color:#f92672>=</span> faceCascade<span style=color:#f92672>.</span>detectMultiScale(frameGray)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> face <span style=color:#f92672>in</span> faces:
</span></span><span style=display:flex><span>    x1, y1, w, h <span style=color:#f92672>=</span> face
</span></span><span style=display:flex><span>    x2 <span style=color:#f92672>=</span> x1 <span style=color:#f92672>+</span> w
</span></span><span style=display:flex><span>    y2 <span style=color:#f92672>=</span> y1 <span style=color:#f92672>+</span> h
</span></span></code></pre></div><h4 id=c>C++</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span>faceCascadePath <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;./haarcascade_frontalface_default.xml&#34;</span>;
</span></span><span style=display:flex><span>faceCascade.load( faceCascadePath )
</span></span><span style=display:flex><span>std<span style=color:#f92672>::</span>vector<span style=color:#f92672>&lt;</span>Rect<span style=color:#f92672>&gt;</span> faces;
</span></span><span style=display:flex><span>faceCascade.detectMultiScale(frameGray, faces);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> ( size_t i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> faces.size(); i<span style=color:#f92672>++</span> )
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>int</span> x1 <span style=color:#f92672>=</span> faces[i].x;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>int</span> y1 <span style=color:#f92672>=</span> faces[i].y;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>int</span> x2 <span style=color:#f92672>=</span> faces[i].x <span style=color:#f92672>+</span> faces[i].width;
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>int</span> y2 <span style=color:#f92672>=</span> faces[i].y <span style=color:#f92672>+</span> faces[i].height;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>对图片灰度变化（grayscale）后，再应用 haar cascade 特征，输出是脸的list。list中每个item有四个element 分别为 top-left corner的(x, y) 、检测出来脸的大小(width, height) 。</p><h3 id=优点>优点</h3><ol><li>在CPU上几乎是实时的（real-time）</li><li>简单的框架 （Simple Architecture）</li><li>能检测不同大小的脸 （different scales）</li></ol><h3 id=缺点>缺点</h3><ol><li>主要缺点是有很多错误的预测（False predictions），会多预测出人脸。</li><li>人脸非正面效果不好 （non-frontal）</li><li>人脸遮挡效果不好 （under occlusion）</li></ol><h2 id=2-opencv-dnn>2. OpenCV-DNN</h2><p>在 OpenCV 3.3 中引入这个方法。DNN模型使用SSD **<a href=https://arxiv.org/abs/1512.02325>Single-Shot-Multibox detector</a>**框架和 ResNet-10 特征提取网络（backbone）。这个模型喂的数据是从网上采集的，但是训练的源代码没有公开。OpenCV提供了2个模型文件。</p><ol><li>Float 16 位版本模型，使用原始的 caffe 训练 (5.4 MB)</li><li>8 bit quantized 版本模型，使用 Tensorflow 训练 (2.7 MB)</li></ol><p>代码 <a href=https://github.com/spmallick/learnopencv/tree/master/FaceDetectionComparison>FaceDetectionComparison</a> 里面放了这两个模型文件。</p><h3 id=代码-1>代码</h3><h4 id=python-1>Python</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>DNN <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;TF&#34;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> DNN <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;CAFFE&#34;</span>:
</span></span><span style=display:flex><span>    modelFile <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;res10_300x300_ssd_iter_140000_fp16.caffemodel&#34;</span>
</span></span><span style=display:flex><span>    configFile <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;deploy.prototxt&#34;</span>
</span></span><span style=display:flex><span>    net <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>dnn<span style=color:#f92672>.</span>readNetFromCaffe(configFile, modelFile)
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>    modelFile <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;opencv_face_detector_uint8.pb&#34;</span>
</span></span><span style=display:flex><span>    configFile <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;opencv_face_detector.pbtxt&#34;</span>
</span></span><span style=display:flex><span>    net <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>dnn<span style=color:#f92672>.</span>readNetFromTensorflow(modelFile, configFile)
</span></span></code></pre></div><h4 id=c-1>C++</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#66d9ef>const</span> std<span style=color:#f92672>::</span>string caffeConfigFile <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;./deploy.prototxt&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> std<span style=color:#f92672>::</span>string caffeWeightFile <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;./res10_300x300_ssd_iter_140000_fp16.caffemodel&#34;</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> std<span style=color:#f92672>::</span>string tensorflowConfigFile <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;./opencv_face_detector.pbtxt&#34;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> std<span style=color:#f92672>::</span>string tensorflowWeightFile <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;./opencv_face_detector_uint8.pb&#34;</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ifdef CAFFE
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>  Net net <span style=color:#f92672>=</span> cv<span style=color:#f92672>::</span>dnn<span style=color:#f92672>::</span>readNetFromCaffe(caffeConfigFile, caffeWeightFile);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># else
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>  Net net <span style=color:#f92672>=</span> cv<span style=color:#f92672>::</span>dnn<span style=color:#f92672>::</span>readNetFromTensorflow(tensorflowWeightFile, tensorflowConfigFile);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># endif
</span></span></span></code></pre></div><p>caffe 和 Tensorflow 框架加载模型的代码。使用 Float 16 的 Caffe 模型，需要 caffemodel 和 prototxt 文件。使用 8 bit quantized 的 Tensorflow 模型，需要 Tensorflow 配置文件和模型。</p><h4 id=python-2>Python</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>blob <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>dnn<span style=color:#f92672>.</span>blobFromImage(frameOpencvDnn, <span style=color:#ae81ff>1.0</span>, (<span style=color:#ae81ff>300</span>, <span style=color:#ae81ff>300</span>), [<span style=color:#ae81ff>104</span>, <span style=color:#ae81ff>117</span>, <span style=color:#ae81ff>123</span>], <span style=color:#66d9ef>False</span>, <span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>net<span style=color:#f92672>.</span>setInput(blob)
</span></span><span style=display:flex><span>detections <span style=color:#f92672>=</span> net<span style=color:#f92672>.</span>forward()
</span></span><span style=display:flex><span>bboxes <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(detections<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>2</span>]):
</span></span><span style=display:flex><span>    confidence <span style=color:#f92672>=</span> detections[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, i, <span style=color:#ae81ff>2</span>]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> confidence <span style=color:#f92672>&gt;</span> conf_threshold:
</span></span><span style=display:flex><span>        x1 <span style=color:#f92672>=</span> int(detections[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, i, <span style=color:#ae81ff>3</span>] <span style=color:#f92672>*</span> frameWidth)
</span></span><span style=display:flex><span>        y1 <span style=color:#f92672>=</span> int(detections[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, i, <span style=color:#ae81ff>4</span>] <span style=color:#f92672>*</span> frameHeight)
</span></span><span style=display:flex><span>        x2 <span style=color:#f92672>=</span> int(detections[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, i, <span style=color:#ae81ff>5</span>] <span style=color:#f92672>*</span> frameWidth)
</span></span><span style=display:flex><span>        y2 <span style=color:#f92672>=</span> int(detections[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, i, <span style=color:#ae81ff>6</span>] <span style=color:#f92672>*</span> frameHeight)
</span></span></code></pre></div><h4 id=c-2>C++</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#75715e>#ifdef CAFFE
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>cv<span style=color:#f92672>::</span>Mat inputBlob <span style=color:#f92672>=</span> cv<span style=color:#f92672>::</span>dnn<span style=color:#f92672>::</span>blobFromImage(frameOpenCVDNN, inScaleFactor, cv<span style=color:#f92672>::</span>Size(inWidth, inHeight), meanVal, false, false);
</span></span><span style=display:flex><span><span style=color:#75715e>#else
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>cv<span style=color:#f92672>::</span>Mat inputBlob <span style=color:#f92672>=</span> cv<span style=color:#f92672>::</span>dnn<span style=color:#f92672>::</span>blobFromImage(frameOpenCVDNN, inScaleFactor, cv<span style=color:#f92672>::</span>Size(inWidth, inHeight), meanVal, true, false);
</span></span><span style=display:flex><span><span style=color:#75715e>#endif
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>net.setInput(inputBlob, <span style=color:#e6db74>&#34;data&#34;</span>);
</span></span><span style=display:flex><span>cv<span style=color:#f92672>::</span>Mat detection <span style=color:#f92672>=</span> net.forward(<span style=color:#e6db74>&#34;detection_out&#34;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cv<span style=color:#f92672>::</span>Mat detectionMat(detection.size[<span style=color:#ae81ff>2</span>], detection.size[<span style=color:#ae81ff>3</span>], CV_32F, detection.ptr<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span>());
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> detectionMat.rows; i<span style=color:#f92672>++</span>)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>     <span style=color:#66d9ef>float</span> confidence <span style=color:#f92672>=</span> detectionMat.at<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span>(i, <span style=color:#ae81ff>2</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> (confidence <span style=color:#f92672>&gt;</span> confidenceThreshold)
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>         <span style=color:#66d9ef>int</span> x1 <span style=color:#f92672>=</span> <span style=color:#66d9ef>static_cast</span><span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span>(detectionMat.at<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span>(i, <span style=color:#ae81ff>3</span>) <span style=color:#f92672>*</span> frameWidth);
</span></span><span style=display:flex><span>         <span style=color:#66d9ef>int</span> y1 <span style=color:#f92672>=</span> <span style=color:#66d9ef>static_cast</span><span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span>(detectionMat.at<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span>(i, <span style=color:#ae81ff>4</span>) <span style=color:#f92672>*</span> frameHeight);
</span></span><span style=display:flex><span>         <span style=color:#66d9ef>int</span> x2 <span style=color:#f92672>=</span> <span style=color:#66d9ef>static_cast</span><span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span>(detectionMat.at<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span>(i, <span style=color:#ae81ff>5</span>) <span style=color:#f92672>*</span> frameWidth);
</span></span><span style=display:flex><span>         <span style=color:#66d9ef>int</span> y2 <span style=color:#f92672>=</span> <span style=color:#66d9ef>static_cast</span><span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span>(detectionMat.at<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span>(i, <span style=color:#ae81ff>6</span>) <span style=color:#f92672>*</span> frameHeight);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        cv<span style=color:#f92672>::</span>rectangle(frameOpenCVDNN, cv<span style=color:#f92672>::</span>Point(x1, y1), cv<span style=color:#f92672>::</span>Point(x2, y2), cv<span style=color:#f92672>::</span>Scalar(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>255</span>, <span style=color:#ae81ff>0</span>), <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>在上面的代码里面，图像转为blob输入进network里，利用前向传播函数forward()，得到一个4-D matrix。 这里不是很理解，代码跑起来看一下？？？</p><ul><li>The 3rd dimension iterates over the detected faces. (i is the iterator over the number of faces)</li><li>The fourth dimension contains information about the bounding box and score for each face. For example, detections[0,0,0,2] gives the confidence score for the first face, and detections[0,0,0,3:6] give the bounding box.</li></ul><p>The output coordinates of the bounding box are normalized between [0,1]. Thus the coordinates should be multiplied by the height and width of the original image to get the correct bounding box on the image.</p><h3 id=优点merits>优点（merits）</h3><ol><li>在本文四个方法中最精确（Most accurate）</li><li>可以在CPU上实时运行（real-time）</li><li>人脸不同方向效果不错（上下左右，侧脸等）up, down, left, right, side-face etc</li><li>人脸不同大小效果不错哦（various scales, big and tiny OK）</li></ol><p>OpenCV的这个DNN方法克服了 Haar cascade 方法的不足，同时精度也不比它差。暂时没有发现这个方法其他有不足地方，除了比后面的 Dlib HoG 方法速度慢一点以外。</p><p>作者建议，在使用OpenCV时，比Haar方法，可以优先考虑DNN方法。</p><h2 id=3-dlib-hog>3. Dlib-HoG</h2><p>HoG 人脸检测方法被广泛的使用，基于 HoG 特征和 SVM 分类。作者还写了一篇 HoG 的博客 <a href=https://www.learnopencv.com/histogram-of-oriented-gradients/>post</a>。模型有5个 HOG filters 滤波器（ front looking, left looking, right looking, front looking but rotated left, and a front looking but rotated right），模型直接放在了头文件里面 <strong><a href=https://github.com/davisking/dlib/blob/master/dlib/image_processing/frontal_face_detector.h>header file</a></strong>。</p><p>训练模型的数据库，来自LFW dataset，由 Davis King (Dlib的作者) 手工标记 （manually annotated）共2825张。需要的话，数据库从这里可以下载 <strong><a href=http://dlib.net/files/data/dlib_face_detector_training_data.tar.gz>dlib_face_detector_training_data.tar.gz</a></strong>.</p><h3 id=代码-2>代码</h3><h4 id=python-3>Python</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>hogFaceDetector <span style=color:#f92672>=</span> dlib<span style=color:#f92672>.</span>get_frontal_face_detector()
</span></span><span style=display:flex><span>faceRects <span style=color:#f92672>=</span> hogFaceDetector(frameDlibHogSmall, <span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> faceRect <span style=color:#f92672>in</span> faceRects:
</span></span><span style=display:flex><span>    x1 <span style=color:#f92672>=</span> faceRect<span style=color:#f92672>.</span>left()
</span></span><span style=display:flex><span>    y1 <span style=color:#f92672>=</span> faceRect<span style=color:#f92672>.</span>top()
</span></span><span style=display:flex><span>    x2 <span style=color:#f92672>=</span> faceRect<span style=color:#f92672>.</span>right()
</span></span><span style=display:flex><span>    y2 <span style=color:#f92672>=</span> faceRect<span style=color:#f92672>.</span>bottom()
</span></span></code></pre></div><h4 id=c-3>C++</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span>frontal_face_detector hogFaceDetector <span style=color:#f92672>=</span> get_frontal_face_detector();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Convert OpenCV image format to Dlib&#39;s image format
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>cv_image<span style=color:#f92672>&lt;</span>bgr_pixel<span style=color:#f92672>&gt;</span> dlibIm(frameDlibHogSmall);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Detect faces in the image
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>std<span style=color:#f92672>::</span>vector<span style=color:#f92672>&lt;</span>dlib<span style=color:#f92672>::</span>rectangle<span style=color:#f92672>&gt;</span> faceRects <span style=color:#f92672>=</span> hogFaceDetector(dlibIm);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> ( size_t i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> faceRects.size(); i<span style=color:#f92672>++</span> )
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>int</span> x1 <span style=color:#f92672>=</span> faceRects[i].left();
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>int</span> y1 <span style=color:#f92672>=</span> faceRects[i].top();
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>int</span> x2 <span style=color:#f92672>=</span> faceRects[i].right();
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>int</span> y2 <span style=color:#f92672>=</span> faceRects[i].bottom();
</span></span><span style=display:flex><span>  cv<span style=color:#f92672>::</span>rectangle(frameDlibHog, Point(x1, y1), Point(x2, y2), Scalar(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>255</span>,<span style=color:#ae81ff>0</span>), (<span style=color:#66d9ef>int</span>)(frameHeight<span style=color:#f92672>/</span><span style=color:#ae81ff>150.0</span>), <span style=color:#ae81ff>4</span>);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>在上面的代码中，首先加载 face detector，然后将图像输入给 detector 。其中第二个参数代表，想要上采样图片的倍数（times of upscale）。你给的数字越大，小脸检测出的概率越大。但是upscaling 会在计算上花费可观的时间（ substantial impact on the computation speed）。输出是脸的list， 框框对角的坐标（diagonal corners）。</p><h3 id=优点-1>优点</h3><ol><li>在cpu上最快的方法（在四个方法中）</li><li>对正面和轻微非正面的方法效果很不错</li><li>模型比较少对于其他三个的文件来说</li><li>轻微遮挡下可以检测</li></ol><p>大概以上，这个方法多数情况可以工作，除了下面的情况。</p><h3 id=缺点-1>缺点</h3><ol><li>主要缺点对小人脸不识别。由于训练在最小 80×80 的数据集上，要确保你的使用环境，不然的话你要自己再训练一下小人脸。</li><li>人脸框经常去掉了人额头一部分，有时脸颊一部分。
（part of forehead and even part of chin sometimes）</li><li>在明显的遮挡情况下效果不好</li><li>在测量和极端不正面的脸情况不工作，像向上看，和向下看的情况。</li></ol><h2 id=4-dlib-cnn>4. Dlib-CNN</h2><p>这个模型使用了**<a href=https://arxiv.org/pdf/1502.00046.pdf>Maximum-Margin Object Detector (MMOD)</a>** 加CNN的特征的方法。训练过程相当简单，也不需要大量的数据去训练一个新的 object detector。更多的训练套路，在这个网站上 <strong><a href=http://blog.dlib.net/2016/10/easily-create-high-quality-object.html>website</a></strong>.</p><p>使用的模型可以从 <strong><a href=https://github.com/davisking/dlib-models>dlib-models repository</a></strong> 下载。</p><p>训练使用的数据库是dlib的作者 Davis King 手工标的，7220张从 ImageNet, PASCAL VOC, VGG, WIDER, Face Scrub等数据库里面挑的。这个数据库可以下载到。<a href=http://dlib.net/files/data/dlib_face_detection_dataset-2016-09-30.tar.gz><strong>dlib_face_detection_dataset-2016-09-30.tar.gz</strong></a></p><h3 id=代码-3>代码</h3><h4 id=python-4>Python</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>dnnFaceDetector <span style=color:#f92672>=</span> dlib<span style=color:#f92672>.</span>cnn_face_detection_model_v1(<span style=color:#e6db74>&#34;./mmod_human_face_detector.dat&#34;</span>)
</span></span><span style=display:flex><span>faceRects <span style=color:#f92672>=</span> dnnFaceDetector(frameDlibHogSmall, <span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> faceRect <span style=color:#f92672>in</span> faceRects:
</span></span><span style=display:flex><span>    x1 <span style=color:#f92672>=</span> faceRect<span style=color:#f92672>.</span>rect<span style=color:#f92672>.</span>left()
</span></span><span style=display:flex><span>    y1 <span style=color:#f92672>=</span> faceRect<span style=color:#f92672>.</span>rect<span style=color:#f92672>.</span>top()
</span></span><span style=display:flex><span>    x2 <span style=color:#f92672>=</span> faceRect<span style=color:#f92672>.</span>rect<span style=color:#f92672>.</span>right()
</span></span><span style=display:flex><span>    y2 <span style=color:#f92672>=</span> faceRect<span style=color:#f92672>.</span>rect<span style=color:#f92672>.</span>bottom()
</span></span><span style=display:flex><span>    
</span></span></code></pre></div><h4 id=c-4>C++</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span>String mmodModelPath <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;./mmod_human_face_detector.dat&#34;</span>;
</span></span><span style=display:flex><span>net_type mmodFaceDetector;
</span></span><span style=display:flex><span>deserialize(mmodModelPath) <span style=color:#f92672>&gt;&gt;</span> mmodFaceDetector;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Convert OpenCV image format to Dlib&#39;s image format
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>cv_image<span style=color:#f92672>&lt;</span>bgr_pixel<span style=color:#f92672>&gt;</span> dlibIm(frameDlibMmodSmall);
</span></span><span style=display:flex><span>matrix<span style=color:#f92672>&lt;</span>rgb_pixel<span style=color:#f92672>&gt;</span> dlibMatrix;
</span></span><span style=display:flex><span>assign_image(dlibMatrix, dlibIm);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Detect faces in the image
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>std<span style=color:#f92672>::</span>vector<span style=color:#f92672>&lt;</span>dlib<span style=color:#f92672>::</span>mmod_rect<span style=color:#f92672>&gt;</span> faceRects <span style=color:#f92672>=</span> mmodFaceDetector(dlibMatrix);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> ( size_t i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> faceRects.size(); i<span style=color:#f92672>++</span> )
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>int</span> x1 <span style=color:#f92672>=</span> faceRects[i].rect.left();
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>int</span> y1 <span style=color:#f92672>=</span> faceRects[i].rect.top();
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>int</span> x2 <span style=color:#f92672>=</span> faceRects[i].rect.right();
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>int</span> y2 <span style=color:#f92672>=</span> faceRects[i].rect.bottom();
</span></span><span style=display:flex><span>  cv<span style=color:#f92672>::</span>rectangle(frameDlibMmod, Point(x1, y1), Point(x2, y2), Scalar(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>255</span>,<span style=color:#ae81ff>0</span>), (<span style=color:#66d9ef>int</span>)(frameHeight<span style=color:#f92672>/</span><span style=color:#ae81ff>150.0</span>), <span style=color:#ae81ff>4</span>);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>代码和 HoG detector 差不多，除了下载的 CNN face detection 的模型文件。</p><h3 id=优点-2>优点</h3><ol><li>不同的脸朝向效果不错 （face orientations）</li><li>遮挡比较稳定 （occlusion）</li><li>在GPU上很快</li><li>训练模型过程很简单</li></ol><h3 id=缺点-2>缺点</h3><ol><li>CPU上很慢</li><li>脸大小于 80×80 检测不出，因为模型在小脸训练的。所以要考虑你应用的具体场景脸的大小，当然也可以对小脸数据库再训练一下。</li><li>人脸框 bounding box 甚至比 HoG detector 还小。</li></ol><h2 id=5-精度比较>5. 精度比较</h2><p>（Accuracy Comparison）</p><p>作者评估这四个模型使用的是 FDDB 数据库，其中评估OpenCV-DNN 脚本为 <a href=https://github.com/opencv/opencv/blob/master/modules/dnn/misc/face_detector_accuracy.py>OpenCV face_detector_accuracy.py</a>.</p><p>作者发现奇怪的结果。Dlib 的结果比 Haar OpenCV还要低，然而实际从图片上效果比较好。下图是这四个方法的精度得分（ Precision scores）。</p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/face-detection-coco-comparison.jpg alt style=width:80%></div></p><p>指标说明（Metric）：
AP_50 = Precision when overlap between Ground Truth and predicted bounding box is at least 50% (IoU = 50%)
AP_75 = Precision when overlap between Ground Truth and predicted bounding box is at least 75% (IoU = 75%)
AP_Small = Average Precision for small size faces (Average of IoU = 50% to 95%)
AP_medium = Average Precision for medium size faces (Average of IoU = 50% to 95%)
AP_Large = Average Precision for large size faces (Average of IoU = 50% to 95%)
mAP = Average precision across different IoU (Average of IoU = 50% to 95%)</p><p><strong>作者最近的发现评估过程对 Dlib 不够公平，科学。</strong></p><h3 id=51-评估过程出错了分析的二个原因>5.1. 评估过程出错了，分析的二个原因！</h3><p>根据我们的分析，Dlib拿到低的精度的原因如下：
<strong>第一个主要原因是训练dlib的是标准数据库没有加标签（annotations）</strong>。数据库图片是由dlib作者自己切的，因此可以发现同样是人脸检测的框，同OpenCV 中的两个方法 OpenCV-Haar 或者 OpenCV-DNN 相比，dlib的方法会裁掉额头一部分或者脸颊一部分（forehead chin）。下面的图中可以看到。</p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/fd-acc-result1-e1539872861105.jpg alt style=width:80%></div></p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/fd-acc-result2-e1539872827875.jpg alt style=width:80%></div></p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/fd-acc-result3-e1539872783684.jpg alt style=width:80%></div></p><p>这个问题可以导致 在上个柱状图中 dlib 分数会低。AP_X 代表着 X% 预测框和真实框交叠的面积占合起来面积的比率。dlib 的 AP_75 的得分为0，尽管有在 AP_75 比 Haar 还高。这个就意味着：<strong>Dlib 模型可以预测更多的人脸比 Haar 特征，但是dlib的框的 AP_75 得分比较低</strong>。</p><p><strong>第二个原因是 dlib 不能检测小的人脸，进一步拉低了得分。</strong></p><p><strong>因此，比较 OpenCV 和 Dlib 精确性的一个相对合理的指标是 AP_50 （或者可以使用小于50%的指标，我们只是设阈值用来计算人头的个数）</strong> 以上分析大家使用 Dlib 的时候注意一下。</p><h2 id=6-速度比较>6. 速度比较</h2><p>Speed Comparison</p><p>我们使用 300x300 图像做的对比实验。Dlib 的 MMOD 模型可以利用上GPU，但是OpenCV方法对 NVIDIA GPUs 支持还没有。所以我们评估对比这些方法在CPU上，但我们也给出 GPU 版本 MMOD 结果。</p><p>(这段话以后写论文的时候可以用到，保留:cat:) We used a 300×300 image for the comparison of the methods. The MMOD detector can be run on a GPU, but the support for NVIDIA GPUs in OpenCV is still not there. So, we evaluate the methods on CPU only and also report result for MMOD on GPU as well as CPU.</p><h3 id=硬件的配置>硬件的配置</h3><p>Processor : Intel Core i7 6850K – 6 Core
RAM : 32 GB
GPU : NVIDIA GTX 1080 Ti with 11 GB RAM
OS : Linux 16.04 LTS
Programming Language : Python</p><p>我们跑了10次，每次对图片进行10000趟测试得总时间，然后对这10次取平均。下面的柱状图是结果。We run each method 10000 times on the given image and take 10 such iterations and average the time taken. Given below are the results.</p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/face-detection-speed-comparison.jpg alt style=width:80%></div></p><p>从图中可以看到，对于 300x300 的图片，除了 MMOD。MMOD 在GPU上还是很快的，CPU上就是渣渣了。As you can see that for the image of this size, all the methods perform in real-time, except MMOD. MMOD detector is very fast on a GPU but is very slow on a CPU.</p><p>以上的结果在不同电脑硬软件环境下可能不一样。</p><h2 id=7-多种情况讨论>7. 多种情况讨论</h2><p>除了速度和精度外，我们在选择哪个模型来使用还有一些因素可以考虑。在这节中，将考虑这些情况下的选择。主要为人脸大小变化、非正脸、遮挡。</p><h3 id=71-人脸大小变化>7.1. 人脸大小变化</h3><p>Detection across scale</p><p>下面有一个例子视频，这位帅哥在做一个前后的健身动作，使得脸部区域变大变小。可以看到OpenCV DNN 检测出了所有的脸，而 Dlib 的方法只有在大于某个 size 的时候才被检测出来。</p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/face-detection-scale-comparison.gif alt style=width:80%></div></p><p>我们测试后，脸大于 70×70 才能被 dlib检测出。正如在前面说到的，对小人脸检测是dlib方法的一个大的缺点。我们也可以将图片上采样，但这样的话速度的话相对于 OpenCV-DNN 就太慢了。</p><p>It can be seen that dlib based methods are able to detect faces of size upto ~(70×70) after which they fail to detect. As we discussed earlier, I think this is the major drawback of Dlib based methods. Since it is not possible to know the size of the face before-hand in most cases. We can get rid of this problem by upscaling the image, but then the speed advantage of dlib as compared to OpenCV-DNN goes away.</p><h3 id=72-非正脸>7.2. 非正脸</h3><p>Non-frontal Face</p><p>对于非正脸的测试，我们选用了 looking towards right, left, up, down。为了对 dlib 公平，我们选择了face 大于 80×80 的图片。下面是一些例子。</p><p>Non-frontal can be looking towards right, left, up, down. Again, to be fair with dlib, we make sure the face size is more than 80×80. Given below are some examples.</p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/fd-non-frontal-result7.jpg alt style=width:80%></div></p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/fd-non-frontal-result6.jpg alt style=width:80%></div></p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/fd-non-frontal-result5.jpg alt style=width:80%></div></p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/fd-non-frontal-result4.jpg alt style=width:80%></div></p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/fd-non-frontal-result2.jpg alt style=width:80%></div></p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/fd-non-frontal-result1.jpg alt style=width:80%></div></p><p>和预期的一样，OpenCV Haar 方法完全败了。Dlib HoG能检测出 left 或 right looking faces，但是精度不如那些DNN方法。</p><p>As expected, Haar based detector fails totally. HoG based detector does detect faces for left or right looking faces (since it was trained on them) but not as accurately as the DNN based detectors of OpenCV and Dlib.</p><h3 id=73-遮挡>7.3. 遮挡</h3><p>Occlusion</p><p>接下来看一下遮挡的情况。Let us see how well the methods perform under occlusion.</p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/fd-occlusion-result1.jpg alt style=width:80%></div></p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/fd-occlusion-result2.jpg alt style=width:80%></div></p><p><div style=text-align:center><img src=https://www.learnopencv.com/wp-content/uploads/2018/10/fd-occlusion-result3.jpg alt style=width:80%></div></p><p>再一次看到，DNN方法比其他方法更优，OpenCV-DNN 比 Dlib-MMOD 还好一点。这是因为CNN 特征 比 HoG or Haar 更加鲁棒，稳定。</p><p>Again, the DNN methods outperform the other two, with OpenCV-DNN slightly better than Dlib-MMOD. This is mainly because the CNN features are much more robust than HoG or Haar features.</p><h2 id=8-总结>8. 总结</h2><p>我们讨论了每个方法的优缺点。个人建议使用 OpenCV-DNN 和 Dlib-HoG 在应用和设备成本权衡中。以下我们的建议：</p><p>We had discussed the pros and cons of each method in the respective sections. I recommend to try both OpenCV-DNN and HoG methods for your application and decide accordingly. We share some tips to get started.</p><h3 id=81-大多数的情况>8.1 大多数的情况</h3><p>General Case</p><p>在多数场景中，我们提前不知道图片大小，因此 选用 OpenCV – DNN 相当快也很精确，甚至对于小人脸也不错，各种人脸角度也可以。选用这个在大多情况下是最优的。</p><p>In most applications, we won’t know the size of the face in the image before-hand. Thus, it is better to use OpenCV – DNN method as it is pretty fast and very accurate, even for small sized faces. It also detects faces at various angles. We recommend to use OpenCV-DNN in most</p><h3 id=82-大小中等或大一点图片>8.2 大小中等或大一点图片</h3><p>For medium to large image sizes</p><p>Dlib HoG 在 cpu上是最快的一个方法。但是它不能检测出 face size (&lt; 70x70) 的图片。所以你得清楚使用的场景，比如自拍的话就可以。如果能使用GPU的话 dlib-MMOD 是一个最好的选择，因为它支持GPU，跑得也比较快，也能适应人脸的角度变化。</p><p>Dlib HoG is the fastest method on CPU. But it does not detect small sized faces (&lt; 70x70). So, if you know that your application will not be dealing with very small sized faces ( for example a selfie app ), then HoG based Face detector is a better option. Also, If you can use a GPU, then MMOD face detector is the best option as it is very fast on GPU and also provides detection at various angles.</p><h3 id=83-高分辨率图像>8.3 高分辨率图像</h3><p>High resolution images</p><p>对于这些方法来说，高分辨图像都有点难度，计算时间比较长。可能采用的方法是resize图像 （ scale down the image），HoG / MMOD方法可能就识别不出了，但是可以使用 OpenCV-DNN 尝试一下。我认为也可以将图片分割开再识别呀，嘻嘻。</p><p>Since feeding high resolution images is not possible to these algorithms (for computation speed), HoG / MMOD detectors might fail when you scale down the image. On the other hand, OpenCV-DNN method can be used for these since it detects small faces.</p><p>有任何建议，欢迎在下面评论。
Have any other suggestions? Please mention in the comments and we’ll update the post with them!</p><h2 id=参考>参考</h2><p><a href=https://github.com/opencv/opencv/blob/master/modules/dnn/misc/face_detector_accuracy.py>FDDB Comparison code</a>
<a href=http://blog.dlib.net/2016/10/easily-create-high-quality-object.html>Dlib Blog</a>
<a href=http://dlib.net/cnn_face_detector.py.html>dlib mmod python example</a>
<a href=http://dlib.net/dnn_mmod_face_detection_ex.cpp.html>dlib mmod cpp example</a>
<a href=https://github.com/opencv/opencv/tree/master/samples/dnn/face_detector>OpenCV DNN Face detector</a>
<a href=https://docs.opencv.org/3.4/d7/d8b/tutorial_py_face_detection.html>Haar Based Face Detector</a></p><h2 id=todos>TODOS</h2><p>文章作者是 <a href=https://www.learnopencv.com/author/vikas/>VIKAS GUPTA</a></p><p>来，看看这个是站长大佬的图片，是不是很熟悉？膜拜一哈。</p><p><div style=text-align:center><img src="https://secure.gravatar.com/avatar/708995cd13fb5756f6bc418aecb23b78?s=250&amp;d=mm&amp;r=g" alt=blog_author style=width:80%></div></p><p>我订阅后文章后，作者发的邮件内容，并没有给文章页的代码。</p><ul><li><a href=https://www.learnopencv.com/wp-content/uploads/2015/05/Computer-Vision-Resources.pdf>给的Computer-Vision-Resources.pdf</a></li><li><a href=https://github.com/spmallick/dlib>作者的Dlib fork</a></li></ul><p><strong>重要资源</strong></p><ul><li><p>作者博客 <a href=https://www.learnopencv.com/>link</a></p></li><li><p>作者的所有代码拿走不谢 <a href=https://github.com/spmallick/learnopencv>link</a></p></li><li><p><input checked disabled type=checkbox> 翻译</p></li><li><p><input checked disabled type=checkbox> 代码运行</p></li><li><p><input disabled type=checkbox> 根据该作者的博客继续翻译，学习，向大佬致敬。</p></li></ul></main><script src=https://giscus.app/client.js data-repo=talengu/talengu.github.io data-repo-id="MDEwOlJlcG9zaXRvcnk5MTk0NjkxNQ==" data-category=Blog data-category-id=DIC_kwDOBXr_o84C0Qpk data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=/css/giscus.css data-lang=zh-CN crossorigin=anonymous async></script><footer>- END -<hr><a href=/about target=_blank title=About>一塘</a>
© 2025
<a href=/index.xml target=_blank title=RSS>RSS</a></footer></body></html>