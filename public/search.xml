<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[计算机视觉应用（1）- Real-time HeadPose]]></title>
    <url>%2Fpublic%2F2018%2F11%2F16%2Fcv%2FHeadPoseALL%2F</url>
    <content type="text"><![CDATA[本文方法的流程： 检测人脸 OpenCV DNN 检测landmark Dlib 利用landmark计算pose landmark有68个点我用了其中6个点 下面是代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210#!/usr/bin/env python# -*- coding: utf-8 -*- import cv2import numpy as npimport sysimport timeimport dlib# 检测人脸# OpenCV DNN supports 2 networks.# 1. FP16 version of the original caffe implementation ( 5.4 MB )# 2. 8 bit Quantized version using Tensorflow ( 2.7 MB )# model:# https://github.com/spmallick/learnopencv/tree/master/FaceDetectionComparison/modelsDNN = "CAFFE"if DNN == "CAFFE": modelFile = "models/res10_300x300_ssd_iter_140000_fp16.caffemodel" configFile = "models/deploy.prototxt" net = cv2.dnn.readNetFromCaffe(configFile, modelFile)else: modelFile = "models/opencv_face_detector_uint8.pb" configFile = "models/opencv_face_detector.pbtxt" net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)def detectFaceOpenCVDnn(net, frame): conf_threshold = 0.7 frameOpencvDnn = frame.copy() frameHeight = frameOpencvDnn.shape[0] frameWidth = frameOpencvDnn.shape[1] blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], False, False) net.setInput(blob) detections = net.forward() bboxes = [] for i in range(detections.shape[2]): confidence = detections[0, 0, i, 2] if confidence &gt; conf_threshold: x1 = int(detections[0, 0, i, 3] * frameWidth) y1 = int(detections[0, 0, i, 4] * frameHeight) x2 = int(detections[0, 0, i, 5] * frameWidth) y2 = int(detections[0, 0, i, 6] * frameHeight) bboxes.append([x1, y1, x2, y2]) cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight / 150)), 8) return frameOpencvDnn, bboxes# 生成landmarkpredictor = dlib.shape_predictor("models/shape_predictor_68_face_landmarks.dat")# if not automatically downloaded, get it from:# http://sourceforge.net/projects/dclib/files/dlib/v18.10/shape_predictor_68_face_landmarks.dat.bz2def get_landmarks(img, bboxes): def _shape_to_np(shape): xy = [] for i in range(68): xy.append((shape.part(i).x, shape.part(i).y,)) xy = np.asarray(xy, dtype='float32') return xy def _det_to_dlib_rectangle(bbox): bbox = [int(x) for x in bbox[:4]] return dlib.rectangle(bbox[0], bbox[1], bbox[2], bbox[3]) shape = predictor(img, _det_to_dlib_rectangle(bboxes[0])) xy = _shape_to_np(shape) # lmarks.append(xy) # lmarks = np.asarray(lmarks, dtype='float32') # display_landmarks(img, dets, shapes) # return lmarks return xydef getlandmark(img, bboxs): landmark = get_landmarks(img, bboxs) sixPoints = [landmark[30], landmark[8], landmark[36], landmark[45], landmark[48], landmark[54] ] return sixPoints# 计算posedef showHeadPose(im, sixPoints): # Read Image # im = cv2.imread("headPose.jpg") size = im.shape # 2D image points. If you change the image, you need to change vector # image_points = np.array([ # (359, 391), # Nose tip 30 # start with 0 # (399, 561), # Chin 8 # (337, 297), # Left eye left corner 36 # (513, 301), # Right eye right corne 45 # (345, 465), # Left Mouth corner 48 # (453, 469) # Right mouth corner 54 # ], dtype="double") image_points = np.array(sixPoints, dtype="double") # 3D model points. model_points = np.array([ (0.0, 0.0, 0.0), # Nose tip (0.0, -330.0, -65.0), # Chin (-225.0, 170.0, -135.0), # Left eye left corner (225.0, 170.0, -135.0), # Right eye right corne (-150.0, -150.0, -125.0), # Left Mouth corner (150.0, -150.0, -125.0) # Right mouth corner ]) # Camera internals focal_length = size[1] center = (size[1] / 2, size[0] / 2) camera_matrix = np.array( [[focal_length, 0, center[0]], [0, focal_length, center[1]], [0, 0, 1]], dtype="double" ) print "Camera Matrix :\n &#123;0&#125;".format(camera_matrix) dist_coeffs = np.zeros((4, 1)) # Assuming no lens distortion (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE) print "Rotation Vector:\n &#123;0&#125;".format(rotation_vector) print "Translation Vector:\n &#123;0&#125;".format(translation_vector) # Project a 3D point (0, 0, 1000.0) onto the image plane. # We use this to draw a line sticking out of the nose (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs) for p in image_points: cv2.circle(im, (int(p[0]), int(p[1])), 3, (0, 0, 255), -1) p1 = (int(image_points[0][0]), int(image_points[0][1])) p2 = (int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1])) cv2.line(im, p1, p2, (255, 0, 0), 2) return im# Display image# cv2.imshow("Output", im)# cv2.waitKey(0)if __name__ == "__main__": # source = "orginal.avi" source = 0 if len(sys.argv) &gt; 1: source = sys.argv[1] cap = cv2.VideoCapture(source) hasFrame, frame = cap.read() CV_CAP_PROP_FRAME_WIDTH = 3 # 视频的宽 CV_CAP_PROP_FRAME_HEIGHT = 4 # 视频的高 width = cap.get(CV_CAP_PROP_FRAME_WIDTH) height = cap.get(CV_CAP_PROP_FRAME_HEIGHT) SizeTuple = (int(width / 2), int(height / 2)) vid_writer = cv2.VideoWriter('output-&#123;&#125;.avi'.format(str(source).split(".")[0]),cv2.VideoWriter_fourcc('M','J','P','G'), 15, SizeTuple) frame_count = 0 tt = 0 while (1): hasFrame, frame = cap.read() if not hasFrame: break frame_count += 1 frame = cv2.resize(frame, SizeTuple) frame = cv2.flip(frame, 1) try: t = time.time() outOpencvDnn, bboxes = detectFaceOpenCVDnn(net, frame) sixPoints = getlandmark(outOpencvDnn, bboxes) # 添加headpose的操作 outHeadPoseImg = showHeadPose(outOpencvDnn, sixPoints) tt += time.time() - t fpsOpencvDnn = frame_count / tt label = "OpenCV DNN ; FPS : &#123;:.2f&#125;".format(fpsOpencvDnn) cv2.putText(outOpencvDnn, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1, cv2.LINE_AA) frame = outHeadPoseImg except: pass cv2.imshow("Face Detection and Head Pose", frame) vid_writer.write(frame) if frame_count == 1: tt_opencvDnn = 0 k = cv2.waitKey(1) if k == 27: break cv2.destroyAllWindows() vid_writer.release() TODOS 在landmark检测中模型太大，不利于放到手机上（90Mb） 模型68点检测 重新训练5点检测 将landmark方法转移到opencv上 landmark抖动 加上一些滤波？kalman Savgol 滤波器？ 带上眼镜的误差也比较大 对本文的理论再进行解释清楚，主要参考 headpose learnopencv 代码里面没有合并landmark部分的代码]]></content>
      <categories>
        <category>计算机视觉应用</category>
        <category>HeadPose</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>DeepLearning</tag>
        <tag>HeadPose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[译] Hand Keypoint Detection using Deep Learning and OpenCV]]></title>
    <url>%2Fpublic%2F2018%2F11%2F13%2Fcv%2FHandKeypointDetection%2F</url>
    <content type="text"><![CDATA[我的翻译里面带了好多英文对应，为了我以后写作服务，请读者朋友原谅。:cat: :cat:原文地址 https://www.learnopencv.com/hand-keypoint-detection-using-deep-learning-and-opencv/ 重要结论： 作者github代码 HandPosetip：仅下载一个文件夹会比较快 svn checkout https://github.com/spmallick/learnopencv/trunk/HandPose 代码说明：为了使文章显得简洁一些，在文中只提供关键的代码片段。在github项目中详细代码，包括。。。。。 Hand Keypoint detection is the process of finding the joints on the fingers as well as the finger-tips in a given image. It is similar to finding keypoints on Face ( a.k.a Facial Landmark Detection ) or Body ( a.k.a Human Body Pose Estimation ), but, different from Hand Detection since in that case, we treat the whole hand as one object. In our previous blog posts on Pose estimation – Single Person, Multi-Person, we had discussed how to use deep learning models in OpenCV to extract body pose in an image or video. The researchers at CMU Perceptual Computing Lab have also released models for keypoint detection of Hand and Face along with the body. The Hand Keypoint detector is based on this paper. We will take a quick look at the network architecture and then share code in C++ and Python for predicting hand keypoints using OpenCV. 1. 背景 [Image taken from the paper] They start with a small set of labelled hand images and use a neural network ( Convolutional Pose Machines – similar to Body Pose ) to get rough estimates of the hand keypoints. They have a huge multi-view system set up to take images from different view-points or angles comprising of 31 HD cameras. They pass these images through the detector to get many rough keypoint predictions. Once you get the detected keypoints of the same hand from different views, Keypoint triangulation is performed to get the 3D location of the keypoints. The 3D location of keypoints is used to robustly predict the keypoints through reprojection from 3D to 2D. This is especially crucial for images where keypoints are difficult to predict. This way they get a much improved detector in a few iterations. In summary, they use keypoint detectors and multi-view images to come up with an improved detector. The detection architecture used is similar to the one used for body pose. The main source of improvement is the multi-view images for the labelled set of images. The model produces 22 keypoints. The hand has 21 points while the 22nd point signifies the background. The points are as shown below: Let us see how to use the model in OpenCV. 2. 代码Code for Hand Keypoint Detection 2.1. Download model for Hand KeypointFirst thing is to download the model weights file. The config file has been provided with the code. You can either use the getModels.sh script to download the file to the hand/ folder. Go to the code folder and run the following command from the Terminal. 12sudo chmod a+x getModels.sh./getModels.sh You can also download the model from this link. Please put the model in the hand/ folder after downloading. 2.2. Load Model and ImageFirst, we will load the image and the model into memory. Make sure you have the model downloaded and in the correct folder as specified in the variable. C++123456789string protoFile = "hand/pose_deploy.prototxt";string weightsFile = "hand/pose_iter_102000.caffemodel";int nPoints = 22;string imageFile = "hand.jpg";Mat frame = imread(imageFile);Net net = readNetFromCaffe(protoFile, weightsFile); Python123456protoFile = "hand/pose_deploy.prototxt"weightsFile = "hand/pose_iter_102000.caffemodel"nPoints = 22frame = cv2.imread("hand.jpg")net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile) 2.3. Get PredictionsWe convert the BGR image to blob so that it can be fed to the network. Then we do a forward pass to get the predictions. C++12345Mat inpBlob = blobFromImage(frame, 1.0 / 255, Size(inWidth, inHeight), Scalar(0, 0, 0), false, false);net.setInput(inpBlob);Mat output = net.forward(); Python123456inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)net.setInput(inpBlob)output = net.forward() 2.4. Show DetectionsThe output has 22 matrices with each matrix being the Probability Map of a keypoint. Given below is the probability heatmap superimposed on the original image for the keypoint belonging to the tip of thumb and base of little finger. For finding the exact keypoints, first, we scale the probabilty map to the size of the original image. Then find the location of the keypoint by finding the maxima of the probability map. This is done using the minmaxLoc function in OpenCV. We draw the detected points along with the numbering on the image. C++123456789101112131415161718192021222324// find the position of the body partsvector&lt;Point&gt; points(nPoints);for (int n=0; n &lt; nPoints; n++)&#123; // Probability map of corresponding body's part. Mat probMap(H, W, CV_32F, output.ptr(0,n)); resize(probMap, probMap, Size(frameWidth, frame_width));Point maxLoc;double prob;minMaxLoc(probMap, 0, &amp;prob, 0, &amp;maxLoc);if (prob &gt; thresh)&#123; circle(frameCopy, cv::Point((int)maxLoc.x, (int)maxLoc.y), 8, Scalar(0,255,255), -1); cv::putText(frameCopy, cv::format("%d", n), cv::Point((int)maxLoc.x, (int)maxLoc.y), cv::FONT_HERSHEY_COMPLEX, 1, cv::Scalar(0, 0, 255), 2);&#125;points[n] = maxLoc;&#125;imshow("Output-Keypoints", frameCopy); Python12345678910111213141516171819points = []for i in range(nPoints): # confidence map of corresponding body's part. probMap = output[0, i, :, :] probMap = cv2.resize(probMap, (frameWidth, frameHeight))# Find global maxima of the probMap.minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)if prob &gt; threshold : cv2.circle(frameCopy, (int(point[0]), int(point[1])), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED) cv2.putText(frameCopy, "&#123;&#125;".format(i), (int(point[0]), int(point[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA) # Add the point to the list if the probability is greater than the threshold points.append((int(point[0]), int(point[1])))else : points.append(None)cv2.imshow('Output-Keypoints', frameCopy) Sample Result with keypoints numbered using the Hand keypoint Detector 2.5. Draw SkeletonWe will use the detected points to get the skeleton formed by the keypoints and draw them on the image. C++1234567891011121314151617181920int nPairs = sizeof(POSE_PAIRS)/sizeof(POSE_PAIRS[0]);for (int n = 0; n &lt; nPairs; n++)&#123;​ // lookup 2 connected body/hand parts​ Point2f partA = points[POSE_PAIRS[n][0]];​ Point2f partB = points[POSE_PAIRS[n][1]];if (partA.x&lt;=0 || partA.y&lt;=0 || partB.x&lt;=0 || partB.y&lt;=0) continue;line(frame, partA, partB, Scalar(0,255,255), 8);circle(frame, partA, 8, Scalar(0,0,255), -1);circle(frame, partB, 8, Scalar(0,0,255), -1);&#125;imshow("Output-Skeleton", frame); Python1234567891011# Draw Skeletonfor pair in POSE_PAIRS: partA = pair[0] partB = pair[1]if points[partA] and points[partB]: cv2.line(frame, points[partA], points[partB], (0, 255, 255), 2) cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)cv2.imshow('Output-Skeleton', frame) Result showing the skeleton obtained by joining the keypoint pairs One thing to note is that the detector expects a bounding box around the hand to predict the keypoints. Thus, for better results, the hand should be close to the camera or it should be cropped using a hand detector and then fed to the network.Also, the code given can detect only one hand at a time. You can easily port it to detecting multiple hands with the help of the probability maps and applying some heuristics. 3. 应用The model just discussed can be used in many practical applications such as: Gesture Recognition Sign Language understanding for disabled Activity Recognition based on Hand 参考1. [Image used in the post]2. [Hand Keypoint Detection Paper]3. [Hand Keypoint Detection model]4. [Link to demo video]5. [Link to american sign language video]6. [Hand Image from Wikipedia] 前几日分享了 learnopencv.com 博主 Satya Mallick 发表的关于 OpenCV Mask RCNN 实例分割的博文（详见：），展示了 OpenCV 作为 DNN 推断工具的简单用法。昨日 Satya Mallick 又发表了使用 OpenCV 调用 OpenPose 工程中的手部关键点检测（hand pose estimation）模型的文章，对于想要使用手部关键点检测做手势识别、手语识别、抽烟检测等工程开发的朋友来说这是一个非常简单的上手教程。先来看看作者发布的视频效果： 在大部分情况下还是不错的，但也出现了少数帧关键点跳变的情况。 1. 算法思想该文中作者使用的算法模型是 CMU Perceptual Computing Lab 开源的集合人体、人脸、手部关键点检测的开源库 OpenPose，其中手部关键点检测（Hand Keypoint detector）算法来自 CVPR2017 的论文《Hand Keypoint Detection in Single Images using Multiview Bootstrapping》。人手在 3D 空间由于视角不同、灵活的精细动作等原因，较难得到精确标注的数据集。在该论文中，作者提出了一种称之为 Multiview Bootstrapping 的手部关键点检测迭代改进算法，实现了具有较高精度的检测算法。 如上图所示，作者提出首先使用少量标注的含有人手关键点的数据集训练 Convolutional Pose Machines 神经网络，使用 31 个不同视角的高清摄像头拍摄人手，用上述检测模型初步检测关键点，将这些关键点根据摄像机的位姿构建三角（triangulation），得到关键点的 3D 位置，再将计算得到的 3D 点位置重投影到每一幅不同视角的 2D 图像，再使用这些 2D 图像和关键点标注训练检测模型网络，经过几次迭代，即可以得到较为精确的手部关键点检测模型。原论文中提出的模型可生成 22 个关键点，其中 21 个点是人手部的，第 22 个点代表着背景。下图展示了人手部的 21 个关键点位置。 2. OpenCV 手部关键点检测主要流程1）下载模型运行开源工程中的 getModels.sh 下载模型， 或者直接在网址：http://posefs1.perception.cs.cmu.edu/OpenPose/models/hand/pose_iter_102000.caffemodel下载。将模型放到 “hand/” 文件夹下。 2）加载模型和图像使用 OpenCV DNN 函数 readNetFromCaffe 函数加载模型权重。 3）推断预测blobFromImage 将图像转为 blob,forward 函数实现网络推断。 4）获取关键点精确位置并显示上述网络计算的结果是 22 个矩阵，每个矩阵代表某个特定关键点最可能出现在图像中哪个位置的热图，需要调用 minmaxLoc 函数找到精确位置，进而将其画出并标注序号。 5）画出骨架 视频效果： 3. 去抖从视频中可以看出关键点有抖动，且有部分帧出现关键点跳变，如何让其更稳定呢？ 在该博文评论区，某大佬提出使用 Savgol 滤波器对数据进行平滑可以得到较满意的结果。看看效果如何： 是不是感觉立刻好了很多？ 关键点平滑代码：https://stackoverflow.com/questions/52450681/how-can-i-use-smoothing-techniques-to-remove-jitter-in-pose-estimation/ 原博文地址：https://www.learnopencv.com/hand-keypoint-detection-using-deep-learning-and-opencv/代码地址：https://github.com/spmallick/learnopencv/tree/master/HandPose 转载请注明：《OpenCV 深度学习手部关键点检测（手势识别）代码示例》 TODO合并上面的工作]]></content>
      <categories>
        <category>博客转载</category>
        <category>cv</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
        <tag>Hand Keypoint Detection</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[译] Face Detection – OpenCV, Dlib and Deep Learning ( C++ / Python )]]></title>
    <url>%2Fpublic%2F2018%2F11%2F12%2Fcv%2FFaceDetectionComparison%2F</url>
    <content type="text"><![CDATA[我的翻译里面带了好多英文对应，为了我以后写作服务，请读者朋友原谅。:cat: :cat:原文地址 https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/ 重要结论：在多数场景中，我们提前不知道图片大小，因此 选用 OpenCV – DNN 相当快也很精确，甚至对于小人脸也不错，各种人脸角度也可以。选用这个在大多情况下是最优的。 作者github代码 FaceDetectionComparison 代码说明：为了使文章显得简洁一些，在文中只提供关键的代码片段。在github项目中详细代码，包括每个方法独立的代码和整合在一起的cpp和py文件（run-all.py 和 run-all.cpp），同时里面也有运行代码所使用的人脸检测模型。 在这篇文章中，作者讨论使用了OpenCV或Dlib的多种人脸检测的代码，并给出性能分析。作者使用的 Face Detector 包括以下四个，后面分别给出 c++ 和 python 实现。 OpenCV 的 Haar Cascade Face Detector OpenCV 的 Deep Learning based Face Detector Dlib 的 HoG Face Detector Dlib 的 Deep Learning based Face Detector 作者限于篇幅没有对对理论进行深入解读，只讨论框架的使用，同时分享一些应用上的选择权衡的经验。 实验的图片尺寸是 image size 300×300 1. OpenCV-Haar在2001年，Viola 和 Jones提出Haar Cascade 特征为基础的 Face Detector，在以后的多年内都是最优的人脸检测算法。以他们的算法为基础人们做了很多改进。OpenCV提供了很多Haar特征的模型算法，更多的Haar特征模型 here 代码Python123456faceCascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')faces = faceCascade.detectMultiScale(frameGray)for face in faces: x1, y1, w, h = face x2 = x1 + w y2 = y1 + h C++123456789101112faceCascadePath = "./haarcascade_frontalface_default.xml";faceCascade.load( faceCascadePath )std::vector&lt;Rect&gt; faces;faceCascade.detectMultiScale(frameGray, faces);for ( size_t i = 0; i &lt; faces.size(); i++ )&#123; int x1 = faces[i].x; int y1 = faces[i].y; int x2 = faces[i].x + faces[i].width; int y2 = faces[i].y + faces[i].height;&#125; 对图片灰度变化（grayscale）后，再应用 haar cascade 特征，输出是脸的list。list中每个item有四个element 分别为 top-left corner的(x, y) 、检测出来脸的大小(width, height) 。 优点 在CPU上几乎是实时的（real-time） 简单的框架 （Simple Architecture） 能检测不同大小的脸 （different scales） 缺点 主要缺点是有很多错误的预测（False predictions），会多预测出人脸。 人脸非正面效果不好 （non-frontal） 人脸遮挡效果不好 （under occlusion） 2. OpenCV-DNN在 OpenCV 3.3 中引入这个方法。DNN模型使用SSD Single-Shot-Multibox detector框架和 ResNet-10 特征提取网络（backbone）。这个模型喂的数据是从网上采集的，但是训练的源代码没有公开。OpenCV提供了2个模型文件。 Float 16 位版本模型，使用原始的 caffe 训练 (5.4 MB) 8 bit quantized 版本模型，使用 Tensorflow 训练 (2.7 MB) 代码 FaceDetectionComparison 里面放了这两个模型文件。 代码Python123456789DNN = "TF"if DNN == "CAFFE": modelFile = "res10_300x300_ssd_iter_140000_fp16.caffemodel" configFile = "deploy.prototxt" net = cv2.dnn.readNetFromCaffe(configFile, modelFile)else: modelFile = "opencv_face_detector_uint8.pb" configFile = "opencv_face_detector.pbtxt" net = cv2.dnn.readNetFromTensorflow(modelFile, configFile) C++123456789101112131415const std::string caffeConfigFile = "./deploy.prototxt";const std::string caffeWeightFile = "./res10_300x300_ssd_iter_140000_fp16.caffemodel";const std::string tensorflowConfigFile = "./opencv_face_detector.pbtxt";const std::string tensorflowWeightFile = "./opencv_face_detector_uint8.pb";# ifdef CAFFE Net net = cv::dnn::readNetFromCaffe(caffeConfigFile, caffeWeightFile);# else Net net = cv::dnn::readNetFromTensorflow(tensorflowWeightFile, tensorflowConfigFile);# endif caffe 和 Tensorflow 框架加载模型的代码。使用 Float 16 的 Caffe 模型，需要 caffemodel 和 prototxt 文件。使用 8 bit quantized 的 Tensorflow 模型，需要 Tensorflow 配置文件和模型。 Python123456789101112blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], False, False)net.setInput(blob)detections = net.forward()bboxes = []for i in range(detections.shape[2]): confidence = detections[0, 0, i, 2] if confidence &gt; conf_threshold: x1 = int(detections[0, 0, i, 3] * frameWidth) y1 = int(detections[0, 0, i, 4] * frameHeight) x2 = int(detections[0, 0, i, 5] * frameWidth) y2 = int(detections[0, 0, i, 6] * frameHeight) C++12345678910111213141516171819202122232425#ifdef CAFFEcv::Mat inputBlob = cv::dnn::blobFromImage(frameOpenCVDNN, inScaleFactor, cv::Size(inWidth, inHeight), meanVal, false, false);#elsecv::Mat inputBlob = cv::dnn::blobFromImage(frameOpenCVDNN, inScaleFactor, cv::Size(inWidth, inHeight), meanVal, true, false);#endifnet.setInput(inputBlob, "data");cv::Mat detection = net.forward("detection_out");cv::Mat detectionMat(detection.size[2], detection.size[3], CV_32F, detection.ptr&lt;float&gt;());for (int i = 0; i &lt; detectionMat.rows; i++)&#123; float confidence = detectionMat.at&lt;float&gt;(i, 2); if (confidence &gt; confidenceThreshold) &#123; int x1 = static_cast&lt;int&gt;(detectionMat.at&lt;float&gt;(i, 3) * frameWidth); int y1 = static_cast&lt;int&gt;(detectionMat.at&lt;float&gt;(i, 4) * frameHeight); int x2 = static_cast&lt;int&gt;(detectionMat.at&lt;float&gt;(i, 5) * frameWidth); int y2 = static_cast&lt;int&gt;(detectionMat.at&lt;float&gt;(i, 6) * frameHeight); cv::rectangle(frameOpenCVDNN, cv::Point(x1, y1), cv::Point(x2, y2), cv::Scalar(0, 255, 0), 2, 4); &#125;&#125; 在上面的代码里面，图像转为blob输入进network里，利用前向传播函数forward()，得到一个4-D matrix。 #TODO :这里不是很理解，代码跑起来看一下？？？ The 3rd dimension iterates over the detected faces. (i is the iterator over the number of faces) The fourth dimension contains information about the bounding box and score for each face. For example, detections[0,0,0,2] gives the confidence score for the first face, and detections[0,0,0,3:6] give the bounding box. The output coordinates of the bounding box are normalized between [0,1]. Thus the coordinates should be multiplied by the height and width of the original image to get the correct bounding box on the image. 优点（merits） 在本文四个方法中最精确（Most accurate） 可以在CPU上实时运行（real-time） 人脸不同方向效果不错（上下左右，侧脸等）up, down, left, right, side-face etc 人脸不同大小效果不错哦（various scales, big and tiny OK） OpenCV的这个DNN方法克服了 Haar cascade 方法的不足，同时精度也不比它差。暂时没有发现这个方法其他有不足地方，除了比后面的 Dlib HoG 方法速度慢一点以外。 作者建议，在使用OpenCV时，比Haar方法，可以优先考虑DNN方法。 3. Dlib-HoGHoG 人脸检测方法被广泛的使用，基于 HoG 特征和 SVM 分类。作者还写了一篇 HoG 的博客 post。模型有5个 HOG filters 滤波器（ front looking, left looking, right looking, front looking but rotated left, and a front looking but rotated right），模型直接放在了头文件里面 header file。 训练模型的数据库，来自LFW dataset，由 Davis King (Dlib的作者) 手工标记 （manually annotated）共2825张。需要的话，数据库从这里可以下载 dlib_face_detector_training_data.tar.gz. 代码Python1234567hogFaceDetector = dlib.get_frontal_face_detector()faceRects = hogFaceDetector(frameDlibHogSmall, 0)for faceRect in faceRects: x1 = faceRect.left() y1 = faceRect.top() x2 = faceRect.right() y2 = faceRect.bottom() C++12345678910111213141516frontal_face_detector hogFaceDetector = get_frontal_face_detector();// Convert OpenCV image format to Dlib's image formatcv_image&lt;bgr_pixel&gt; dlibIm(frameDlibHogSmall);// Detect faces in the imagestd::vector&lt;dlib::rectangle&gt; faceRects = hogFaceDetector(dlibIm);for ( size_t i = 0; i &lt; faceRects.size(); i++ )&#123; int x1 = faceRects[i].left(); int y1 = faceRects[i].top(); int x2 = faceRects[i].right(); int y2 = faceRects[i].bottom(); cv::rectangle(frameDlibHog, Point(x1, y1), Point(x2, y2), Scalar(0,255,0), (int)(frameHeight/150.0), 4);&#125; 在上面的代码中，首先加载 face detector，然后将图像输入给 detector 。其中第二个参数代表，想要上采样图片的倍数（times of upscale）。你给的数字越大，小脸检测出的概率越大。但是upscaling 会在计算上花费可观的时间（ substantial impact on the computation speed）。输出是脸的list， 框框对角的坐标（diagonal corners）。 优点 在cpu上最快的方法（在四个方法中） 对正面和轻微非正面的方法效果很不错 模型比较少对于其他三个的文件来说 轻微遮挡下可以检测 大概以上，这个方法多数情况可以工作，除了下面的情况。 缺点 主要缺点对小人脸不识别。由于训练在最小 80×80 的数据集上，要确保你的使用环境，不然的话你要自己再训练一下小人脸。 人脸框经常去掉了人额头一部分，有时脸颊一部分。（part of forehead and even part of chin sometimes） 在明显的遮挡情况下效果不好 在测量和极端不正面的脸情况不工作，像向上看，和向下看的情况。 4. Dlib-CNN这个模型使用了Maximum-Margin Object Detector (MMOD) 加CNN的特征的方法。训练过程相当简单，也不需要大量的数据去训练一个新的 object detector。更多的训练套路，在这个网站上 website. 使用的模型可以从 dlib-models repository 下载。 训练使用的数据库是dlib的作者 Davis King 手工标的，7220张从 ImageNet, PASCAL VOC, VGG, WIDER, Face Scrub等数据库里面挑的。这个数据库可以下载到。dlib_face_detection_dataset-2016-09-30.tar.gz 代码Python1234567dnnFaceDetector = dlib.cnn_face_detection_model_v1("./mmod_human_face_detector.dat")faceRects = dnnFaceDetector(frameDlibHogSmall, 0)for faceRect in faceRects: x1 = faceRect.rect.left() y1 = faceRect.rect.top() x2 = faceRect.rect.right() y2 = faceRect.rect.bottom() C++1234567891011121314151617181920String mmodModelPath = "./mmod_human_face_detector.dat";net_type mmodFaceDetector;deserialize(mmodModelPath) &gt;&gt; mmodFaceDetector;// Convert OpenCV image format to Dlib's image formatcv_image&lt;bgr_pixel&gt; dlibIm(frameDlibMmodSmall);matrix&lt;rgb_pixel&gt; dlibMatrix;assign_image(dlibMatrix, dlibIm);// Detect faces in the imagestd::vector&lt;dlib::mmod_rect&gt; faceRects = mmodFaceDetector(dlibMatrix);for ( size_t i = 0; i &lt; faceRects.size(); i++ )&#123; int x1 = faceRects[i].rect.left(); int y1 = faceRects[i].rect.top(); int x2 = faceRects[i].rect.right(); int y2 = faceRects[i].rect.bottom(); cv::rectangle(frameDlibMmod, Point(x1, y1), Point(x2, y2), Scalar(0,255,0), (int)(frameHeight/150.0), 4);&#125; 代码和 HoG detector 差不多，除了下载的 CNN face detection 的模型文件。 优点 不同的脸朝向效果不错 （face orientations） 遮挡比较稳定 （occlusion） 在GPU上很快 训练模型过程很简单 缺点 CPU上很慢 脸大小于 80×80 检测不出，因为模型在小脸训练的。所以要考虑你应用的具体场景脸的大小，当然也可以对小脸数据库再训练一下。 人脸框 bounding box 甚至比 HoG detector 还小。 5. 精度比较（Accuracy Comparison） 作者评估这四个模型使用的是 FDDB 数据库，其中评估OpenCV-DNN 脚本为 OpenCV face_detector_accuracy.py. 作者发现奇怪的结果。Dlib 的结果比 Haar OpenCV还要低，然而实际从图片上效果比较好。下图是这四个方法的精度得分（ Precision scores）。 指标说明（Metric）：AP_50 = Precision when overlap between Ground Truth and predicted bounding box is at least 50% (IoU = 50%)AP_75 = Precision when overlap between Ground Truth and predicted bounding box is at least 75% (IoU = 75%)AP_Small = Average Precision for small size faces (Average of IoU = 50% to 95%)AP_medium = Average Precision for medium size faces (Average of IoU = 50% to 95%)AP_Large = Average Precision for large size faces (Average of IoU = 50% to 95%)mAP = Average precision across different IoU (Average of IoU = 50% to 95%) 作者最近的发现评估过程对 Dlib 不够公平，科学。 5.1. 评估过程出错了，分析的二个原因！根据我们的分析，Dlib拿到低的精度的原因如下：第一个主要原因是训练dlib的是标准数据库没有加标签（annotations）。数据库图片是由dlib作者自己切的，因此可以发现同样是人脸检测的框，同OpenCV 中的两个方法 OpenCV-Haar 或者 OpenCV-DNN 相比，dlib的方法会裁掉额头一部分或者脸颊一部分（forehead chin）。下面的图中可以看到。 这个问题可以导致 在上个柱状图中 dlib 分数会低。AP_X 代表着 X% 预测框和真实框交叠的面积占合起来面积的比率。dlib 的 AP_75 的得分为0，尽管有在 AP_75 比 Haar 还高。这个就意味着：Dlib 模型可以预测更多的人脸比 Haar 特征，但是dlib的框的 AP_75 得分比较低。 第二个原因是 dlib 不能检测小的人脸，进一步拉低了得分。 因此，比较 OpenCV 和 Dlib 精确性的一个相对合理的指标是 AP_50 （或者可以使用小于50%的指标，我们只是设阈值用来计算人头的个数） 以上分析大家使用 Dlib 的时候注意一下。 6. 速度比较Speed Comparison 我们使用 300x300 图像做的对比实验。Dlib 的 MMOD 模型可以利用上GPU，但是OpenCV方法对 NVIDIA GPUs 支持还没有。所以我们评估对比这些方法在CPU上，但我们也给出 GPU 版本 MMOD 结果。 (这段话以后写论文的时候可以用到，保留:cat:) We used a 300×300 image for the comparison of the methods. The MMOD detector can be run on a GPU, but the support for NVIDIA GPUs in OpenCV is still not there. So, we evaluate the methods on CPU only and also report result for MMOD on GPU as well as CPU. 硬件的配置Processor : Intel Core i7 6850K – 6 CoreRAM : 32 GBGPU : NVIDIA GTX 1080 Ti with 11 GB RAMOS : Linux 16.04 LTSProgramming Language : Python 我们跑了10次，每次对图片进行10000趟测试得总时间，然后对这10次取平均。下面的柱状图是结果。We run each method 10000 times on the given image and take 10 such iterations and average the time taken. Given below are the results. 从图中可以看到，对于 300x300 的图片，除了 MMOD。MMOD 在GPU上还是很快的，CPU上就是渣渣了。As you can see that for the image of this size, all the methods perform in real-time, except MMOD. MMOD detector is very fast on a GPU but is very slow on a CPU. 以上的结果在不同电脑硬软件环境下可能不一样。 7. 多种情况讨论除了速度和精度外，我们在选择哪个模型来使用还有一些因素可以考虑。在这节中，将考虑这些情况下的选择。主要为人脸大小变化、非正脸、遮挡。 7.1. 人脸大小变化Detection across scale 下面有一个例子视频，这位帅哥在做一个前后的健身动作，使得脸部区域变大变小。可以看到OpenCV DNN 检测出了所有的脸，而 Dlib 的方法只有在大于某个 size 的时候才被检测出来。 我们测试后，脸大于 70×70 才能被 dlib检测出。正如在前面说到的，对小人脸检测是dlib方法的一个大的缺点。我们也可以将图片上采样，但这样的话速度的话相对于 OpenCV-DNN 就太慢了。 It can be seen that dlib based methods are able to detect faces of size upto ~(70×70) after which they fail to detect. As we discussed earlier, I think this is the major drawback of Dlib based methods. Since it is not possible to know the size of the face before-hand in most cases. We can get rid of this problem by upscaling the image, but then the speed advantage of dlib as compared to OpenCV-DNN goes away. 7.2. 非正脸Non-frontal Face 对于非正脸的测试，我们选用了 looking towards right, left, up, down。为了对 dlib 公平，我们选择了face 大于 80×80 的图片。下面是一些例子。 Non-frontal can be looking towards right, left, up, down. Again, to be fair with dlib, we make sure the face size is more than 80×80. Given below are some examples. 和预期的一样，OpenCV Haar 方法完全败了。Dlib HoG能检测出 left 或 right looking faces，但是精度不如那些DNN方法。 As expected, Haar based detector fails totally. HoG based detector does detect faces for left or right looking faces (since it was trained on them) but not as accurately as the DNN based detectors of OpenCV and Dlib. 7.3. 遮挡Occlusion 接下来看一下遮挡的情况。Let us see how well the methods perform under occlusion. 再一次看到，DNN方法比其他方法更优，OpenCV-DNN 比 Dlib-MMOD 还好一点。这是因为CNN 特征 比 HoG or Haar 更加鲁棒，稳定。 Again, the DNN methods outperform the other two, with OpenCV-DNN slightly better than Dlib-MMOD. This is mainly because the CNN features are much more robust than HoG or Haar features. 8. 总结我们讨论了每个方法的优缺点。个人建议使用 OpenCV-DNN 和 Dlib-HoG 在应用和设备成本权衡中。以下我们的建议： We had discussed the pros and cons of each method in the respective sections. I recommend to try both OpenCV-DNN and HoG methods for your application and decide accordingly. We share some tips to get started. 8.1 大多数的情况General Case 在多数场景中，我们提前不知道图片大小，因此 选用 OpenCV – DNN 相当快也很精确，甚至对于小人脸也不错，各种人脸角度也可以。选用这个在大多情况下是最优的。 In most applications, we won’t know the size of the face in the image before-hand. Thus, it is better to use OpenCV – DNN method as it is pretty fast and very accurate, even for small sized faces. It also detects faces at various angles. We recommend to use OpenCV-DNN in most 8.2 大小中等或大一点图片For medium to large image sizes Dlib HoG 在 cpu上是最快的一个方法。但是它不能检测出 face size (&lt; 70x70) 的图片。所以你得清楚使用的场景，比如自拍的话就可以。如果能使用GPU的话 dlib-MMOD 是一个最好的选择，因为它支持GPU，跑得也比较快，也能适应人脸的角度变化。 Dlib HoG is the fastest method on CPU. But it does not detect small sized faces (&lt; 70x70). So, if you know that your application will not be dealing with very small sized faces ( for example a selfie app ), then HoG based Face detector is a better option. Also, If you can use a GPU, then MMOD face detector is the best option as it is very fast on GPU and also provides detection at various angles. 8.3 高分辨率图像High resolution images 对于这些方法来说，高分辨图像都有点难度，计算时间比较长。可能采用的方法是resize图像 （ scale down the image），HoG / MMOD方法可能就识别不出了，但是可以使用 OpenCV-DNN 尝试一下。我认为也可以将图片分割开再识别呀，嘻嘻。 Since feeding high resolution images is not possible to these algorithms (for computation speed), HoG / MMOD detectors might fail when you scale down the image. On the other hand, OpenCV-DNN method can be used for these since it detects small faces. 有任何建议，欢迎在下面评论。Have any other suggestions? Please mention in the comments and we’ll update the post with them! 参考[FDDB Comparison code][Dlib Blog][dlib mmod python example][dlib mmod cpp example][OpenCV DNN Face detector][Haar Based Face Detector] TODOS文章作者是 VIKAS GUPTA 来，看看这个是站长大佬的图片，是不是很熟悉？膜拜一哈。 我订阅后文章后，作者发的邮件内容，并没有给文章页的代码。 给的Computer-Vision-Resources.pdf 作者的Dlib fork 重要资源 作者博客 link 作者的所有代码拿走不谢 link 翻译 代码运行 根据该作者的博客继续翻译，学习，向大佬致敬。]]></content>
      <categories>
        <category>博客转载</category>
        <category>cv</category>
      </categories>
      <tags>
        <tag>Face Detection</tag>
        <tag>OpenCV</tag>
        <tag>Dlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[希腊罗马神话]]></title>
    <url>%2Fpublic%2F2018%2F11%2F05%2Freadings%2FGods_stories%2F</url>
    <content type="text"><![CDATA[概要：古代希腊罗马神话。最近在看一些古代希腊罗马的神话故事，挺好玩的，记录一下。 起源在我电的图书馆的还书柜子里面偶然所得，一本叫《希腊罗马神话对英语语言文化的影响》吕海平 著 江苏大学初版社，然后莫名的想研究一下，发现挺不错的。 古希腊罗马的神的关系还是比较乱的，尤其是jupiter 或者zeus的奥林匹斯神系。从上古的神系，总共有三代。 网上有个人（Korwin Briggs）做的关系图很不错。后面我也会对其进行整理，以后给大家分享。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>神话</tag>
        <tag>希腊罗马神话</tag>
        <tag>语言文化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux代理的使用]]></title>
    <url>%2Fpublic%2F2018%2F07%2F24%2Flinux%2Flinux_proxy%2F</url>
    <content type="text"><![CDATA[最近要下载一个在youtube上的数据库，用来训练模型，由于下载比较慢，我选择了代理方式下载。shadowsocks和tsocks实现命令行的代理和一些常用小工具的代理。 本文以科学研究为目的，请勿滥用。 1. shadowsocksShadowsocks是一个轻量级socks5代理工具。 TIP:下面的ssserver和sslocal都在pip安装的shadowsocks包里面。 12345$ apt-get install python-pip$ pip install shadowsocks# 或者对于shadowsocksr$ pip install git+https://github.com/shadowsocks/shadowsocks.git@master 其他平台安装 参考 shadowsocks install 1.1 vps 配置 Shadowsocks server远程ssh连接到（Virtual Private Server）vps上，可以开个screen来执行ssserver -c server_shadowsocks.json 新建文件 server_shadowsocks.json 12345678910&#123; "server":"0.0.0.0", "server_port":443, "local_address": "127.0.0.1", "local_port":1080, "password":"密码", "timeout":300, "method":"aes-256-cfb", "fast_open": false&#125; 1.2 本地linux 配置 Shadowsocks client开个screen来执行sslocal -c client_shadowsocks.json，也可以使用-d 参数放在后台运行。更多见 archlinux Shadowsocks)sslocal -c client_shadowsocks.json -d start 新建文件 client_shadowsocks.json 1234567891011&#123; "server":"服务器ip或域名", "server_port":443, "local_address":"127.0.0.1", "local_port":1280, "password":"密码", "timeout":300, "method":"aes-256-cfb", "fast_open":false, "workers":1&#125; 2. tsockstsocks 是个给终端使用的类似于proxychains，它可以直接和shadowsocks的socks 5配置，配置较为简单。 linux安装tsocks 命令：apt install tsocksmac 安装参考 homebrew-tsocks 修改tsock配置文件：/etc/tsocks.conf 更改以下内容：/etc/tsocks.conf 1234local = 192.168.1.0/255.255.255.0server = 127.0.0.1server_type = 5server_port = 1080 3. 实用工具的代理使用3.1 tsocks 使用在所需代理的命令前加个tsocks就行，如：tsocks wget -c xxxx,tsocks axel -n 10 -av xxxx,tsocks curl xxx 3.2 youtube-dl 绑定proxyyoutube-dl是批量下载youtube视频的好工具。安装脚本 pip install --upgrade youtube-dl 一个down.sh脚本12URL=https://www.youtube.com/playlist?list=PLLbeS1kM6teJqdFzw1ICHfa4a1y0hg8Ax./youtube-dl --proxy socks5://127.0.0.1:1280 $&#123;URL&#125; youtube-dl待解决的问题？？我的任务是下载一个视频中的一部分，不用下载整个视频。太奢侈了，我的vpn的流量有限，还未找到解决办法，我找到的issue，忘有朋友会的指导一下。is it possible to download only desired time interval? 4. 出现的问题dns解析不了google.com1234567# 临时在 /etc/resolv.conf$ sudo echo &quot;nameserver 8.8.8.8&quot; &gt;&gt; /etc/resolv.conf# 永久 /etc/resolvconf/resolv.conf.d/head$ sudo echo &quot;nameserver 8.8.8.8&quot; &gt;&gt; /etc/resolvconf/resolv.conf.d/head# 更新 /etc/resolv.conf$ /etc/init.d/resolvconf restart 需要展示net相关信息1nmcli d show 这里对linux的网络修改并不太会参考 redlinux 的nmcli介绍。不要用nmcli配置网络，我发现用nmcli重启机器无法自动连接有线网络，最后还是去ubuntu的界面手动删除配置才可以。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>proxy代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bashrc与vimrc的配置]]></title>
    <url>%2Fpublic%2F2018%2F07%2F12%2Flinux%2Fbash_bashrc%2F</url>
    <content type="text"><![CDATA[概要：对于bashrc和vimrc的一些记录。 在cd ~下建立talen_bashrc文件1234567891011121314151617181920 HOME_BASHRC=xxxx/talen_bashrc alias vimbashrc=&apos;vim $HOME_BASHRC &amp;&amp; source $HOME_BASHRC&apos;# files alias countfiles=&apos;echo &quot;total num: &quot; &amp;&amp; ls | wc -l &amp;&amp; du -sh&apos; alias ll=&apos;ls -htrlF --time-style=&quot;+%H:%M %Y/%m/%d&quot;&apos; alias dum=&apos;du -a -d 1 -m |sort -nr&apos; alias dug=&apos;df -h /dev/sdbxxx &amp;&amp; du -BG -d 1 --time |sort -nr&apos; alias pi=&apos;pip install -i https://pypi.tuna.tsinghua.edu.cn/simple&apos; alias gpuwatch=&apos;watch -n 1 nvidia-smi&apos; alias gitm=&apos;git commit -m&apos; alias gits=&apos;git status -s&apos; export PYTHONPATH=$PYTHONPATH:xxxxxxx# vimrc export MYVIMRC=xxxx/.vim/.vimrc export VIMINIT=&quot;let &amp;rtp=&apos;xxxx/.vim,&apos; . &amp;rtp so $MYVIMRC&quot; 对于anaconda虚拟环境的激活在~/.bashrc中加入12alias talen=&apos;source xxx/talen_bashrc &amp;&amp; source activate xxx/envs&apos;alias utalen=&apos;source deactivate&apos; github bashrc 其他的vimrc配置见我的github项目vimrc]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Bashrc</tag>
        <tag>Vimrc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jupyter notebook的配置]]></title>
    <url>%2Fpublic%2F2017%2F07%2F03%2Flinux%2Fjupyter_notebook%2F</url>
    <content type="text"><![CDATA[概要：jupyter notebook的安装 1. 安装与配置安装jupyter12conda install jupyter# pip install jupyter -y 配置文件修改123# 生成配置文件jupyter notebook --generate-configvim ~/.jupyter/jupyter_notebook_config.py 修改配置文件里面的对应内容 1234c.NotebookApp.ip = '*'c.NotebookApp.port = 8018# 设置密码c.NotebookApp.password = u'sha1:bcd259ccf...your hashed password here' Tip: 利用ipython 生成密码123456&gt; In [1]: from IPython.lib import passwd&gt; In [2]: passwd()&gt; Enter password:&gt; Verify password:&gt; Out[2]: &apos;sha1:67xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&apos;&gt; 此处我选用的是一个密码的方案，jupyter的密码其他设置方案见 link 安装插件 nbextensionsnbextensions是对于jupyter notebook 的一些插件，有很多有趣的插件，我选用了几个。jupyter_contrib_nbextensions github 12345678# 用conda安装conda install jupyterconda install -c conda-forge jupyter_contrib_nbextensions# pip安装pip install jupyter_contrib_nbextensions --user# 使能jupyter contrib nbextension install --user 我启用的一些插件 plugins Table of Contents (2) Freeze 比较好的一个插件，可以用来冻住cell nbTranslate 这个插件利用Google翻译cell很好用 support languages ExecuteTime 显示执行时间 2. 使用的技巧2.1 基本操作快捷键 在非激活状态即是蓝颜色的边框 内容 A insert cell above B insert cell below H 查看帮助 ⌃↩(ctrl + enter) run selected cells 2.2 技巧主要是画图、显示视频和音频的方法。 12345678910111213141516171819# 图片%%HTML&lt;img src="xxx.jpg" alt="title" /&gt;# 视频%%HTML&lt;video width="330" height="150" controls&gt;&lt;source src="out_all.mp4" type="video/mp4"&gt;&lt;/video&gt;# 语音%%HTML&lt;audio src="out.wav" controls="controls"&gt;Your browser does not support the audio element.&lt;/audio&gt;# html t是html的字符串from IPython.core.display import HTMLHTML(str(t)) 2.3 其他技巧修复视频文件1234567def fix_use_ffmpeg(in_name, out_name,message=""): import os if os.path.isfile(out_name): os.remove(out_name) cmd = 'ffmpeg -i %s %s' % (in_name, out_name) log_lines = os.popen(cmd).readlines() print(message,"ok") 加载自己的模块文件出于性能考虑，每个模块在每个解释器会话中只导入一遍。因此，如果你修改了你的模块，需要重启解释器；或者，如果你就是想交互式的测试这么一个模块，可以用 imp.reload() 重新加载，例如 import imp; imp.reload(modulename) 导出pdf支持中文Jupyter Notebook 输出PDF中文支持 link 12345cd /usr/local/lib/python3.6/site-packages/nbconvert/templates/latex# 在里面的模版中添加，前提是安装好了texlive% add\usepackage&#123;ctex&#125;]]></content>
      <categories>
        <category>Jupyter</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Notebook</tag>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu引导修复]]></title>
    <url>%2Fpublic%2F2017%2F06%2F14%2Flinux%2Fboot_recovery%2F</url>
    <content type="text"><![CDATA[概要：修复ubuntu引导，修改ubuntu盘的大小参考：http://www.cnblogs.com/jloveu/p/Ubuntu-partition-expansion-record.html我直接用Ubuntu live，里面自带gparted分区工具，还有grub修复工具 修复启动执行以下命令（以root身份）：123456789mkdir /tmp/mydirmount /dev/sda8 /tmp/mydir (注：其中的`/dev/sda8`为我的`/`分区标识，根据自己情况修改为自己的`/`分区标识)mount /dev/sda11 /tmp/mydir/boot (注：同上，`/dev/sda11`为`/boot`分区标识)mount --bind /dev /tmp/mydir/devmount --bind /proc /tmp/mydir/procmount --bind /sys /tmp/mydir/syschroot /tmp/mydir (此步可能输出一些信息，可以无视)grub-install /dev/sda (注：其中的`/dev/sda`为`/`分区所在硬盘的标识)exit 修改Ubuntu多系统的默认启动顺序link打开该配置文件”/etc/default/grub”1sudo vim /etc/default/grub 其中的“GRUB_DEFAULT=0”为设置默认启动项。系统启动菜单Windows10的启动项在第5项，修改为4（GRUB启动项是从0开始的）。 去除多余GRUB启动项（直接）link注释掉“/boot/grub/grub.cfg”中对应1sudo gedit /boot/grub/grub.cfg]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>BootRecovery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu的优化与设置]]></title>
    <url>%2Fpublic%2F2017%2F05%2F22%2Flinux%2Fubuntu%2F</url>
    <content type="text"><![CDATA[概要：本文整理了一下我在使用ubuntu过程中的一些小技巧。一个好的Ubuntu教程.原文链接Linux有很多分支，Ubuntu的使用安装比较方便.Ubuntu 16.04 LTS 1.个性化窗口颜色设置浅绿色窗口编程浅绿色 link12cd /usr/share/themes/Ambiance/gtk-3.0sudo gedit gtk-main.css 编辑该文件,将base_color #ffffff修改成 #CCE8CF对应RGB 48,19,36 2. 常用环境安装jdk打开文件 vim ~/.bashrc，在文件后面添加下面几行，其中JAVA_HOME根据自己的java安装位置修改。12345# add java pathexport JAVA_HOME=/usr/local/java/jdk1.7export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 别忘了，source ~/.bashrc激活环境 3. 安装软件在线软件安装源列表地址修改(可选)，如果选用靠近的源速度会比较快，但是可能不是最新的软件。现在好像ubuntu china的官方节点速度还不错。1234# 备份源列表地址sudo cp /etc/apt/sources.list /etc/apt/sources.list_backup# 修改sudo vim /etc/apt/sources.list 在线安装123456# 更新源apt-get updateapt-get install xxx# 包searchapt-cache search xxx deb本地软件安装安装软件12345# 安装deb包命令dpkg -i *.deb# 如果缺少依赖执行apt-get -f install 4. 常用软件mpv播放器有道字典有道字典 需要修改一下才能使用。 link atom高分屏字体大小，Settings-&gt;Themes-&gt;your stylesheet123456atom-pane &#123; font-size: 16px; &#125; .command-palette &#123; font-size: 16px; &#125; 图标设置对于一些绿化软件来说没有图标，我们可以手动创建一个图标。在/usr/share/applications目录下创建eclipse启动器配置文件 12cd /usr/share/applicationsvim eclipse.desktop 编辑eclipse.desktop并保存。简单的配置示例：12345678910#!/usr/bin/env xdg-open[Desktop Entry]Version=22.0Name=eclipseExec=/home/gtc/Android/adt-bundle-linux/eclipse/eclipseTerminal=falseIcon=/home/gtc/Android/adt-bundle-linux/eclipse/icon.xpmType=ApplicationCategories=Development 5. 其他优化关闭错误报告12# 关闭烦人的错误报告sudo gedit /etc/default/apport CPU 100%占用gvfsd-smb-browse CPU 100%占用我没有修改，它就自己停了，可以在mointer里中止这个进程地址http://tieba.baidu.com/p/4505730863 123cd /usr/lib/gvfs# 将gvfsd-smb-brows权限改成744，取消普通用户的执行权限，# 也挺有意思，暂时没引发别的问题]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红楼梦与我]]></title>
    <url>%2Fpublic%2F2017%2F05%2F14%2Freadings%2Fhongloumeng%2F</url>
    <content type="text"><![CDATA[红楼梦是我国四大名著之一，主要内容是贾府的兴衰和宝黛的悲剧爱情。电视剧红楼梦2010版，我是从八月开始看的，看完到现在，也有小一个月了。在网上大家对这版电视剧褒贬不一。与我来说，我是喜欢这部剧的，不能说拍得很好，但这部剧却勾起了我读书与写字的兴趣。于是乎，做了一篇随笔，以记录我的一些感触。 我记得最早是小学，我们还是顾着打玻璃珠和丢沙包的年纪，学校旁边的小书店里，也都是七龙珠，哆啦A梦，柯南的小人书，老师们讲到四大名著，顺带提了下红楼梦，其他没印象了。我们学习最多的是中文的拼音和书写，作文都是打油，日记也闹了不少笑话。后来上初中，有一次寒假附加作业是阅读红楼梦，我虽毫无兴趣，但还是硬着头皮，去新华书店，试看红楼梦。120章的红楼，厚得连看下去的勇气也没有。略看了几下，最后，做了一个红楼梦不好看的论断，也就放在那边了。那时有老版的红楼梦电视剧播映，打开电视偶尔会遇见，但是立马换台，央视的西游记与情深深雨蒙蒙，湖南电视台的还珠格格，也是欣赏了好几遍。再者，有动画片谁有兴趣去看这些什么破剧，关于书本，最多也就是看看汤姆索亚历险记。 再后来，去启中读书，学习上比较紧张，再加上理科班的非文学氛围，对这些文学的东西更不感冒。尽管偶尔也会入耳一些其中的人物，比如林妹妹，刘姥姥，也是不用大脑耳朵直接过滤。当时，大伙是杂志，读者，青年文摘读得比较多，班上一本，全班查阅，杂志文章篇幅较小，读起很顺很舒服。期间，与红楼的唯一一次接触是，高中教科书上有刘姥姥进大观园的章节，翻了一遍，当时，感叹人物好多，理不出人物关系，完全放弃看完红楼的欲望。以为姥姥是贾府的姥姥，猩猩然想着以后可以说看过一段红楼，红楼也比较贵不如多买几本读者，积累作文素材。不知什么时候，班上网络小说之风随着mp4和智能手机的普及而吹起，我也用MP4刷完了一两部网络小说，感觉都是一个套路，主角都是绝处逢生，越来越无敌，也就不敢兴趣了。 再然后，我上大学，藏书400百万册的成电图书馆，也并没有引起我读文学类的欲望，大学四年借的专业工具类书比较多，想来也是浪费资源。在一个工科高校，文学方面的课程几乎没有，虽说有个大学语文的选修课，俨然不感兴趣。大学里，再一次看到有人在看红楼梦电视剧，也是大二的时候的人工智能课上，也是闲得无聊。再后来，大四时，手机上自带一个蜻蜓网络电台应用，无聊点开蒋勋老师评述的红楼梦音频，红学大师讲到他与红楼梦的相遇，同时，他介绍的红楼基本背景和人物，通俗易懂，一下子引起我的兴趣。他说红楼梦写的都是15、6岁人的故事，15、16岁就可以读了。回想我15、16岁，基本没看什么名著。要说四大名著，我也就看了三国和水浒的少年版。上次回家，看美剧，老妈突然蹦出句，不能光看英文也应当看看我们老祖宗的文化。 现在得空，就这样抱着惭愧和一丝尝试我看起了2010版红楼梦。在这我得承认，我是个演员控。不得不说，三大主演都很不错。 50集过后，原来红楼讲得是这个，并表示有兴趣去读读名著了。原来有这么多原来。 人物家族命运令人感慨。作者写出超越那个时代的朦胧的爱情与不得不提的丧心病狂的全部悲剧，果然是个失意文人的作品。 可叹停机德，堪怜咏絮才。宝钗落落大方德才兼备，黛玉因情而伤而痛去世，宝玉虽与宝钗结婚，最后离家成道去。精于人情世故,，胸有城府的王熙凤，平日的爽朗笑声终究悲剧，贾府里多么好的领导，最后也人情冷暖，不免为其伤心。刘姥姥，其实是个成功的投机分子，但也是朴实善良的“穷亲戚”，最后救了巧儿。十二金钗各有个的悲剧，正如宝玉在虚幻仙境里警幻仙姑给的设定。原来故事一开始就把结局告诉了读者。 体验古代贵族文化。里面还有个诗社的组织，古人的结社，好有雅致，也会给人起“绰号”。除此以外还有击鼓传花，有时主题是讲笑话有时对诗。猜灯谜，中秋赏月，生日宴会等等。 语言魅力。打秋风，这是形容刘姥姥找找贾府接济用的。恼，生气，或者使生气。不同人的称谓，宝兄弟，宝二爷，宝姐姐或者好姐姐，林妹妹或者好妹妹。 情节回味无穷。刘姥姥进大观园，是贾母和姥姥差不多年纪想和她聊聊，邀请她的。乡村来打秋风的刘姥姥像是在参观皇宫。在后面时期 ，家族里一次比一次捉襟见肘的聚会，可以看见这些家族的衰落。中国的各种人情世故体现在这里面。四个大家族，一个小社会。 以上是我的一点点感悟。 只是，我与红楼梦，还差80章书页，希望还能有计划地读完。 2016年于成电]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>故事</tag>
        <tag>《红楼梦》</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数学问题 - 一个空间解析几何问题]]></title>
    <url>%2Fpublic%2F2017%2F05%2F05%2Fmath%2Fmath_q1%2F</url>
    <content type="text"><![CDATA[概要：一个数学问题，我有空试着练习一下，顺便练习一下Latex输入公式。如果有错误或更好的解答，欢迎在下面回复。 问题为什么会经过这个空隙？ 解答首先建立空间直角坐标系，$P$ 点为水平杆与斜杆的交点，$Q$点为垂直杆与水平杆的交点，将斜杆标记为 $L$，假设 $OQ=q$ ，$QP=r$ 。 设水平杆 $ QP $ 绕 $ z $ 轴以 $ \omega\, rad/s $ 的角速度旋转，并设开始旋转的时间长度为$t$ 秒，则$ P(r\cos{\omega t}, r\sin{\omega t}, q) $ $$ \overrightarrow{OQ}=(0, 0, q) \qquad \overrightarrow{QP}=(r\cos{\omega t}, r\sin{\omega t}, 0)$$ 我们知道 $\overrightarrow{QP}$ 与斜杆 $L$ 垂直，假设 $\overrightarrow{OQ}$ 与斜杆 $L$ 成固定角 $\theta$ ，设 $L$ 的方向向量 $\overrightarrow{s}=(A, B, C)$ 斜杆 $L$ 代表的直线：$$\frac{x-r\cos{\omega t}}{A}=\frac{y-r\sin{\omega t}}{B}=\frac{z-q}{C}$$ $$\begin{cases}0=\overrightarrow{QP} \cdot \overrightarrow{s} \\\cos{\theta}=\frac{\overrightarrow{OQ} \cdot \overrightarrow{s}}{\left|\overrightarrow{OQ}\right| \left| \overrightarrow{s}\right|}\end{cases}$$ $$\frac{A}{C}=\frac{-\sin{\omega t}}{\cos{\omega t}}$$ $$B^{2}(\tan{\theta})^{2}=A^{2}+C^{2}$$ $$ \frac{B^{2}}{C^{2}}=\frac{1}{(\tan{\theta})^{2}(\cos{\omega t})^{2}} $$ 为了求直线组$L$与$xoy$平面相交的图形，我们令$z=0$$$ \frac{x-r\cos{\omega t}}{A}=\frac{y-q}{B}=\frac{-r\sin{\omega t}}{C} $$ $$ \begin{cases}\frac{A}{C}=\frac{1}{(\tan{\theta})^{2}(\cos{\omega t})^{2}}\\\frac{x-r\cos{\omega t}}{A}=\frac{-r\sin{\omega t}}{C}\end{cases} $$ $$ \cos{tx}=r $$ $$ (\cos{\omega t})^{2}=\frac{r^{2}}{x^{2}} $$ $$ (\sin{\omega t})^{2}=\frac{x^{2}-r^{2}}{x^{2}} $$ $$ \begin{cases}\frac{B^{2}}{C^{2}}=\frac{1}{(\tan{\theta})^{2}(\cos{\omega t})^{2}}\\\frac{y-q}{B}=\frac{-r\sin{\omega t}}{C}\end{cases} $$ 消去 $ (\cos{\omega t})^{2} $ 和 $ (\sin{\omega t})^{2} $得 $ x^{2}-(\tan{\theta})^{2}(y-q)^{2}=r^{2} $易知为双曲线方程，所以在 $ xoy $ 平面相交得图形为双曲线。]]></content>
      <categories>
        <category>数学问题</category>
      </categories>
      <tags>
        <tag>空间解析几何</tag>
        <tag>Latex</tag>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[琉璃易碎，人言易坠——关于《莺莺传》的叙事]]></title>
    <url>%2Fpublic%2F2017%2F04%2F14%2Freadings%2Fyingyingzhuan%2F</url>
    <content type="text"><![CDATA[《西厢记》的书评:【琉璃易碎，人言易坠——关于《莺莺传》的叙事】转载…全文:(豆瓣link) “半欲天明半未明，醉闻花气睡闻莺。 狌儿撼起钟声动，二十年来晓寺情。 ”男人四十的元微之写着酸酸的诗，回忆年少风流。假如我是元微之，我一定会这般写道：天空尚未亮透，微微透着点光，远处传来钟声，让我的思绪一下子回忆到二十年前，也是这样的一个早晨，在那所古寺的西厢，那个散发着鲜花一样香气的女子，用鸟儿般宛转的声音在我耳边低语：“钟声响了，想来我也该回去了。”那声音一直萦绕在耳边，十年、二十年、也许一辈子在我在记忆深处响起……。 夜宿古刹，偶遇佳人，相伴遥夜，缠绵缱绻，天明而别。这样的际遇，是最最典型的古代书生的爱情幻想。在一个陌生的地方，遇到一个陌生人，发生一段有始无终的感情。书生注定要做个过客，一生漂泊在对那个女子的思念中，却没有勇气长相守。 当我还是一个初中生的时候，我买来人民文学出版社的《西厢记》，上面盖本教科书，堂而皇之的上课看。但是很快，除了王实甫那华丽的辞藻，整个大团圆的故事构架让我兴趣索然，而前言里现代人给它冠上的什么“礼教叛逆者反抗封建卫道士”的宏大内涵更让我倒尽胃口。 在书后还附着元稹的《莺莺传》。《莺莺传》所描写的其实只是两个人的故事，两个恋爱的人后来分开的故事，没有太宏大的叙事，没有那些官腔的说教和露骨的批判。这样的故事是我所喜的；这样的故事，也是中国文人所津津乐道的。关于类似内容的作品也就汗牛充栋，数不胜数。或许从《诗经》的“氓之蚩蚩，抱布贸丝”开始，就没有谁打算给自己的爱情故事赋予太宏大的命题，只是后来的人突然犯失心疯，发现了字里行间的微言大义。所以我很景仰孔夫子他老人家，他的《论语》里每一个字都可以养活一大批的圣贤大师。 元稹的这篇传奇被人考据出是以自己为原型的故事，是一篇忏悔录。忏悔的味道我闻不出来，但是众前辈大师言之凿凿说张生便是元大才子，那我也就相信了罢。 《莺莺传》的开头，交代道“在贞元年间，有位张生，他性格温和而富有感情，风度潇洒，容貌漂亮，意志坚强，脾气孤僻”。古人向来有画脸谱的习惯，只要不是丑的太离谱，一般的名士贤臣都被描写成“性温茂，美风容”之类。但是据说元稹的家族是著名的鲜卑拓跋，鲜卑人的美貌是相当出名的，就好象现在说日本人长的猥亵一样出名，所以我有理由相信，元稹在这点上也许没有吹牛。 文章写道“以是年二十三，未尝近女色”，后面他自己解释道“登徒子非好色者，是有凶行；余真好色者，而适不我值。何以言之？大凡物之尤者，未尝不留连于心，是知其非忘情者也”，就仿佛现在的大学男生在卧谈会上被迫承认自己二十三岁高龄还是个处男，被人取笑之下只好解释“其实我哪里是没能力啊，我只是没遇到真正让我心动的；一般的庸脂俗粉我看不上眼，要是真有出类拔萃的，我也会追的。我是谈感情的，和你们玩肉体的垃圾是不一样的”诸如此类。但是考察元稹的家庭情况，他八岁丧父，在家族里又被同父异母的兄弟欺凌，从小随着母亲投奔舅氏，生活贫困，母亲教她念书。我们可以想象，一个幼年便寄人篱下，遭受贫困欺凌的味道，他只比林黛玉多了一个母亲而已，但是林黛玉在物质生活上绝对比他适意。我们的脑海里可以浮现这样一个人物性格：幼年丧父的人，对于男人所称道的齐家治国平天下之类的宏伟功名有着不同于常人的热情和执著，范仲淹就是很好的例子，所以元稹在事业上一直很上进努力，为达目的不惜代价不择手段，由于尝尽人情冷暖世态炎凉，他很敏感，这样的人物让我想到了《红与黑》里的主人公于连；他自幼由一个母亲抚养成人，一般这样的人具有恋母情结，对于女性有异于常人的喜好，所以他的性格里又有滥情懦弱的一面。多情和薄幸，坚毅和懦弱，正义和无耻都矛盾地体现在他身上，这也就能让我们更好的理解他后来为了追求功名而抛弃莺莺的举动了。由于家境贫寒，极端律己，自卑和敏感的元微之“内秉坚孤，非礼不可入”，就算偶尔参加朋友一起的游宴——古人的游宴和现在去歌舞厅唱歌跳舞一样，一般都安排了色情服务——“扰杂其间，他人皆汹汹拳拳，若将不及”，而他“容顺而已，终不能乱”。我不清楚他是不是冬天还要帮别人洗衣服赚钱，但是可以肯定他不会参与打牌这样不合礼仪的活动，所以也就不会有谁去污蔑他打牌作弊，不会有“樗蒲不胜，槌杀四生”的惨剧了。 在这里他第一次提到“物之尤者”，后面他还有段很著名的话也提到“尤物”，为自己抛弃莺莺的行为做解释“大凡天之所命尤物也，不妖其身，必妖于人”。如此看来，仿佛我们的元大才子是个叶公好龙式的人物，这边在说假如能遇到尤物一定会动真情，那边厢却在说尤物不害她自身，必定祸害他人。没有得到的时候千方百计的追求，到手以后又不迭地甩掉去追求新的目标。人总是这样矛盾的动物，永远不明白自己所追求的到底是什么。我们知道最后元稹娶了豪门韦家的女儿为妻，使得他在仕途平步青云。于此，我们不妨看成是理智和情欲的对立，一边是代表事业投机的豪门韦家联姻的机会，而一边只是爱过的漂亮的女子，理智告诉他应该离开那个女子，但是情欲却欲罢不能，但是最后我们知道理智战胜了情欲，感情只好盘踞在文字里去凭吊，所以元微之为我们贡献了很多首脍炙人口的情诗。 后来，张生，也就是元稹路过蒲州，搭救了寄住在普救寺的崔家寡妇一家。“是岁，浑瑊薨于蒲，有中人丁文雅，不善于军，军人因丧而扰，大掠蒲人。……先是张与蒲将之党有善，请吏护之，遂不及于难。十余日，廉使杜确将天子命以总戎节，令于军，军由是戢。”据《旧唐书·德宗纪》，贞元十五年十二月，河中绛州节度使浑瑊卒，以同州刺史杜确为河中尹、河中绛州观察使。元稹在贞元九年举明经科，并于贞元十五年在河中府任卑职，所以他和蒲将之党有交情，打个招呼关照一下也在情理之中；但据唐代举士制度，士之及第者还需要经过吏部考试才能正式任命官职，所以我们可以推测出在贞元十五年年底的时候，元稹便上路去长安应考，于是在蒲州遇上了莺莺一家。 我们知道这篇传奇是有虚构的成分，就如元稹在里边成了张君瑞，但是有一点细节仍然需要注意的，就是莺莺家族的姓氏。在唐朝时候，年轻人普遍的梦想有两个，金榜题名，娶七姓女；就如同现在的大学生的梦想，考上公务员，讨个有钱人做老婆。娶个有钱人做老婆可以少奋斗十年，这是基于现实利益的考量，而娶七姓女等于瞬间提升了自身家族的社会层次，也是基于现实利益的考量。在中国人的现实生活里，找不到“爱情”这两个字–有时候看历史真的会看到掩卷叹息，中国人过了几千年，还是一点长进都没有啊。唐代的士族世家已经逐渐没落，但是依然地位显赫，其中以陇西李氏、太原王氏、荥阳郑氏、范阳卢氏、清河崔氏、博陵崔氏、赵郡李氏等七姓十族最为著名，一般这些世家大族互为婚姻，自惜羽毛。唐高宗时宰相李义府为子向山东士族求婚不遂，而向朝廷建议禁止七姓十族自为婚姻。可见娶个望族女子为妻，是多么的艰难啊。莺莺是姓崔的，而且“财产甚厚，多奴仆”，很自然的就联想到了清河崔氏、博陵崔氏这些世家大族；但是很奇怪的是元稹描写的张生居然抛弃了莺莺，一个出身寒族的士子抛弃了一个那么美貌温柔的世家女子，仅仅只为了他自己所谓的“予之德不足以胜妖孽，是用忍情”么？考察元某人在政治上趋炎附势的态度，我是不相信他冠冕堂皇的话的。姑且让我用自己邪恶的想法去揣测他：那个被唤作莺莺的女子必定不是什么世家望族，所以元稹为了前途而抛弃了她，之所以故意写成崔氏，只是制造了一种假象，让读者有个印象那个莺莺是世家女子，我元微之离开她只是因为好男儿不该沉溺于爱情，你看为了理想我连世家女都放弃了啊。这便是文人的下作！ 为了答谢这位刚认的远亲的救命之恩，于是请吃饭，贞元十五年十二月很快就在危机中渡过，这顿饭的时间也应该在贞元十六年的春天。当贞元十五年的大门“咣当”一声关掉，命运就载着我们的主人公来到了贞元十六年。饭局中张生曾问莺莺的年纪，“郑曰：‘今天子甲子岁之七月，终今贞元庚辰，生年十七矣。’”贞元庚辰，正是贞元十六年，那年元稹二十二岁，莺莺十七岁。 拿破仑指示说“请客的菜一定要好”，这个世间有好多的阴谋和决策在餐桌上议定，有好多缠绵或者惨烈的故事由餐桌上发端。郑国的子宋因为吃饭的时候分不到王八汤，结果一怒就干掉了郑灵公；而我们的张生，也就是元微之同学因为吃饭认识了莺莺姑娘。这表明吃饭是一次冒险，运气好的可以吃出一段情缘，运气不好的就要丢了性命，所以列位正要去吃饭相亲的同学们，你们要小心啊。 吃饭的时候，郑氏让儿子、女儿出来拜会救命恩人。那时侯未出阁的女子特别是大户人家的女子仿佛家之重宝，秘不见人；而郑氏却突然在一个年轻的刚认识不久的远房亲戚面前把女儿拉出来亮相，还要陪吃饭，哪怕这个年轻是救命恩人，这样的行为也是很突兀的，所以莺莺才会推三阻四的不想出来见面。郑氏这般的举动连一千多年后的我也想入非非，无疑也给了元稹兄弟很多假设的可能。不论当初的郑氏出于什么样的考虑做了这个决定，反正莺莺姑娘就此登场了。第一次召唤推说有疾，郑氏看起来很生气的说“张兄保尔之命，不然，尔且掳矣，能复远嫌乎”，这其中的话外之音，只能读者自己体会了。又过了很久，莺莺终于出场了。 “常服睟容，不加新饰，垂鬟接黛，双脸销红而已。颜色艳异，光辉动人”，简直惊为天人啊。我们很可以理解元稹的心情，在记忆里，那个已经离开的初恋情人总是最美丽的，而那第一次的见面总是浪漫得无法言说，第一眼里情人的样貌也是美艳不可方物。但是假如当时有照相的话，看到莺莺的照片也许你会失望，那个时代普遍流行的美女的体态是肥胖丰满的，那个时代美女的画像普遍有双下巴（有些是三下巴或者更多），面颊鼓鼓外凸，因为胖所以嘴巴也被挤的小小的嘟起来，实乃人间惨剧，竟无语凝噎！幸好莺莺不加新饰，保持了一点自然状态，否则那个惨白的面容、用红颜料描出的樱桃小嘴、脸上贴的花状的金钿和浓晕蛾翅眉足足可以把你吓死。 后面一句话很有意思：“张惊，为之礼。”张生看到莺莺那么漂亮，忙起来对她行礼。这个描写很传神，一般男子看到普通的女子，都保持一点点的风度，淡淡的仿佛视若不见；惟独见到美女，眼睛一亮，慌忙起身行礼，态度谦恭。足见莺莺之美。后来她坐到郑氏旁边，因为是郑氏强迫她出见的，所以她“凝睇怨绝，若不胜其体者”，那个样子就是《喜剧之王》里张柏芝所谓的“鹌鹑状”。如此楚楚动人的姿势，叫张生魂不守舍。问了年纪，只有十七岁，正是花季过后，果季之前，鲜脆欲滴，天真纯情的年纪啊！张生想和她找话题说话，但是莺莺就是不理睬他，一直到吃完饭也没有什么好说的。记得以前去参加一个朋友生日活动，饭桌遇上了朋友的表妹，也是一样的年轻明艳，也是一样的不理睬人，和她搭讪也装做没听见，搞得我们很没有面子，所以说，古往今来的好女孩一般都是很矜持的。由于没有机会接触，张生的思念就象潮水一样把他包围，所以他捉摸着要找个机会表白一下。 于是他从莺莺的小伙伴，侍女红娘那边入手。这个策略在以后的无数次实践当中被证明是极端正确的。大学里你要追求某个女生，先要从她寝室的室友下手，打通所有关节，请他们吃喝玩乐，最后那个女孩子身边所有的朋友都在说你好话，那你就成功一大半了。红娘被张生吓了一跳，问了个问题：“你既然那么喜欢，何不凭借你对我们家的恩情向夫人正式提亲呢（何不因其德而求娶焉）？”张生回答的话简直有点无耻了：“我从孩童时候起，性情就不随便附合。有时和妇女们在一起，也不曾看过谁。当年不肯做的事，如今到底还是在习惯上做不来。昨天在宴会上，我几乎不能控制自己。这几天来，走路忘了到什么地方去，吃饭也感觉不出饱还是没饱。恐怕过不了早晚，我就会因相思而死了。如果通过媒人去娶亲，又要‘纳采’，又要‘问名’，手续多得很，少说也得三四个月，那时恐我也就不会在人世了。你说我该怎么办呢？（余始自孩提，性不苟合。或时纨绮闲居，曾莫流盼。不为当年，终有所蔽。昨日一席间，几不自持。数日来，行忘止，食忘饱，恐不能逾旦暮。若因媒氏而娶，纳采问名，则三数月间，索我于枯鱼之肆矣。尔其谓我何？）”先吹捧自己性格不随便，然后表明见到莺莺姑娘连这样的性情也抛掉了，再不快点接近自己，就挂掉了，哪有时间挺到纳采问名啊。我从来不知道爱一个人，居然连三四个月都无法等待，这是赤裸裸的情欲，而非爱情；张生的第一目标是得到莺莺，而非和她相爱。情欲是正常的，但是不正常的是张生光明正大的以自己的情欲作为接近的借口，在一套绚丽机巧的辞藻下，其实裹挟着的不过是阿Q对吴妈的那句“我要跟你困觉”！ 但是也许张生妇女工作做的好，红娘还真的帮他出主意，让他摇动笔杆。想来那时躲在深闺的大家闺秀并不知道外边文青的名声有多臭，结果一场悲剧上演了。 亚里士多德《诗学》言道：“性格为悲剧六大要素之一。”毫无疑问，莺莺的性格决定了她的悲剧结局。在她的身上我们看到矜持和热情，顺从和叛逆，坚定和认命矛盾的结合在了一起。前面我们已经注意到莺莺出场时的矜持，和在她母亲召唤下不肯出来见面的叛逆，但是当她看了张生的情诗之后却用那首暧昧的《明月三五夜》作为回应，把张生招来相见。“待月西厢下，迎风户半开。拂墙花影动，疑是玉人来。”这诗不论莺莺怎么强调“犹惧兄之见难,是用鄙靡之词，以求其必至”,都无法掩盖字里行间的情意和期盼。 二月十五的晚上，月亮大的吓人,文学青年元稹踏着美丽的月色，攀着墙边的杏花树翻过墙头投奔他的初恋去了。他来到西厢房,却只看到红娘躺在床上，双方都很奇怪。在红娘通报后，莺莺姑娘这才出现了。可能原本元大才子准备着类似“长夜漫漫，无心睡眠，没想到莺莺姑娘你也睡不着”之类的桥段，可是如此以来完全用不上了，而且莺莺姑娘一身包裹严实，表情严肃，狠狠地训斥了他一顿，然后扬长而去。元大才子只好承认都是月亮惹的祸，那样的月色太美太温柔，于是绝望了。元稹没有写他失恋后寻死觅活，更不像他自己说的“索之于枯鱼之肆”。但是很吊诡的是三天后莺莺就自荐枕席了。鉴于这段情节的突兀，《董解元西厢记诸宫调》里就设计了张生患相思病，莺莺探病的情节，王实甫也继承发扬了这段情节。这段情节看似让整个的故事情节更加合理，也让人物性格和心理有一定的起承转合，但其实是画蛇添足的一笔。 莺莺是一个性格矛盾的人，她对待未知的将来既期待又恐惧，她知道自己所做的是不容于世的，但是她对于爱情满怀憧憬而渴望冒险。在爱情的冲动下，她一步步滑向张生的怀抱。也许从第一次出来见这个救命恩人的时候，她便已经心存好感，起码我们知道张生的相貌世让人赏心悦目，这是爱情的基础；当看到张生的两首诗，更加倾慕于他。唐代的女孩子也和现在的女孩子一样，有自己心目中的白马王子。也许那个时代比较流行的梦中情人形象，就是元稹这样的才子。于是她情不自禁回了一首诗，也许只是想见他一面，但是理智告诉她这样做法的危险性。也许在红娘去通报的时候，她还在那里犹豫到底要不要去见。最后她决定去看一眼那个自己衷情的男子，她穿戴齐整。当爱上一个男人的女子，在那个男人面前总是很低很低,低到尘埃里,尘埃里便开出花来，于是她潜意识的想保持自己的尊严，她不想被他看成是轻薄的女子。她终于见到了他，在月色下，俊朗的男子期盼地看着自己，眼神顾盼之间，让人心旌摇荡；那淡淡的笑容，刚毅的嘴角，也许随着那夜的月色一起留在莺莺地记忆深处。她发觉自己陷入一种前所未有的危机，一种爱上别人为了那男子可以不顾一切的冲动，于是她板下脸来，义正词严地拒绝了那个男子。“非礼之动，能不愧心？特愿以礼自持，毋及于乱！”这些话在我看来倒有一大半是在对自己萌动的心说的，莺莺在警告自己不要逾越了礼，否则将万劫不复。男子一脸地失望，仿佛满地月光都成了严霜。她还是转身离去。但是正如元稹在《会真诗》里所写的“戏调初微拒，柔情已暗通”。我不知道莺莺在这三天里是如何地心情，我也不知道其中红娘起了多大地作用，但是我知道到了十八日的晚上，莺莺终于做了自己一生中最重要的决定。 “数夕，张生临轩独寝，忽有人觉之。惊骇而起，则红娘敛衾携枕而至，抚张曰：‘至矣！至矣！睡何为哉！’并枕重衾而去。张生拭目危坐久之，犹疑梦寐；然而修谨以俟。俄而红娘捧崔氏而至。至，则娇羞融冶，力不能运支体，曩时端庄，不复同矣。是夕，旬有八日也。斜月晶莹，幽辉半床。”唐贞元十六年二月十八日的夜晚，那一夜的经历对于元稹来说是如此的深刻，以至于很久以后依然清楚的记得那天的日期，那夜的月色。元稹在《会真诗》里清楚地描写了缠绵的经过，在千年之后的人们看来，那诗依然写得香艳露骨，荡人心旌：“微月透帘栊，萤光度碧空；遥天初缥缈，低树渐葱茏……低鬟蝉影动，回步玉尘蒙；转面流花雪，登床抱绮丛；鸳鸯交颈舞，翡翠合欢笼；眉黛羞频聚，朱唇暖更融；气清兰蕊馥，肤润玉肌丰；无力慵移腕，多娇爱敛躬；汗光珠点点，发乱绿松松……”。在晶莹的斜月下，天真善良的莺莺投奔了爱情，为了自己心爱的男子，为了梦想中的爱情，抛弃了一切，奉献了一切。也许古往今来有很多的人有这般的经历，曾经真心单纯地去爱一个人，为他（她）付出了一切。不管结果如何，起码在那一刻，付出的人是幸福的，虽然这样的幸福可能是要遭到报应的。 在现代人的眼光来看，莺莺这床也上的太快了些。其实这还不算彻底的，汉代的司马相如不过弹了次琴，卓文君便跟着他私奔了，连富翁老爹也不认了。那个时代，女子应允了一份爱情就等于一生一世，不会再有给你重来改过的机会。那是个严肃的时代，女子地位低下，虽然相对于其他朝代，唐朝的风气算是比较开明宽松，但是逾越礼制的爱情依然不容于世，和一个男子相恋，要么嫁给他，要么就是再也得不到幸福和爱情。如那位被元稹好友白居易赞为“醉娇胜不得，风嫋牡丹花”的徐州名妓关盼盼，在其丈夫徐州守帅张愔死后却被白居易讽刺她不肯殉情，逼得她不得不绝食自尽；又如步非烟，因为父母之命而嫁于功曹参军武公业，毫无爱情可言，于是她红杏出墙，爱上了攻读课业的书生赵象，被丈夫发现后，只是淡淡说了句“生既相爱，死亦何恨”，于是从容淡定，任凭丈夫拷打，不肯开口求饶一句，最后终于被活活打死，以暴疾而亡的名义埋了。那个时代的女子，很少可以拥有幸福的爱情，所以这充分体现了新社会的优越性，起码你谈几场恋爱没有关系，女孩子只要不失身还是会有幸福的。 红娘把枕头也带来了,在古时候,共同倚靠的枕头是充满暗示意味的情物，是在一起温柔缠绵的明证。本朝初年高阳公主嫁于房玄龄之子房遗爱为妻，却不爱房遗爱，在新婚之夜就把新郎拒于洞房之外。高贵的公主爱上了玄奘的高徒、最年轻却最聪慧的高僧辩机和尚，那时高阳公主十六岁，辩机和尚二十一岁。高阳公主送给辩机一个“金玉宝枕”，却被小偷偷出。结果事情因此泄露，高贵的辩机被腰斩于市，而高阳公主也一辈子恨上了自己的家族，“帝崩无哀容”。或许唐代的女子血液里奔流着冒险的因子，所以为了爱情不顾一切，哪怕被抛弃被鄙夷被万夫所指天地不容也再所不惜。于是整个唐朝给我们后人留下了一大堆让人向往的爱情故事。莺莺对待爱情的勇气，无疑是秉承了大唐女子一贯的风气，虽然她的命运因此让人心痛，但是她的形象也因此让人爱怜，在千百年后的今天依然让我爱慕钦佩。 “有顷，寺钟鸣，天将晓。红娘促去。崔氏娇啼宛转，红娘又捧之而去，终夕无一言。”如此“金风玉露一相逢”的时光过的总是很快，古寺的朝钟响起，天快亮了，莺莺也要离去了。对于类似的幽会后的早晨，《诗经》里便有很细致的描述：《郑风·女曰鸡鸣》里写道“女曰鸡鸣，士曰昧旦；子兴视夜，明星有烂”，女子在催促说“鸡已经在打啼了”，男子眷恋枕衾，“天还没全亮；你起身看夜空，启明星还闪闪发光”，然后慢慢谈到工作，谈到两个人的未来，谈到恩爱到白头，“宜言饮酒，与子偕老。琴瑟在御，莫不静好”；《齐风．鸡鸣》里写道“鸡既鸣矣，朝既盈矣。匪鸡则鸣，苍蝇之声。东方明矣，朝既昌矣。匪东方则明，月出之光”，女子催促男子快起身，男子淹留不肯，“那不是鸡叫，是苍蝇嗡嗡声，东边也没亮，那是月亮光而已”，回答言语可爱缠绵。钱钟书说：“莎士比亚剧中写情人欢会，女曰：‘天尚未明，此夜莺啼，非云雀鸣也。’男曰：‘云雀报曙，东方云开透日矣。’女曰：‘此非晨光，乃流星耳。’用以比勘。”但是我们注意到，莺莺和张生一夜缠绵，居然不交一词，只是在天明将别的时候，呜咽哭泣。这个写法相当传神，我们可以从那“山盟海誓”的缺失和离别时的哭泣，感受到莺莺内心的矛盾：她明知道她正在做一件可能万劫不复的错事，但是却无法控制内心对于张生的情意，爱情的那种使双方合二为一的强烈愿望战胜了对命运的恐惧，她不敢说话，因为说话就代表了清醒，她宁愿在一种迷醉的状态下委身于自己的爱人，抛却一切利益的得失、道德的禁梏；当天明将别，她仿佛恍然从梦中惊醒，好象做错了事的孩子一样，为自己的选择和命运哭泣，为自己所失去的哭泣。当然在这眼泪之中，对于离别的伤感，也占了一定的比重，所以在未来的十多天里，她再也没有和张生联系。 直到张生“赋《会真诗》三十韵，未毕，而红娘适至，因授之，以贻崔氏”，才又来与张生相会。想来未完的《会真诗》是个很好的说服自己的借口，只是来探讨文学罢了，但是总免不了“向谁行宿,不如休去”的挽留。于是这样相处了将近一个月。 “张生常诘郑氏之情，则曰：‘我不可奈何矣。’因欲就成之。”这是最常见的断句，莺莺说：“我没有办法告诉她。”于是张生便想亲自和郑氏谈谈，促成这件事。但是见家长的事突然没有下文，很快张生也去了长安，这样的情节安排无论如何都是不通的。幸好还有另外一个版本：“张生常诘郑氏之情，则曰：‘知不可奈何矣，因欲就成之。’”莺莺说她妈知道也没其他办法了，所以想促成我们的婚事。他们相处同居了一个月，而寺院内有崔家那么多的仆役，就算郑氏再昏懵，也应该了解到女儿的事情了。事已既此，无可奈何，女儿大了，心向外人，现在也只能期盼那男人能负责任把她娶去了。这样的心情很可以理解，我的一个朋友，和她女朋友两地分居，而且女孩子在当地做了教师，不错的职业，眼看因为家里反对要分手了，但是有天女孩子的父母偷听他们的电话，知道了女儿已经失身于我的朋友，于是第二天就让女儿把我的朋友叫去见面，很快便结了婚。所以很多时候，我都分不清自己到底是生活在古代还是生活在现代，一千多年下来，对待某些问题的做法还是一点都没变化。 但是张生可能很害怕被一桩寒门的婚姻套牢，一听这话赶快跑路；于是借口“为了梦想中金碧辉煌的长安,都市里充满了神奇的历险,满足一个男儿宏伟的心愿”，西下长安去了。去之前还先告诉了莺莺，“崔氏宛无难词，然而愁怨之容动人矣”。有一种哀伤，是哭不出来的，它会慢慢渗透进你的骨子，日日夜夜一点一滴地侵蚀你的情绪。或许她害怕自己会控制不住自己面对离别的悲伤，所以在张生将要走的第二天晚上，莺莺没有来。我总是不能理解女子的心思，明明想念你的，却不肯见面；明明想把你留下的，却早早地说出一路顺风的祝福；明明在说没有留下更多的甜蜜回忆，却连分手了也不肯来见最后一面，谁都无法想见女子的心里到底在想些什么，或许正是这样的复杂，才成就了莺莺形象的丰满。 但是很快，张生又回到了蒲州，又与莺莺相处了好几个月，也许是他无法放下这段感情，也许是长安尚未有“实现一个男儿宏伟志向”的机会，更可能是长安还没那么早开考，想最后的缠绵一下。莺莺的字和文章写的都很好，却从不给张生看；她写文章的水平很好，但是却好象什么都不懂的样子；她言辞敏捷，但是在外人面前却很少说话。或许这样的女孩子最是让人怜爱。“待张之意甚厚，然未尝以词继之。时愁艳幽邃，恒若不识，喜愠之容，亦罕形见”，莺莺是个内向的女孩子，有了情绪却不轻易流露，她不会口口声声地和你说“我爱你”，但是连她注视你的目光都能让你感到无限柔情，你无法知晓她的想法，但是却沉溺于她时时流露的情意。她喜欢弹琴来抒发情感，可能是心情忧郁，所以弹奏的曲子异常伤感。 不久张生便要去长安应试了，或许是下了决心终要割断前缘，一心功名，所以这个男人连说分手的勇气都没有，只能对着莺莺忧愁哀叹，自然他也是不肯去承诺些什么的。莺莺自然明白他的心思，面对爱人的负心薄情，做为一个弱女子又能说什么呢。莺莺是个坚强而又自尊的女子，她不会低声哀求张生留下，她态度恭敬，声音柔和，慢慢地对张生说：“始乱之，终弃之，固其宜矣，愚不敢恨。必也君乱之，君终之，君之惠也。则没身之誓，其有终矣，又何必深感于此行？然而君既不怿，无以奉宁。君常谓我善鼓琴，向时羞颜，所不能及。今且往矣，既君此诚。” 莺莺平静的面容下说出“始乱之，终弃之，固其宜矣，愚不敢恨”那是怎样的一种心痛呢，假如仅仅是个人爱情的失败也就罢了，但是其中还昭显出整个家族的衰败和老母最后一丝期望的落空。人很多时候并非为自己而活，所以人最不能承受的并非自身的失败，而是自身的失败给自己亲爱之人所带来的伤害。张生挥一挥衣袖，固然不带走一片云彩，还可以得到时人“善补过者”的赞誉，但是对于莺莺来说，不但她这一生的命运已经凄惨无疑，而且也给了她衰颓式微的家族一次重重的羞辱和打击。 她终于明白了“则没身之誓，其有终矣”，古往今来男女说着“山无陵，江水为竭，冬雷阵阵，夏雨雪，天地合，乃敢与君绝”的誓言，可大多数的人言语远比自身华丽，现实远没有恶化到世界末日，便已经支持不住，爱情一如华美的琉璃，碰触现实难免粉碎。 于是她为自己心爱的男子弹了最后一首曲子《霓裳羽衣曲序》，琴声因为心情悲伤而纷乱错杂，旁边的人都听着流泪，她终于弹不下去，扔下琴哭着跑到母亲的房里，再也没出来。在这部作品里，郑氏出场只有一次，侧面描写也并不多，但是我们却依然能想象一千多年前那位母亲的悲痛，为自己的命运，为家族的命运，更为自己女儿的命运感到悲伤。 第二天我们的元大才子便神清气爽地踏上西去长安的路途，但是那年他没有考中。于是他留在了长安，从莺莺的信中我们了解到，这个鄙薄的文青曾托人给莺莺寄去一封信，让她看开些，“以广其意”，顺便送去“花胜一合、口脂五寸”做为分手礼物。唐代女子喜欢用绢纸、金银等材料做出一朵朵花形的小物件，贴在脸上，唐代就称之为“花胜”或者“花钿”。元稹很潇洒地给分手后的情人送去长安最时尚的化妆品和首饰，想以此来弥补内心的愧疚。但凡女子都爱最新潮时尚的化妆品，犹以情人所赠为甚；但是我不知道淹留蒲州普救寺的母女，在这个穷乡僻壤突然看到负心的男人送来长安的时尚货色，会是怎样的心情，或许如后世李清照所言“泪融残粉花钿重”。 孤独无望地留在普救寺的莺莺回了一封信，那信却被张生炫耀于长安的朋友之间。就好象胡兰成把曾与他恩爱缠绵的女子都写进《今生今世》，古今文人下作起来都是一样。 对于自己的负心，元稹还借用了《左传》那句“夫有尤物,足以移人,苟非道德,则必有祸”，义正词严地发表了一通高论：“大凡天之所命尤物也，不妖其身，必妖于人。使崔氏子遇合富贵，乘宠娇，不为云为雨，则为蛟为螭，吾不知其变化矣。昔殷之辛，周之幽，据百万之国，其势甚厚。然而一女子败之，溃其众，屠其身，至今为天下戮笑。予之德不足以胜妖孽，是用忍情。”最可怕的是听众的反应，“于时坐者皆为深叹”，大家叹口气，居然没人指责张生的负心薄幸，或者有一点小小的同情给予莺莺。 对于美貌女子的恐惧，其实不过只是自身懦弱的借口罢了，男子严于律女子，宽于律己，实在是很无耻。《世说新语》里记载着石崇宴客让美人劝酒，如客人不饮，便杀掉劝酒的美人。有一次丞相王导和大将军王敦去赴宴，王导不善饮酒，也只好勉强自己喝，以至于喝醉了；而王敦死活不肯给面子，就是不喝，“已斩三人，颜色如故，尚不肯饮”。而此事，却被刘义庆归为“汰侈”，意思是奢侈浪费。在这里我们看到的是人正常情感的缺位，对于爱情和女性的残忍，却成了男子气度的象征。记得唐代曾有一个很出名的事件：军官冯燕，和同事张婴的漂亮老婆私通，张婴酗酒而归，冯燕逃避不及，只好藏到床底，却发觉自己的头巾还留在枕边，幸好张婴喝醉了并没发觉。于是冯燕指指头巾示意张妻把头巾取来免得事情败露，可是张妻会错了意，竟把枕边张婴的佩刀递给了他。冯燕看了张妻几眼，觉得这个女人太狠毒，就一刀砍下了张妻的头，然后戴上头巾走了。张婴于是就被认为杀害自己的妻子，被判死刑；结果在刑场上，冯燕出现了，他宣称张婴是无辜的，张妻是自己杀的。军政长官贾耽将此案据实上奏，并表示，宁愿免去自己的官职，也要为冯燕赎罪。最后皇帝的敕令是，将滑地的全部死刑犯同时赦免。这件案子影响很大，以至于那个时代的流行小说家沈下贤专门为之创作了传奇《冯燕传》；著名诗人司空图则写了长篇叙事诗《冯燕歌》，其中有一句诗写道“已为不平能割爱”，也就是说为了所谓的道德规范，能割舍爱情的才是大英雄。于是世情普遍鄙薄男欢女爱，积极培养冷血寡情的人，于是婚姻便成利益的交换，所谓的爱情只能沦落到勾栏瓦舍里去了。对比西方，希罗多德《历史》曾讲过吕底亚王坎道列斯的故事。坎道列斯认为自己的妻子是世上最美丽的女子，于是他想拿来炫耀了，他强迫他的亲信巨吉斯看王后的身体，以便确认这一点；不得已，巨吉斯只好藏在卧室，看了王后的身体。王后知道此事后，认为是奇耻大辱，就将巨吉斯召来，给他两个选择：要么他杀掉国王，“变成我的丈夫并取得吕底亚的王位”；要么被处死。结果巨吉斯选择了前者，他杀死了国王，并娶了王后，登上了吕底亚的王位。我们从中可以看到东西方文明对待情欲的差别。遗风留至如今，家里关心你的结婚对象，不是双方有多么相爱，感情有多深厚，而是这个人家里怎样，是不是老实，有没有本事赚钱升官；假如你斗胆和他们说起你们的爱情，于是大家都开始哄堂大笑或者不屑一顾，仿佛看你就是一个不成熟的孩子、精神错乱的病人。对于爱情的信仰，或许只存在于看戏的那段辰光。 有了这样一种社会心理氛围，再加上有太子少保韦夏卿的赏识，那么元稹抛弃寒门女子莺莺而迎娶豪门韦家的千金韦丛，也就顺理成章了。但吊诡的是在蒋防写的《霍小玉传》里，元稹的老丈人韦夏卿却对负心薄行的朋友李益这般说：“风光甚丽，草木荣华。伤哉郑卿，衔冤空室！足下终能弃置，实是忍人。丈夫之心，不宜如此。足下宜为思之！”蒋防此人在仕途上得到过元稹的推荐，所以他写及元稹的岳父时总要润色拔高一下，只是他的恩公看到这番话时是否会心头一颤？ 或许是虬髯客已没，不会再有人“衔之十年”也要去取“天下负心者”的头颅心肝下酒，所以男人也就越发理直气壮地负心薄幸。负心人元稹没有得到什么报应，又过了一年多后，也就是贞元十九年他登拔萃科，署秘书省校书郎，娶了韦夏卿之女韦丛为妻，并在那一年与同中书判拔萃科的白居易相识订交，从此元白之名满天下。元稹在《梦游春七十韵》中写道：“当年二纪初，嘉节三星度……韦门正全盛，出入多欢裕。”在元稹志得意满，欢娱畅快之时，莺莺也匆匆嫁于他人了。后来元稹偶然路过莺莺居住的地方，以莺莺表兄的身份求见，终不得一见。莺莺的不复相见，是对情人的深深失望，或许她会深深的认同鱼玄机说的“易求无价宝，难得有情郎”；她没有霍小玉那般刚烈，她也许也会哀怜自己“我为女子，薄命如斯，是丈夫负心若此”，但她却说不出“我死之後，必为厉鬼，使君妻妾，终日不安”的话。莺莺只写了首诗给元稹，硬着骨头咬着牙说“弃置今何道，当时且自亲”，既然都已经分开了不爱我了又有什么好说的呢，当时恩爱缠绵也就足够了，让他“还将旧时意，怜取眼前人”，因为懂得，所以慈悲。当爱情归于寂寥，繁华消于落寞，一切都只存在与记忆里，曾经的美好，只能活在心底。“惆怅旧欢如梦，觉来无处追寻”。或许她也明白，往事只能追忆，不可重温。曾经年少单纯的莺莺已经死了，只留下一具逐渐衰老的躯壳和悲伤的灵魂继续苟活。现实那样丑恶，我们却不得不活下去。 我真的怀疑元稹所谓的“曾经沧海难为水，除却巫山不是云”到底指哪一位，是莺莺，还是韦丛，抑或是薛涛？元和四年，韦丛去世，元稹写了三十三篇诗来悼念她，其中最有名的一句：“惟将终夜长开眼，报答平生未展眉。”根据陈寅恪先生的考证，这个“长开眼”不仅仅是睡不着的意思，“所谓‘常开眼’者，自比鳏鱼（有“鳏鱼眼长开”这一说法），即自誓终鳏之义”（陈寅恪《元白诗笺证稿》），元稹信誓旦旦的要为韦丛终生不娶，鳏孤到死了。但事实证明，元稹是个文过饰非的人，在韦丛凑趣去世的那年，他邂逅薛涛，两人相恋了一年后将之抛弃，可怜薛涛为之终身不嫁，“只欲栏边安枕席，夜深闲共说相思”；两年后纳妾安氏，又过数年续弦裴淑。简直是“取次花丛频回顾”啊！所以观陈寅恪先生对其评价“自私自利。综其一生行迹，巧宦固不待言，而巧婚尤为可恶也。岂其多情哉？实多诈而已矣”并不为过。 读《元长庆集》，常免不了痛恨为什么如此深情优美的诗句却出自一个那么薄情负心的伧夫之手。雪莱在《致云雀》中说：“我们最甜美的歌，就是那些倾吐最哀伤的思想的。”不知道元稹所哀伤的到底是什么。贝克尔在《抗拒死亡》中说的：“所有动人心弦的事中，对死的恐惧是首当其冲的。”他的悼亡诗写的那么情深意切，大概是出于对死亡本身的恐惧和悲哀吧。 或许不该过分指责元稹，他也不过是为了功名奔波的庸人，这个世界原本就是为庸人所设的。太过恩爱的情侣总是不容于世：苏东坡与王弗已是“十年生死两茫茫”了；陆游和唐婉儿只能“一怀愁绪，几年离索”；刘克庄在哀叹“旧日风烟草树，而今总断人肠”；冒辟疆和董小宛“一生清福,九年占尽,九年折尽矣”；还有纳兰性德，感慨着“被酒莫惊春睡重，睹书消得泼茶香，当时只道是寻常”。但是起码他们是能真心相爱的，就算不能“执子之手，与子偕老”，起码也是“骨化形销而丹诚不泯”，却可怜了单纯的莺莺，一个人用余生去背负全部的思念、悔恨和指摘。 史籍上再没有关于莺莺以后生活的记载，或许她一生坎坷，慢慢地消磨了纯真善良，成了世间常见的庸俗势利的妇人。但哪怕是这样，我依然相信在她心底的最幽深隐蔽的角落、最柔嫩脆弱的地方，记忆会像一把锯齿慢慢地来回剧着那根最纤细的神经，午夜梦回的时候，依然会为贞元十六年的那个男子泪流满面。 我怕我鄙薄的文字无法完美地译出那女子悲伤的文字，且让我们再细细读一读那信的原文,体会一下她的心情吧： 捧览来问，抚爱过深。儿女之情，悲喜交集。兼惠花胜一合、口脂五寸，致耀首膏唇之饰。虽荷殊恩，谁复为容？睹物增怀，但积悲叹耳。伏承使于京中就业，进修之道，固在便安。但恨僻陋之人，永以遐弃。命也如此，知复何言！自去秋已来，常忽忽如有所失。于喧哗之下，或勉为语笑，闲宵自处，无不泪零。乃至梦寐之间，亦多感咽离忧之思。绸缪缱绻，暂若寻常，幽会未终，惊魂已断。虽半衾如暖，而思之甚遥。一昨拜辞，倏逾旧岁。长安行乐之地，触绪牵情。何幸不忘幽微，眷念无斁，鄙薄之志，无以奉酬。至于终始之盟，则固不忒。鄙昔中表相因，或同宴处。婢仆见诱，遂致私诚。儿女之心，不能自固。君子有援琴之挑，鄙人无投梭之拒。及荐寝席，义盛意深。愚陋之情，永谓终托。岂期既见君子，而不能定情，致有自献之羞，不复明侍巾帻。没身永恨，含叹何言！倘仁人用心，俯遂幽眇，虽死之日，犹生之年。如或达士略情，舍小从大，以先配为丑行，以要盟为可欺，则当骨化形销，丹诚不泯，因风委露，犹托清尘。存没之诚，言尽于此。临纸呜咽，情不能申。千万珍重，珍重千万！玉环一枚，是儿婴年所弄，寄充君子下体所佩。玉取其坚润不渝，环取其终始不绝。兼乱丝一绚、文竹茶碾子一枚。此数物不足见珍，意者欲君子如玉之真，弊志如环不解。泪痕在竹，愁绪萦丝，因物达情，永以为好耳。心迩身遐，拜会无期。幽愤所钟，千里神合。千万珍重！春风多厉，强饭为嘉。慎言自保，无以鄙为深念。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>故事</tag>
        <tag>《莺莺传》</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人主页搭建]]></title>
    <url>%2Fpublic%2F2016%2F12%2F22%2Fbuild_blog%2F</url>
    <content type="text"><![CDATA[概要：博客搭建的记录与分享，主要用了Hexo，NexT主题和Gitment评论系统。这里记录了我从头到尾的安装流程，和使用过程中的改进。如果想方便使用的话，后面会给个独立的hexo theme，放到github 项目上。 使用新版本的NexT v6 主题即可，有些功能如gitment已经实现。对于图片的使用可能会出现问题。仅需看看我下面的2.2小节。怕麻烦的同学，下面内容就不用看了，现在的v6支持的很好。2018.10 我现在还是使用的是version: 5.1.0。 小技巧，在文章中使用&lt;!-- more --&gt;手动进行截断，Hexo 提供的方式。下面就是用这个截断的～～ 在开始看安装的时候，发现怎么涉及这么多东西，大家不要担心。也不用在意会不会nodejs，这些东西，人家已经帮我们把东西都写好了，我们做的就是改改配置文件，最多改改里面swig的模版的一些代码。望大家见谅的是，我对js不熟，有些地方不是很清楚。欢迎大家在下面评论，或者在github上开issue，共同讨论。 1. 安装1.1 简易安装使用使用新版本的NexT v6 主题即可，有些功能如gitment已经实现。对于图片的使用可能会出现问题。仅需看看我下面的2.2小节。我使用的是version: 5.1.0。 1.2 从头安装 安装 nodejs，从nodejs 官网下载安装包 download page 安装git客户端 git 安装Hexo npm install -g hexo-cli hexo 中文安装文档 Hexo中文网站 安装NexT ，NexT是一个比较火的主题。 按官网教程NexT安装即可，官网安装和配置教程比较美滋滋。 http://theme-next.iissnan.com/getting-started.html NexT Github https://github.com/iissnan/hexo-theme-next 另外，NexT开发者的博客（最近Next 变成组织了，祝贺）http://notes.iissnan.com Ubuntu安装记录1234567# for Ubuntu16.04$ sudo apt install npm nodejs-legacy$ sudo npm install hexo-cli -g$ hexo init blog$ cd blog$ npm install$ hexo server ok，安装完的目录结构。12345678910111213.├── node_modules # nodejs的目录├── public # 输出网站目录├── scaffolds # hexo 的一些预设模版├── source # 独立submodule├── themes # 主题 里面也有主题的配置文件不要与项目的配置文件搞混├── README.md├── _config.yml # 整个项目配置文件├── db.json├── index.html。 # 用于跳转到public下└── package.json5 directories, 5 files 我对博客项目的安排是这样的，总共有两个github项目，一个放素材，一个用hexo框架生成html文件。在上面的文件目录只能够，将source 文件夹作为一个submodule 用 git submodule123# 对于我来说$ cd path/to/your/github.io/project$ git submodule add https://github.com/talengu/blog_source source 在生成html，下面操作都在 path/to/your/github.io/project，hexo找不到node_modules12345678910111213# clone 项目$ git clone https://github.com/talengu/talengu.github.io$ git submodule init$ git submodule update# 切换到最新的submodule$ cd source$ git merge origin/master$ git submodule update# 执行npm按照，由于已经生成它会按照package.json文件自动安装# 没有npm的话 安装 https://nodejs.org/en/download/$ npm install 2. 配置对于在NexT主页上介绍的配置我就不写了，请参考http://theme-next.iissnan.com/getting-started.html 。 下面主要对重要的和我自己修改的部分说明没有的进行配置，值得注意的是我的NexT版本是version: 5.1.0。 2.1 NexT官网的设置MathJax 编辑 主题配置文件， 将 mathjax 下的 enable 设定为 true 即可。 cdn 用于指定 MathJax 的脚本地址，默认是 MathJax 官方提供的 CDN 地址。 1234# MathJax Supportmathjax: enable: true cdn: //cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML 下面测试$\frac{d}{dx}c^n=nx^{n-1}$ $\frac{d}{dx}c^n=nx^{n-1}$ Local Search (推荐)本地内容搜索引擎。 安装 hexo-generator-searchdb，在站点的根目录下执行以下命令： npm install hexo-generator-searchdb --save 编辑 站点配置文件，新增以下内容到任意位置： 12345search: path: search.xml field: post format: html limit: 10000 编辑 主题配置文件，启用本地搜索功能： 123# Local searchlocal_search: enable: true 2.2 markdown图片网上的图片链接可以直接使用，下面对本地图片使用进行配置。 使用 安装插件npm install https://github.com/CodeFalling/hexo-asset-image --save 在 主题配置文件（不是next的_config.yml）中设置permalink: :year/:month/:day/:title/，设置 post_asset_folder: true，这主要将文件拷贝到/public文件夹。其中permalink很关键，只能这样设置。 图片必须放到和md文件名字一样的同名字文件夹。如使用Typora软件写md的话，设置一下image保存路径即可，如下。 2.3 代码复制为了提高博客代码块的用户体验，仅仅代码高亮还不行，最好还能一键复制代码。故此文将讲述 Hexo NexT 主题博客的代码块复制功能配置。转(Hexo NexT 代码块复制功能)[https://www.jianshu.com/p/3e9d614c1e77] 2.3.1 下载 clipboard.js三方插件 clipboardjs ，相关介绍和兼容性它主页或 github 上看。 下载地址： clipboard.js clipboard.min.js 推荐 保存文件clipboard.js / clipboard.min.js ，目录如下：.\themes\next\source\js\src 2.3.2 clipboardjs 使用也是在.\themes\next\source\js\src目录下，创建clipboard-use.js，文件内容如下： 1234567891011121314151617/*页面载入完成后，创建复制按钮*/!function (e, t, a) &#123; /* code */ var initCopyCode = function()&#123; var copyHtml = ''; copyHtml += '&lt;button class="btn-copy" data-clipboard-snippet=""&gt;'; copyHtml += ' &lt;i class="fa fa-globe"&gt;&lt;/i&gt;&lt;span&gt;copy&lt;/span&gt;'; copyHtml += '&lt;/button&gt;'; $(".highlight .code pre").before(copyHtml); new ClipboardJS('.btn-copy', &#123; target: function(trigger) &#123; return trigger.nextElementSibling; &#125; &#125;); &#125; initCopyCode();&#125;(window, document); 在.\themes\next\source\css\_custom\custom.styl样式文件中添加下面代码： 123456789101112131415161718192021222324252627282930313233343536//代码块复制按钮.highlight&#123; //方便copy代码按钮（btn-copy）的定位 position: relative;&#125;.btn-copy &#123; display: inline-block; cursor: pointer; background-color: #eee; background-image: linear-gradient(#fcfcfc,#eee); border: 1px solid #d5d5d5; border-radius: 3px; -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; -webkit-appearance: none; font-size: 13px; font-weight: 700; line-height: 20px; color: #333; -webkit-transition: opacity .3s ease-in-out; -o-transition: opacity .3s ease-in-out; transition: opacity .3s ease-in-out; padding: 2px 6px; position: absolute; right: 5px; top: 5px; opacity: 0;&#125;.btn-copy span &#123; margin-left: 5px;&#125;.highlight:hover .btn-copy&#123; opacity: 1;&#125; 2.3.3 引用在.\themes\next\layout\_layout.swig文件中，添加引用（注：在 swig 末尾或 body 结束标签（&lt;/body&gt;）之前添加）： 123&lt;!-- 代码块复制功能 --&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/clipboard.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/clipboard-use.js&quot;&gt;&lt;/script&gt; 想看效果的可以去我博客看，截图如下: 熟悉的也可以将clipboard.min.js和clipboard-use.js合并为一个文件，再在.\themes\next\layout\_layout.swig文件中使用。当然clipboard.min.js也可以直接用三方 cdn 的方式引入也行。 2.4 Gitment 评论功能 集成 giment 评论系统的过程。gitment 把评论放到 github 的 issues 系统里，评论支持 md，比较适合程序员. 12# 安装gitment$ npm install gitment --save 2.4.1 注册 OAuth Application点击 https://github.com/settings/applications/new 注册，注意Authorization callback URL填自己的网站 url https://xxxx.github.io/. 记下 Client ID 和 Client Secret. 在新版本NexT v6里面已经支持gitment了所以你只要在github上注册一下 OAuth Application ，填上Client ID 和 Client Secret.即可 ####2.4.2 修改themes/next/_config.yml 在其中添加: 123456789# Gitment# Introduction: https://imsun.net/posts/gitment-introduction/gitment: enable: true githubID: yourid repo: yourrepo ClientID: yourid ClientSecret: yoursecret lazy: true 注意: 格式要正确，该空格的一定要空格。所有的 yourXXX 都换成自己的. 在主题的en.yml增加: 1gitmentbutton: Show comments from Gitment zh-Hans.yml增加: 1gitmentbutton: 显示 Gitment 评论 2.4.3 修改主题layout/_partials/comments.swig找到这个文件里的这两行: 12&#123;% elseif theme.valine.appid and theme.valine.appkey %&#125; &lt;div id="vcomments"&gt;&lt;/div&gt; 上面是最后一个elseif分支，在下面加一个elseif分支: 1234567&#123;% elseif theme.gitment.enable %&#125; &#123;% if theme.gitment.lazy %&#125; &lt;div onclick="ShowGitment()" id="gitment-display-button"&gt;&#123;&#123; __('gitmentbutton') &#125;&#125;&lt;/div&gt; &lt;div id="gitment-container" style="display:none"&gt;&lt;/div&gt; &#123;% else %&#125; &lt;div id="gitment-container"&gt;&lt;/div&gt; &#123;% endif %&#125; 加完之后下面的内容是原来的，保持不变: 123 &#123;% endif %&#125; &lt;/div&gt;&#123;% endif %&#125; 2.4.4 增加gitment.swig在主题下layout/_third-party/comments/目录下中添加文件gitment.swig： 12345678910111213141516171819202122232425262728293031323334353637&#123;% if theme.gitment.enable %&#125; &#123;% set owner = theme.gitment.githubID %&#125; &#123;% set repo = theme.gitment.repo %&#125; &#123;% set cid = theme.gitment.ClientID %&#125; &#123;% set cs = theme.gitment.ClientSecret %&#125; &lt;link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"&gt; &lt;script src="https://imsun.github.io/gitment/dist/gitment.browser.js"&gt;&lt;/script&gt; &#123;% if not theme.gitment.lazy %&#125; &lt;script type="text/javascript"&gt; var gitment = new Gitment(&#123; id: window.location.pathname, owner: '&#123;&#123;owner&#125;&#125;', repo: '&#123;&#123;repo&#125;&#125;', oauth: &#123; client_id: '&#123;&#123;cid&#125;&#125;', client_secret: '&#123;&#123;cs&#125;&#125;', &#125;&#125;); gitment.render('gitment-container'); &lt;/script&gt; &#123;% else %&#125; &lt;script type="text/javascript"&gt; function ShowGitment()&#123; document.getElementById("gitment-display-button").style.display = "none"; document.getElementById("gitment-container").style.display = "block"; var gitment = new Gitment(&#123; id: document.location.href, owner: '&#123;&#123;owner&#125;&#125;', repo: '&#123;&#123;repo&#125;&#125;', oauth: &#123; client_id: '&#123;&#123;cid&#125;&#125;', client_secret: '&#123;&#123;cs&#125;&#125;', &#125;&#125;); gitment.render('gitment-container'); &#125; &lt;/script&gt; &#123;% endif %&#125;&#123;% endif %&#125; 然后在主题下layout/_third-party/comments/index.swig文件中引入 gitment.swig 文件： 1&#123;% include &apos;gitment.swig&apos; %&#125; 2.4.5 添加gitment.styl在主题下source/css/_common/components/third-party/目录下添加gitment.styl文件，设置 button 的样式： 12345678910111213#gitment-display-button&#123; display: inline-block; padding: 0 15px; color: #0a9caf; cursor: pointer; font-size: 14px; border: 1px solid #0a9caf; border-radius: 4px; &#125; #gitment-display-button:hover&#123; color: #fff; background: #0a9caf; &#125; 然后在主题下source/css/_common/components/third-party/third-party.styl文件中引入相应的 CSS 样式即可: 1@import &quot;gitment&quot;; 这样就 ok 了！ 2.4.6 易错点 修改themes/next/_config.yml这个文件时，格式要正确。另外，repo 是你要想创建 issues 的仓库，完全可以跟博文所放的仓库不一个。id 就写自己的 github 用户名就可以，这个用户名跟 repo 必须匹配。 gitment 可能不支持链接地址里有中文，所以安装 gitment 前一定要参考前文把链接持久化搞成全是英文的。 同一篇文章需要初始化 comment 两次的问题，是因为 http://xxx.com/post/ab9bb85a.html 和点击阅读全文进去的链接 http://xxx.com/post/ab9bb85a.html#more 对 issues 来说是不同的，所以创建两次。解决方法就是gitment.swig里 id 弄成window.location.pathname而不是document.location.href。 初始化评论后，可以到 github 里自己放 issues 的仓库查看 issues 是否创建成功，有时候浏览器可能会有缓存依然提示你初始化评论。一般过个两分钟就显示正常了。 2.4.7 参考文档 主要参考文档 一种相对简略的配置方式 作者 issue 2.5 copyright文字添加效果 可以在md文件里面控制是否使用这个组建。 使用 在md文件中的front-head部分，设置 copyright:true如下面。设置next/_config.yml 文件，中设置post_copyright 的选项 enable。 12345678910---title: 个人主页搭建date: 2016-12-22 12:39:04categories: - 博客搭建tags: - Hexocomments: truecopyright: true--- 说明 对原next的改变 对于一些原创的文本可以设置版权的声明，这个是next自带的，我进行了修改。next的_config.yml 文件，中设置post_copyright 的选项，启用它会对所有的页面添加，我多加了一个page的copyright使能判断。对next/layout/_macro/post-copyright.swig修改。下面为修改后的文件。 12345678910111213141516171819&#123;% if theme.post_copyright.enable %&#125;&#123;% if page.copyright %&#125; &lt;!-- 加上page md文件头部使能--&gt; &lt;ul class="post-copyright"&gt; &lt;li class="post-copyright-author"&gt; &lt;strong&gt;&#123;&#123; __('post.copyright.author') + __('symbol.colon') &#125;&#125;&lt;/strong&gt; &#123;&#123; config.author &#125;&#125; &lt;/li&gt; &lt;li class="post-copyright-link"&gt; &lt;strong&gt;&#123;&#123; __('post.copyright.link') + __('symbol.colon') &#125;&#125;&lt;/strong&gt; &lt;!-- url的修正，可能要根据你的情况修改--&gt; &lt;a href="&#123;&#123; config.url &#125;&#125;&#123;&#123; config.root &#125;&#125;&#123;&#123; post.path &#125;&#125;" title="&#123;&#123; post.title &#125;&#125;"&gt;&#123;&#123; config.url &#125;&#125;&#123;&#123; config.root &#125;&#125;&#123;&#123; post.path &#125;&#125;&lt;/a&gt; &lt;/li&gt; &lt;li class="post-copyright-license"&gt; &lt;strong&gt;&#123;&#123; __('post.copyright.license_title') + __('symbol.colon') &#125;&#125; &lt;/strong&gt; &#123;&#123; __('post.copyright.license_content', theme.post_copyright.license_url, theme.post_copyright.license) &#125;&#125; &lt;/li&gt; &lt;/ul&gt;&#123;% endif %&#125;&#123;% endif %&#125; 2.6 RSS (可选)对一些网站的feed 的订阅 如rss，使用来进行订阅网站的rss，现在一些网站已经没有rss服务，google也停掉了google rss reader的项目，所以看你的喜好。 123# 安装hexo-generator-feednpm install hexo-generator-feed --save# 在_config.yml 启用feed 2.7 添加 fork me github效果 在GitHub Ribbons或GitHub Corners选择一款你喜欢的挂饰。比如下面的 github corners 在your-url填上你的 url 。 将刚刚复制的挂饰代码，添加到themes/next/layout/_layout.swig文件中，添加位置，放在&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;的下方如下图。 TODO:这个TODO中放的是，我接下来对博客搭建这个项目，要做的事。平台的debug，内容的设计等等。 [ ] 续写这篇博客，后面根据内容多少看要不要拆分这个博客。 [ ] 永久化连接 permalink​ 这permalink 和本地图片的拷贝复制有关不好改，下面是可能的方法，由于现在的评论还比较少，后面改进。​ https://github.com/rozbo/hexo-abbrlink​ https://github.com/EqualMa/hexo-plugin-permalink-pathed-title [ ] gitment object ProgressEvent #170​ gitment 出现问题 作者好像放弃了，所以网上有一些解决方案，(gitment issue #170)(https://github.com/imsun/gitment/issues/170) ​ 临时使用https://www.wenjunjiang.win/js/gitment.js 这个gitment.js [ ] 编写规范 得写一个博客的编写规范。分类、标签的使用，图片的使用，公式的使用等等 博客编写规范 github上有项目图片就从项目中链接过来，比如头像就是我github的头像 重要的图片存在本项目中 Typora的使用 参考Hexo-NexT配置超炫网页效果 好多新奇玩意儿～ Hexo gitment 原文地址 图标网站icon8 web 比较舒服http://fontawesome.io 标准风格https://www.easyicon.net/ 国内的图标 【正在补充修改内容中～】]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>NexT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[srt中英文合并python脚本]]></title>
    <url>%2Fpublic%2F2016%2F04%2F14%2Fshells%2Fyoutube_src_combine%2F</url>
    <content type="text"><![CDATA[从 Getting Youtube subtitles 或者中英文字幕，然后将其合并，变成中英文双字幕。 123456789101112131415161718192021222324252627282930313233343536373839404142434445'''这个脚本完成了中英文srt合并的功能'''import osdef srt2lis(name): lines = open('srt/'+name, 'r', encoding='utf-8').readlines() lis = [] tmp = [] for i, line in enumerate(lines): # 以\n 结尾的一个时间点 if line == '\n': lis.append(tmp) tmp = [] else: tmp.append(line) return lisdef hebing(name_zh): name_en = name_zh[:-7] + '.srt' out_name='out/'+name_en f=open(out_name,'w',encoding='utf-8') lis_en=srt2lis(name_en) lis_zh=srt2lis(name_zh) for i,item in enumerate(lis_en): print(item[0]) f.write(item[0]) f.write(item[1]) for line in lis_zh[i][2:]: f.write(line) for line in item[2:]: f.write(line) f.write('\n') f.close()flis=os.listdir('srt/')if not os.path.exists('out'): os.mkdir('out')for name in flis: print(name) if name[-6:-4]=='zh': hebing(name)]]></content>
      <categories>
        <category>常用脚本</category>
      </categories>
      <tags>
        <tag>python脚本</tag>
        <tag>YouTube字幕合并</tag>
        <tag>src</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DSP滤波程序]]></title>
    <url>%2Fpublic%2F2015%2F06%2F14%2Fdsp%2Fdsp_filter%2F</url>
    <content type="text"><![CDATA[通过matlab对数字信号进行滤波器的设计后，我们要将设计好的参数放到嵌入式系统中进行滤波。IIR滤波器FIR滤波器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#include &lt;stdio.h&gt;#include &lt;malloc.h&gt;//z变换转成差分方程然后迭代//Talen @UESTC 2015.6.5//打印数组void print(float *x,int len);//取后第1-n个float* aminusone(float* a,int ar);//差分中间值float gtcet(float *t,float *x,int xr,int s,int d);//主要滤波函数float* gfilter(float *b,int br,float *a,int ar,float *x,int xr);void print(float *x,int len)&#123; for(int i=0;i&lt;len;i++) &#123;printf("%9.3f ",x[i]); if((i%7)==6) printf("\n");&#125; printf("\n");&#125;float* aminusone(float* a,int ar)&#123; float* am = (float *)malloc((ar-1) * sizeof(float)); for(int i=0;i&lt;ar-1;i++) am[i]=a[i+1]; return am;&#125;float gtcet(float *t,float *x,int xr,int s,int d) //x[]数据源 r数据源长度 s开始点(0开始) d数据长度 //t可以是a[] b[] 长度与d一样&#123; float sum=0; float* w = (float *)malloc(d * sizeof(float)); for(int i=0;i&lt;d;i++) &#123; int temp=s-i; if(temp&gt;=0&amp;&amp;temp&lt;xr) w[i]=x[temp]; else w[i]=0; //核心语句 sum=sum+w[i]*t[i]; &#125; return sum;&#125;float* gfilter(float *b,int br,float *a,int ar,float *x,int xr) //b a x br b的长度 ar a的长度 xr数据长度 //use本程序定义的gtcet()和aminusone() //输入数据，b，a，x得出滤波后的y&#123; float* y = (float *)malloc(xr* sizeof(float)); for(int ti=0;ti&lt;xr;ti++) y[ti]=0; for(int i=0;i&lt;xr;i++) &#123; //最核心语句，此处迭代 y[i]=gtcet(b,x,xr,i,br)-gtcet(aminusone(a,ar),y,xr,i-1,ar-1); &#125; return y;&#125;int main()&#123; //input 源数据 可修改 //////////////////////////////////////////////////////////////// float x[120]=&#123;-4, -2, 0, -4, -6, -4, -2, -4, -6, -6, -4, -4,\ -6, -6, -2, 6, 12, 8, 0, -16, -38, -60, -84,\ -90, -66, -32, -4, 2, -4, 8, 12, 12, 10, 6,\ 6, 6, 4, 0, 0, 0, 0, 0, -2, -4, 0, 0, 0, -2,\ -2, 0, 0, -2, -2, -2, -2, 0, -2, -4, -2, 0,\ -2, -4, -4, 2, 0, 0, -2, -4, -2, 0, 0, -2,\ -4, -2, 0, 0, -4, -4, -2, -2, -4, -6, -6,\ -4, -4, 8, -10, -8, -6, -6, -8, -12, -10,\ -8, -8, -10, -12, -10, -8, -8, -10, -10,\ -8, -6, -6, -8, -8, -4, -2, -4, -4, -4,\ 0, 0, -2, -4, -2, -2, 0, -4&#125;; //参数 float b[7]=&#123; 0.0007,0.0044,0.0111,0.0148,0.0111,0.0044,0.0007&#125;; float a[7]=&#123; 1.0000,-3.1836,4.6222,-3.7795,1.8136,-0.4800,0.0544&#125;; ////////////////////////////////////////////////////////////////// //不要修改 int xr=sizeof(x)/sizeof(float); int br=sizeof(b)/sizeof(float); int ar=sizeof(a)/sizeof(float); //output 滤波后数据 float *y; printf("参数b：\n");print(b,br); printf("参数a：\n");print(a,ar); printf("原数据：\n");print(x,xr); y=gfilter(b,br,a,ar,x,xr); printf("滤波后数据：\n");print(y,xr); getchar(); return 0;&#125;]]></content>
      <categories>
        <category>数字信号处理</category>
      </categories>
      <tags>
        <tag>DSP</tag>
        <tag>filter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows笔记本开共享wifi]]></title>
    <url>%2Fpublic%2F2015%2F04%2F14%2Fshells%2Fshare_win_wifi%2F</url>
    <content type="text"><![CDATA[网上有很多用笔记本设置无线热点的批处理，我中和了一下。复制下面代码到记事本，改后缀为bat就行了。[改一下你自己定义的ssid和key] 12345678910111213141516171819202122232425@echo offset mssid=GTC::网络名字set mkey=123456789::大于八位密码echo ***********************************************echo 打开承载网络 1echo 关闭承载网络 2echo 承载网络信息 3echo 设置网络信息 setecho 退出 eecho （网络名字、密码可在源文件中改）echo （请以管理员身份打开!!!）echo ***********************************************:startset /p var=请选择:if %var%==1 netsh wlan start hostednetwork &amp;&amp; echo 网络名字:%mssid% 密码:%mkey% &amp;&amp; GOTO startif %var%==2 netsh wlan stop hostednetwork &amp;&amp; GOTO startif %var%==3 netsh wlan show hostednetwork &amp;&amp; echo 网络名字:%mssid% 密码:%mkey% &amp;&amp; GOTO startif %var%==set netsh wlan set hostednetwork mode=allow ssid=%mssid% key=%mkey% &amp;&amp; echo 网络名字:%mssid% 密码:%mkey% &amp;&amp; GOTO startif %var%==e pause]]></content>
      <categories>
        <category>常用脚本</category>
      </categories>
      <tags>
        <tag>Windows脚本</tag>
        <tag>共享wifi</tag>
        <tag>cmd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[序言]]></title>
    <url>%2Fpublic%2F2015%2F01%2F01%2FAbout%2F</url>
    <content type="text"><![CDATA[欢迎来到这里～ 博客这个东西很好玩，体现出一个人很多个性的东西。看了好多书籍的序，我想也为我的博客写个序。开篇名义，本博客主要记录学习工作中的知识点和生活的休闲杂记。记忆这东西很神奇，莫名其妙地记住一些事，但也不知不觉丢了些东西。在互联网或者说移动互联网之前，人们的记事方式更多的是纸质的，学习也是按照课本一页页去掌握，如今竞争的压力，信息的爆炸，技术信息发布平台多样，信息短快乱，工作与学习所用的知识点越来越多，越来越细，碎片化地学习无法避免的。 如何去记录这些碎片的知识，整理归纳的方法设计，已经迫在眉睫了。在Github上搭建一个带版本控制和评论功能的博客，我认为是个不错的想法。利用Markdown写文档比较方便，不需涉及很多格式的问题，风格想换就换，各个博客平台也支持这种语法方式。git对文本的版本控制比较舒服，我可以在多个终端进行编写，同步方便，合并后利用hexo框架就可以发布。在评论支持方面以前使用的是网易云跟帖，但这个功能网易关了，现在使用的Gitment，利用github的isuue功能的评论框架，现在仅支持github用户登录评论，但就用户面来说，我觉得够了，我写的这些博客主要是给自己看的。 对我博客的寄语。希望利用博客建立个人有效的知识体系，锻炼写文章的水平，留下生活中有趣的事物，同时传递出有趣的想法，有效的和各位大牛交流相关领域的经验，在互联网村里共同成长与进步。 人是一棵会思考的芦苇，并有一个有趣的灵魂。 不忘初心，活波严谨。 感谢The Internet And The World. 联系方式 QQmail: tianchenggu@qq.com Gmail: talenapp@gmail.com wechat QR]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>关于</tag>
      </tags>
  </entry>
</search>