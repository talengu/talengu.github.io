<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>转载 on 一塘</title><link>https://example.com/tags/%E8%BD%AC%E8%BD%BD/</link><description>Recent content in 转载 on 一塘</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Fri, 19 Apr 2024 12:00:00 +0000</lastBuildDate><atom:link href="https://example.com/tags/%E8%BD%AC%E8%BD%BD/index.xml" rel="self" type="application/rss+xml"/><item><title>「转」人人都是开发者</title><link>https://example.com/post/c3-ai/everyone-developer/</link><pubDate>Fri, 19 Apr 2024 12:00:00 +0000</pubDate><guid>https://example.com/post/c3-ai/everyone-developer/</guid><description>&lt;h2 id="前言">前言&lt;/h2>
&lt;p>“自然语言会成为下一代的编程语言，人人都能成为开发者。”&lt;/p>
&lt;p>4月16日，Create 2024百度AI开发者大会在深圳召开，百度创始人、董事长兼首席执行官李彦宏发表了《人人都是开发者》的主题演讲，描述了一个不再局限于编码技能的世界，而是以自然语言为媒介，人人都能参与创造的时代。&lt;/p>
&lt;!-- more -->
&lt;h2 id="演讲稿">演讲稿&lt;/h2>
&lt;p>大家好，欢迎参加Create 2024百度AI开发者大会，这是Create大会首次在粤港澳大湾区举办。今天现场来了5000多位开发者和科技爱好者。&lt;/p>
&lt;p>过去这一年，我跟很多创业者、开发者交流，感觉大家都处在一种“FOMO”状态，也就是Fear of Missing Out，既兴奋、又害怕错过。确实，大模型和生成式AI，将彻底改变开发者这个群体。&lt;/p>
&lt;p>过去，开发者用代码改变世界；未来，自然语言将成为新的通用编程语言，你只要会说话，就可以成为一名开发者，用自己的创造力改变世界。&lt;/p>
&lt;p>这一天并不遥远，我们看到，因为有了强大的基础大模型，有了很多低门槛，甚至零门槛的开发工具，开发者的生产力大大提高了。&lt;/p>
&lt;p>比如，基于文心大模型的智能代码助手Comate，不仅支持100多种语言和所有主流IDE平台，可以推荐代码、生成代码注释、查找代码缺陷、给出优化方案，还可以深度解读代码库、关联私域知识生成新的代码。上岗一年多，Comate已经走入了喜马拉雅、三菱电梯、软通动力等上万家企业，生成的代码采纳率达到了46%，百度每天新增的代码中，已经有27%是由Comate生成的。&lt;/p>
&lt;p>今天，你不会写代码，也可以做出一个AI应用；不用编程，也可以做出一个智能体。AI正在掀起一场创造力革命，未来开发应用就像拍个短视频一样简单，人人都是开发者，人人都是创造者。&lt;/p>
&lt;p>作为一家技术公司，百度的角色定位，就是尽可能地为大家提供所需的开发工具，不断提升整个社会的创造力。具体来说，我们提供1个强大的基础模型系列，就是文心大模型系列，这包括旗舰版的ERNIE3.5， ERNIE4.0， 也包括轻量版的ERNIE Speed、Lite、Tiny等等。&lt;/p>
&lt;p>我们还提供基于大模型来开发各种应用的工具，包括智能体开发工具AgentBuilder，AI原生应用开发工具AppBuilder，以及各种尺寸的模型定制工具ModelBuilder。这三个工具，都代表了先进生产力。下面，我会给大家一一展示。&lt;/p>
&lt;h2 id="文心一言用户超2亿文心大模型40工具版发布">文心一言用户超2亿，文心大模型4.0工具版发布&lt;/h2>
&lt;p>首先讲一下，文心一言和文心大模型的最新进展：&lt;/p>
&lt;p>文心一言从去年3月16日发布，到今天是一年零一个月的时间。我们的用户数突破了2亿，API日均调用量也突破了2亿，服务的客户数达到了8.5万，利用千帆平台开发的AI原生应用数超过了19万。&lt;/p>
&lt;p>我们看看，大家都在用文心一言做什么？&lt;/p>
&lt;p>视频中的真人真事只是冰山一角。我们可以看到，文心一言正在改变更多人的工作和生活。&lt;/p>
&lt;p>支撑文心一言的基座模型，就是文心大模型。过去一年，它经历了从3.0版本到3.5，再到4.0版本的进化。文心4.0在理解、生成、逻辑、记忆四大能力方面，均达到了业界领军水平。&lt;/p>
&lt;p>近几个月来，文心大模型在代码生成、代码解释、代码优化等通用能力方面实现了进一步的显著提升，达到国际领先水平。&lt;/p>
&lt;p>今天，我们正式发布文心大模型4.0的工具版，现在，大家可以在工具版上，体验代码解释器功能，通过自然语言交互，就能实现对复杂数据和文件的处理与分析，还可以生成图表或文件，能够快速洞察数据中的特点、分析变化趋势、为后续的决策提供高效精准的支撑。&lt;/p>
&lt;p>文心大模型已经成为了中国最领先、应用最广泛的AI基础模型。&lt;/p>
&lt;p>不仅如此，相比一年前，文心大模型的算法训练效率提升到了原来的5.1倍，周均训练有效率达到98.8%，推理性能提升了105倍，推理的成本降到了原来的1%。&lt;/p>
&lt;p>也就是说，客户原来一天调用1万次，同样成本现在可以调用100万次。媒体可能不会因为成本下降99%而兴奋。但是企业也好，开发者也好，一旦用起来，最关注的就是效果和成本。&lt;/p>
&lt;p>我们能在提升性能的同时，把推理成本降到1%，正是因为百度在芯片、框架、模型、应用这四层架构上有着全栈的布局，通过端到端优化，不断地把成本打下来，让更多人都可以高效、低价地用大模型来做AI应用。&lt;/p>
&lt;p>毫无疑问，大模型相关的话题，在2024年依然会很热，各类技术突破还会不断涌现。媒体也会继续热衷于用“震撼发布”“史诗级更新”这样的标题进行渲染。但我想强调的是，大模型本身并不直接创造价值，基于大模型开发出来的AI应用才能满足真实的市场需求。&lt;/p>
&lt;h2 id="分享开发ai原生应用的具体思路和工具踩了无数的坑交了高昂学费">分享开发AI原生应用的具体思路和工具：“踩了无数的坑，交了高昂学费”&lt;/h2>
&lt;p>今天我想跟大家分享的是一些基于大模型开发AI原生应用的具体思路和工具。这是我们百度根据过去一年的实践，踩了无数的坑，交了高昂的学费换来的。&lt;/p>
&lt;p>第一是MoE。未来大型的AI原生应用基本都是MoE架构，这里所说的MoE不是一般的学术概念，而是大小模型的混用，不依赖一个模型来解决所有问题。但什么时候调用小模型、什么时候调用大模型、什么时候不调用模型，这都是有技术含量的，要针对应用的不同场景做匹配。&lt;/p>
&lt;p>第二是小模型。小模型推理成本低，响应速度快，在一些特定场景中，经过SFT精调后的小模型，它的使用效果可以媲美大模型。这就是我们发布Speed，Lite、Tiny三个轻量模型的原因。我们通过大模型，压缩蒸馏出来一个基础模型，然后再用数据去训练，这比从头开始训小模型，效果要好很多，比基于开源模型训出来的模型效果更好，速度更快，成本更低。&lt;/p>
&lt;p>第三是智能体。智能体是当下很热的一个话题，随着智能体能力的提升，会不断催生出大量新的应用。智能体机制，包括理解、规划、反思和进化，它让机器像人一样思考和行动，可以自主完成复杂任务，在环境中持续学习、实现自我迭代和进化。在一些复杂系统中，我们还可以让不同的智能体互动，相互协作，更高质量地完成任务。这些智能体能力，我们已经开发出来了，并且向开发者全面开放。&lt;/p>
&lt;p>在MoE、小模型、智能体这三个方向上，百度都已经给大家做好了“开箱即用”的工具。下面，我就给大家介绍三种不同的工具，分别是：智能体开发工具AgentBuilder、AI原生应用开发工具AppBuilder、各种尺寸的模型定制工具ModelBuilder。&lt;/p>
&lt;h2 id="智能体开发工具agentbuilder">智能体开发工具AgentBuilder&lt;/h2>
&lt;p>首先是智能体开发工具AgentBuilder。智能体可能是未来离每个人最近、最主流的大模型使用方式，基于强大的基础模型，智能体可以批量生成，应用在各种各样的场景。&lt;/p>
&lt;p>百度刚刚升级了文心智能体平台。截至目前，已经有3万多个智能体被创建、5万多名开发者和上万家企业入驻。我们的目标是，让每个人、每个组织都成为智能体的开发者，打造国内最完整的智能体生态。&lt;/p>
&lt;p>那如何实现这个目标呢？就是给大家提供零门槛的智能体开发工具AgentBuilder。&lt;/p>
&lt;p>下面我们就先以“新加坡旅游局”为例一起看看，一个智能体是如何做出来的。&lt;/p>
&lt;p>首先，我们打开文心智能体平台，创建页面有着零代码、低代码两种模式，新手可以直接选择“零代码模式”，用自然语言，几句话就能创建一个智能体。&lt;/p>
&lt;p>我们先给智能体起名叫“新加坡旅游局”，然后在设定里写明需要打造旅游方案、解答问题，提供酒店门票预订服务，这些设定都是用来指导智能体的，告诉它都能做什么。&lt;/p>
&lt;p>如果只需要基础智能体，平台会自动完成填写。但我们希望“新加坡旅游局”是一个专业的智能体，所以要进行高级配置。我可以把新加坡百科词条和官网链接都添加到知识库里，让它每天更新。然后添加一些工具，如酒店查询、景点门票购买等，增强它的服务能力。目前我们已经跟携程合作，提供了酒店、景点、票务等旅游服务工具。这样，一个新加坡旅游局的智能体就做好了，可以进一步预览、调优。&lt;/p>
&lt;p>现在打开百度APP，搜索“什么时候去新加坡人最少”，因为大家出去旅游都想避开人潮。智能体会综合多个来源的信息，生成一个答案，“1-3月人最少”。我们还可以点击智能体，和它进一步互动，比如去新加坡旅游的注意事项，推荐新加坡排名前三的酒店，还能让它直接预订新加坡环球影城的门票，一站式解决需求，大大节省了用户时间。&lt;/p>
&lt;p>除了新加坡之外，大连、沈阳等文旅类智能体也都在文心智能体平台上线，还有知识类、创作类、学习类、娱乐类等各式各样的智能体，这些都是用AgentBuilder做出来的。&lt;/p>
&lt;p>去年文心一言刚发布的时候，我就说过，文心一言会影响到每一家公司。因为它强大的自然语言理解能力、表达能力、推理能力，可以使任何一个公司都离自己的客户更近。&lt;/p>
&lt;p>今天，每一个商家、每一个客户，都能在百度拥有专属的智能体。整个过程完全不需要编程，通过类似提示词的信息输入，和简单的几步操作调优，就能迅速生成一个智能体，成为7X24小时在线的金牌业务员。&lt;/p>
&lt;p>我们来看一下，一个商家智能体是怎么做出来的。&lt;/p>
&lt;p>启德教育是家知名教育企业，在全国有60多家分支机构，还有很多海外分公司，覆盖国家广，对接待的话术要求很高。如何能全天24小时回复客户的咨询，并且提高接待水平、降低经营成本呢？&lt;/p>
&lt;p>启德教育利用百度的AgentBuilder，打造了专属的智能体。&lt;/p>
&lt;p>我们来看看，如何打造一个具备基本能力的智能体。很简单，在平台上填写智能体的头像、名称、经营业务范围和欢迎语，再设置一些需要用户提供的信息，比如年龄、学历。5分钟、零门槛，一个智能体就做好了。&lt;/p>
&lt;p>启德教育还希望这个智能体是个懂业务、懂学生的留学顾问。它可以针对学生的不同情况，比如想去美国还是澳洲、是硕士还是学士、雅思和托福考了多少分等等，做出专业分析，给出精准回答。我们可以通过添加知识、角色、工具这几大模块，来打造一个更高级的智能体。&lt;/p>
&lt;p>在知识模块中，上传私域知识，让平台实时解析，自动生成对话语料；在角色模块，把一些不在经营范围内的留学国家，增加到过滤方案中，可以提高用户线索的有效率；在工具模块，加入预约到店等服务。通过这样几步简单操作，一个拥有专业能力的启德教育智能体就做好了。&lt;/p>
&lt;p>现在，我们来搜索“澳洲留学申请条件”，可以看到智能体快速给出了需要的语言能力、专业选择等七大必备条件，还给能出相应的留学咨询方案，对各种难题都有问必答、有求必应。&lt;/p>
&lt;p>启德教育智能体非常的受欢迎，上线第一周，就成功分发了155万次，与用户交互了5.8万次，线索转化量直线增长、有效线索的转化成本明显降低，经营效率大幅提升。&lt;/p>
&lt;p>下面，我再给大家介绍一个家居行业的智能体。&lt;/p>
&lt;p>索菲亚是专注全屋定制的家居品牌。就像刚刚展示的，它也可以通过填写极其简单的信息，创建出一个基础的商家智能体。但对于家居行业，消费者的线下体验更重要，所以索菲亚希望能在线上打造出一个金牌销售，还原线下的接待体验。&lt;/p>
&lt;p>因此在进一步的设置中，它在角色模块，选择了数字人作为展示方式，然后给数字人选取了合适的背景和声音，并且结合平台的智能解析能力，自动总结了一套销售话术。最终打造出一位温柔亲切、话术专业的金牌销售，她能24小时满足用户的各种需求，提供高水准的服务体验。&lt;/p>
&lt;p>当百度搜索用户有装修诉求时，索菲亚智能体会利用文心大模型的能力，优先给出问题的答案。除此之外，她还会主动与客户确认具体需求，如装修类型、预算等，并推荐附近的线下门店。&lt;/p>
&lt;p>索菲亚商家智能体上线以来，有效线索成本下降了30%。也就是说，它获得一个有效客户，如果过去的成本是100块，现在只需要70块了。&lt;/p>
&lt;p>目前，已有超过1万个百度的客户拥有了商家智能体，涵盖了教育培训、房产家居、机械设备、商务服务等超过30个行业。&lt;/p>
&lt;p>上面，通过三个Demo，我展示了开发者和商家，如何利用AgentBuilder，制作不同行业智能体的过程。&lt;/p>
&lt;p>现在，制作一个智能体，真的就是分分钟的事。但问题来了！如果没流量、没分发、找不到、没人用，那么开发者和商家就没有收益，没有收益就没有动力。怎么解决这个痛点呢？&lt;/p></description></item><item><title>「转」裁员增笑</title><link>https://example.com/post/c0-life/readings/caiyuanzengxiao/</link><pubDate>Tue, 23 Jan 2024 12:00:00 +0000</pubDate><guid>https://example.com/post/c0-life/readings/caiyuanzengxiao/</guid><description>&lt;p>我被公司裁了。
我一手搭建起核心项目的底层框架，总算熬出头时，公司把我裁了。
CEO 当着全公司的面落井下石，羞辱我是滥竽充数。
他不知道，核心代码的故障只有我能修。
公司求我的日子比想象中来得更快。&lt;/p>
&lt;!-- more -->
&lt;p>1&lt;/p>
&lt;p>「很遗憾地通知您，公司有人员调整，将结束与您的聘用关系。」
「您的门禁卡已经失效，请您立刻搬走全部个人物品。」
我一头雾水。
本以为被人事叫走只是开个小会，没想到是裁员通知。
三年前，公司只是不足20人的小企业。
我抓住虚拟交互的风口，一手搭建起核心项目的底层框架。
我无数个夜晚加班加点，做出第一款产品一Ribo，以眼镜或车窗为载体，实现所有外界环境与人的虚拟交互。
再也不用佩戴笨重的VR 设备，用户仿佛生活在科幻大片中。
Ribo 一经上市，就引爆市场。
无数代理商和开发商找我们合作。
Ribo 生态仿佛摩天大楼一般建设起来。
我们公司的规模也迅速从 20人扩张到5000人。
Ribo 如火如荼地发展，我们也抓紧更新迭代。我流连在技术网站中，把Ribo的系统升级成最前沿的高可用架构。
这个架构搭建时非常困难，因为掌握核心技术的人不多。
我全身心投入到工作中，无暇处理其他事。
陈炳就是那个时期被招进来的。
最开始他跟着我做些琐事。他这个人很圆滑，最擅长向上社交。
他的朋友圈都是跟大老板打高尔夫、跟产品经理喝下午茶。
Ribo 新产品要开发布会，通知我准备稿子。
我嫌麻烦。陈炳自告奋勇，主动写好稿子上直播。
他的口才好，又积极，让我专心处理技术，以后的发布会都让他去。
我乐得清静。我一心只想让Ribo 更好。
他宣称自己是 Ribo 的总工程师。久而久之，外界也默认了。
他靠着人脉一路高升，做到首席 CEO.
与此同时，我完成了Ribo的升级，工作总算轻松了一点。&lt;/p>
&lt;p>2&lt;/p>
&lt;p>有人问过我，陈炳的技术怎么样?
我说:「一般，他更擅长社交。」
这话传到了陈炳耳朵里。
说者无意，听者有心。
陈炳在发布会上以「总工程师」自居，不能容忍有人拆他的老底。
经济下行时期，很多科技公司都受到波及。
Ribo 的股票也有下降，公司传出裁员风波。
我做梦也想不到，第一个被裁掉的竟然是我。
我回到工位收拾东西，内心一片茫然。
门口传来「陈总好!」的声音，我抬头看，陈炳大腹便便地走过来。
可能是应酬太多，这三年，他迅速发福，成了一个油腻的中年胖子。
他笑眯眯地打招呼:「早，各位早啊!」
他晃到我面前，满脸惊讶:「咦，黎工怎么在收拾东西?」
有几人向我看过来。
陈炳仿佛突然想到什么，大声说:「黎工不会是被裁了吧!」
他一咋呼，整个办公室的同事都停下工作来看我。
我回答他:「对。我还得收拾东西，先失陪了。」
陈炳的话根本就不是对我说的。
他转过身，痛心疾首一般围着我转:
「可惜啊，黎工也是公司的老员工了!」
「公司有人员调整，竟然把黎工给裁了。我就不明白，这么多技术人员不裁，怎么偏偏要裁你呢?」
「难道公司考察了所有人的KPI吗?」
我不喜欢搞形式主义，平时的汇报总结能省则省，专心干活。
陈炳说的 KPI 就是那些形式主义的报告之一。
「我也算是跟黎工共事过，实在痛心。」
「但是公司不养闲人!」
「要是黎工走了，公司业务照常运转，大家就能发现是谁只拿工资不干活了!」
他越说声音越大，幸灾乐祸地斜眼瞟我。&lt;/p></description></item><item><title>「转」九张图一览 Linux 性能工具 全景图</title><link>https://example.com/post/c5-linux/linux/linux_tools/</link><pubDate>Sun, 11 Dec 2022 12:00:00 +0000</pubDate><guid>https://example.com/post/c5-linux/linux/linux_tools/</guid><description>&lt;h2 id="前言">前言&lt;/h2>
&lt;p>当今时代，绝大多数企业的应用都是运行在 Linux 操作系统上，所以对应用进行性能诊断和性能优化时，离不开 Linux 的各种性能观测工具和性能优化工具。&lt;/p>
&lt;p>笔者使用过的常见的 Linux 性能观测和性能优化工具有：&lt;/p>
&lt;ul>
&lt;li>top/uptime&lt;/li>
&lt;li>ps/pstree&lt;/li>
&lt;li>df/du/free/lsblk&lt;/li>
&lt;li>ip/ifconfig/ping/telnet&lt;/li>
&lt;li>route/dig/nslookup&lt;/li>
&lt;li>lsof/netstat/ss&lt;/li>
&lt;li>tcpdump/tshark/wireshark&lt;/li>
&lt;li>netstat/vmstat/iostat/pidstat/dstat/mpstat&lt;/li>
&lt;li>sar/sysctl/ethtool&lt;/li>
&lt;/ul>
&lt;p>最近在拜读国际著名的 LINUX 性能专家 Brendan Gregg 的个人博客和技术书籍，摘抄了如下九张图，一览 Linux 性能工具全景图，大家共勉！&lt;/p>
&lt;!-- more -->
&lt;h2 id="2-linux-性能工具全景图">&lt;strong>2. Linux 性能工具全景图&lt;/strong>&lt;/h2>
&lt;ul>
&lt;li>linux performance observability tools&lt;/li>
&lt;/ul>
&lt;p>




 


&lt;div style="text-align: center;">
&lt;img src="v2-2eadd97c53a3f20f255394c3d90ea914_r.jpg" 
 alt="" 
 
/>
&lt;/div>&lt;/p>
&lt;ul>
&lt;li>linux static performance tools&lt;/li>
&lt;/ul>
&lt;p>




 


&lt;div style="text-align: center;">
&lt;img src="v2-20032bac53c856c5733259eece5c2f76_r.jpg" 
 alt="" 
 
/>
&lt;/div>&lt;/p>
&lt;ul>
&lt;li>linux performance benchmark tools&lt;/li>
&lt;/ul>
&lt;p>




 


&lt;div style="text-align: center;">
&lt;img src="v2-de23423f2eb9deb5410b7128c933f9a9_r.jpg" 
 alt="" 
 
/>
&lt;/div>&lt;/p>
&lt;ul>
&lt;li>linux performance tuning tools&lt;/li>
&lt;/ul>
&lt;p>




 


&lt;div style="text-align: center;">
&lt;img src="v2-cdf37de145763b762ba5af1a620f9686_r.jpg" 
 alt="" 
 
/>
&lt;/div>&lt;/p>
&lt;ul>
&lt;li>linux performance observability: sar&lt;/li>
&lt;/ul>
&lt;p>




 


&lt;div style="text-align: center;">
&lt;img src="v2-eee71a6bf3865367741137da03031411_r.jpg" 
 alt="" 
 
/>
&lt;/div>&lt;/p>
&lt;ul>
&lt;li>linux performance observability: perf-tools&lt;/li>
&lt;/ul>
&lt;p>




 


&lt;div style="text-align: center;">
&lt;img src="v2-1c0134fefbb04597db98ae455a40fad5_r.jpg" 
 alt="" 
 
/>
&lt;/div>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.zhihu.com/search?q=linux%20bcc&amp;amp;search_source=Entity&amp;amp;hybrid_search_source=Entity&amp;amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2795830055%7D">linux bcc&lt;/a>/BPF Tracing tools&lt;/li>
&lt;/ul>
&lt;p>




 


&lt;div style="text-align: center;">
&lt;img src="v2-ffe70303f4d64828ca931d987b12a6d8_r.jpg" 
 alt="" 
 
/>
&lt;/div>&lt;/p></description></item><item><title>「转」tcpdump是在哪儿抓到的包？</title><link>https://example.com/post/c5-linux/linux/how-tcpdump/</link><pubDate>Fri, 01 Jul 2022 16:00:04 +0000</pubDate><guid>https://example.com/post/c5-linux/linux/how-tcpdump/</guid><description>&lt;blockquote>
&lt;p>原文地址 &lt;a href="https://cloud.tencent.com/developer/article/1879646">cloud.tencent.com&lt;/a>&lt;/p>&lt;/blockquote>
&lt;blockquote>
&lt;p>最近使用 tcpdump 的时候突然想到这个问题。因为我之前只存在一些一知半解的认识：比如直接镜像了网卡的包、在数据包进入内核前就获取了。但这些认识真的正确么？针对&amp;hellip;&lt;/p>&lt;/blockquote>
&lt;p>最近使用 tcpdump 的时候突然想到这个问题。因为我之前只存在一些一知半解的认识：比如直接镜像了网卡的包、在数据包进入内核前就获取了。但这些认识真的正确么？针对这个问题，我进行了一番学习探究。&lt;/p>
&lt;p>先说结论：通过 PF_PACKET 这个特殊的套接字协议，直接接收来自链路层的帧。数据包&lt;strong>并非没有&lt;/strong>进入内核，而是在进入内核后直接跳过了内核中三层 / 四层的协议栈，直达套接字接口，被应用层的 tcpdump 所使用。实际上，在网卡驱动程序通知内核接受到数据帧的时候，数据包就已经进入了内核处理流程。具体的区别，可以见下图。&lt;/p>
&lt;p>




 


&lt;div style="text-align: center;">
&lt;img src="1620.png" 
 alt="" 
 
/>
&lt;/div>&lt;/p>
&lt;p>内核网络协议栈示意图&lt;/p>
&lt;!-- more -->
&lt;p>先来看看，普通的套接字的收包路径在内核中是怎么样。&lt;/p>
&lt;p>以最常见的以太网网卡，当网卡接口接收到了一个帧，那么接受者知道它一定包含了一个 Ethernet 报头。封包在协议栈向上传递过程中，一定会在报头中包含一个字段，指出下一阶段的处理应该使用哪一个协议。 以太网卡拥有特定的 MAC 地址，在监听数据帧的时候，当看到帧的目的 MAC 地址与自己的地址或者链路层广播地址（FF:FF:FF:FF:FF:FF）相匹配，就会通过 DMA 把该帧读取到内存中的 ring buffer。&lt;/p>
&lt;p>当一个数据帧被写入到内存后，将产生一个硬件中断请求，以通知 CPU 收到了数据包。操作系统为了减少硬中断产生的次数，会采用一个软中断 (softirq) 唤醒 NAPI 子系统。这样会产生一个单独的线程，调用网卡驱动注册的 poll 方法收包，同时禁止网卡产生新的硬中断，这样的效果便是一次中断可以接收多个包。一旦软终端代码判断有 softirq 处于 pending 状态，便会调用软终端处理函数 net_rx_action。&lt;/p>
&lt;p>中断处理函数会在处理循环中调用 NAPI poll 来接收数据包。poll 方法会分配一个 sk_buff 数据结构（include/linux/skbuff.h），表示该数据包的内核视图。然后将数据从缓冲区提取到新建的 sk_buff 中，并对其中的 protocol 字段做初始化，该字段用以识别特定的协议。之后这个字段会被 netif_receive_skb 内核函数查询，用来确定该执行哪个函数来处理三层的封包。字段涉及协议的值都列在了 include/uapi/linux/if_ether.h 中，名字形如 ETH_P_XXX，比如 ip 协议为 ETH_P_IP。而有一种特殊情况，单一封包可以传递给多个处理函数，这就是 tcpdump 等网络嗅探应用会用到的 ETH_P_ALL。&lt;/p></description></item><item><title>「转」GRE隧道测试</title><link>https://example.com/post/c6-network/gre-test/</link><pubDate>Thu, 05 May 2022 22:52:28 +0000</pubDate><guid>https://example.com/post/c6-network/gre-test/</guid><description>&lt;blockquote>
&lt;p>本文由 &lt;a href="http://ksria.com/simpread/">简悦 SimpRead&lt;/a> 转码， 原文地址 &lt;a href="https://juejin.cn/post/6988645230987706398">juejin.cn&lt;/a>&lt;/p>&lt;/blockquote>
&lt;p>




 


&lt;div style="text-align: center;">
&lt;img src="e31bac5bcb1347a59142486adaf94e30.jpg" 
 alt="" 
 
/>
&lt;/div>&lt;/p>
&lt;h2 id="0-前言">0. 前言&lt;/h2>
&lt;p>在学习 ipsec 过程中，一般都会涉及到 ipsec 的局限性：ipsec 协议是一种点对点协议，不支持组播，也不能保护组播、广播报文。因此 ipsec 协议无法用于音视频会议等场合，此时通常的解决办法是采用 &lt;strong>GRE Over IPSec&lt;/strong> .&lt;/p>
&lt;p>给出的解释是：GRE 协议可以封装组播、广播报文，但是无法对业务内容进行加密；而 ipsec 可以对报文进行加密，但是无法封装组播和广播报文。因此将两种协议结合，因而 GRE over IPSec 协议应运而生。 但是我找了很多资料 (其实没有多少)，都没有找到为什么 GRE 协议支持封装组播和广播报文，而 ipsec 不行；他们作为点对点协议，为什么 GRE 可以而 IPsec 不行呢？因为没有找到答案，所以不能证实自己的想法正确与否，于是通过搭建 GRE 隧道环境，学习 Linux 内核中 GRE 隧道的操作配置原则，希望能从中得到些许启发。&lt;/p>
&lt;p>搭建 GRE 隧道环境实际上是很简单的，因为 Linux 内核已经支持了 GRE 隧道，因此直接在虚拟机 (ubuntu 和 CentOS) 里进行简单的配置即可完成操作。&lt;/p>
&lt;!-- more -->
&lt;p>




 


&lt;div style="text-align: center;">
&lt;img src="db260d2dc98445f9988f1c768ca3e744.jpg" 
 alt="" 
 
/>
&lt;/div>&lt;/p>
&lt;h2 id="1-linux-内核支持的隧道类型">1. Linux 内核支持的隧道类型&lt;/h2>
&lt;p>目前 Linux 内核已经支持多种隧道类型，包括：IPIP 隧道，GRE 隧道，&amp;hellip; 。其余这几个我也没见过。当然除了这几种，还有 ipsec 协议，l2tp 协议，可以的是我目前都还没有用过，实在是暴殄天物，罪过罪过&lt;/p></description></item><item><title>「转」Ubuntu完全教程</title><link>https://example.com/post/c5-linux/linux/ubuntu-tour/</link><pubDate>Fri, 01 Apr 2022 18:00:04 +0000</pubDate><guid>https://example.com/post/c5-linux/linux/ubuntu-tour/</guid><description>&lt;blockquote>
&lt;p>ref:&lt;a href="http://www.cnblogs.com/dutlei/archive/2012/11/20/2778327.html">Ubuntu完全教程，让你成为Ubuntu高手！&lt;/a>
todo整理&lt;/p>&lt;/blockquote>
&lt;h2 id="ubuntu的发音">Ubuntu的发音&lt;/h2>
&lt;p>Ubuntu，源于非洲祖鲁人和科萨人的语言，发作 oo-boon-too 的音。了解发音是有意义的，您不是第一个为此困惑的人，当然，也不会是最后一个：）&lt;/p>
&lt;p>大多数的美国人读 ubuntu 时，将 u 作为元音发音，类似单词 who 或者 boo ，重音在第二个音节即 u&amp;rsquo;buntu ，oo-boon-too 。&lt;/p>
&lt;p>如果您喜欢撒哈拉，喜欢它令人窒息的温柔、梦幻般的寂寥还有张扬恣肆的旷远，您大可在第一个 u，后面带些嗡嗡声： oom-boon-too。&lt;/p>
&lt;p>Ubuntu的中文发音大约为： 乌班图&lt;/p>
&lt;h3 id="ubuntu的涵义">Ubuntu的涵义&lt;/h3>
&lt;p>Ubuntu这个单词源自非洲，意谓“班图精神”────谁都不是一座孤岛，自成一体。每个人都包孕于人类，因他人存在而存在，因他人幸福而幸福。&lt;/p>
&lt;h3 id="ubuntu当前版本">Ubuntu当前版本&lt;/h3>
&lt;p>Ubuntu Linux v6.06 LTS (Dapper Drake)&lt;/p>
&lt;p>LTS：Long Term Support&lt;/p>
&lt;p>Dapper Drake：当前版本的开发代号&lt;/p>
&lt;h3 id="ubuntu的特点">Ubuntu的特点&lt;/h3>
&lt;p>Ubuntu 完全基于 Linux 操作系统， 可以免费得到社区及专业机构的支持。庞大的社区是它成长的沃土，请向这片动人的热忱敞开心扉。&lt;/p>
&lt;p>Ubuntu 社区恪守 Ubuntu 理念：自由！软件应是自由的，应尊重人类的自由意志，它与人类之间不应有任何隔膜。本地语种，功能限制，自主改进的权利……都不应成为使用的障碍或负担。&lt;/p>
&lt;p>自由，让 Ubuntu 与传统的私有软件从根本上不同: 免费不能用来遮羞，您有权修正它，直到满意为止。&lt;/p>
&lt;p>Ubuntu 适合桌面和服务器。当前 Ubuntu 发布版支持 PC (Intel x86), 64-bit PC (AMD64) 和 PowerPC (Apple iBook 和 Powerbook, G4 和 G5) 架构。&lt;/p></description></item><item><title>「转」一文看懂Linux内核！Linux内核架构和工作原理详解</title><link>https://example.com/post/c5-linux/linux/linux-in-one/</link><pubDate>Thu, 23 Dec 2021 22:45:31 +0000</pubDate><guid>https://example.com/post/c5-linux/linux/linux-in-one/</guid><description>&lt;p>全文导读&lt;/p>
&lt;ul>
&lt;li>&lt;a href="">Linux 内核预备工作&lt;/a>&lt;/li>
&lt;li>&lt;a href="">Linux 内核体系结构简析&lt;/a>&lt;/li>
&lt;li>&lt;a href="">Linux 体系结构和内核结构区别&lt;/a>&lt;/li>
&lt;li>&lt;a href="">Linux 驱动的 platform 机制&lt;/a>&lt;/li>
&lt;li>&lt;a href="">Linux 内核体系结构&lt;/a>&lt;/li>
&lt;li>&lt;a href="">内核模块&lt;/a>&lt;/li>
&lt;li>&lt;a href="">Linux 内核学习经验总结&lt;/a>&lt;/li>
&lt;li>&lt;a href="">结尾&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- more -->
&lt;h2 id="linux-内核预备工作">Linux 内核预备工作&lt;/h2>
&lt;p>理解 Linux 内核最好预备的知识点：&lt;/p>
&lt;p>懂 C 语言&lt;br>
懂一点操作系统的知识&lt;br>
熟悉少量相关算法&lt;br>
懂计算机体系结构&lt;/p>
&lt;p>Linux 内核的特点：&lt;/p>
&lt;p>结合了 unix 操作系统的一些基础概念&lt;/p>
&lt;img src="linux_in_one/174749211_2_20191103041018392.jpeg" alt="174749211_2_20191103041018392" style="zoom:50%;" />
&lt;img src="linux_in_one/174749211_3_20191103041018455.jpeg" alt="174749211_3_20191103041018455" style="zoom:60%;" />
&lt;p>Linux 内核的任务：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>从技术层面讲，内核是硬件与软件之间的一个中间层。作用是将应用层序的请求传递给硬件，并充当底层驱动程序，对系统中的各种设备和组件进行寻址。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>从应用程序的层面讲，应用程序与硬件没有联系，只与内核有联系，内核是应用程序知道的层次中的最底层。在实际工作中内核抽象了相关细节。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>内核是一个资源管理程序。负责将可用的共享资源 (CPU 时间、磁盘空间、网络连接等) 分配得到各个系统进程。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>内核就像一个库，提供了一组面向系统的命令。系统调用对于应用程序来说，就像调用普通函数一样。&lt;br>
内核实现策略：&lt;/p>
&lt;/li>
&lt;li>
&lt;p>微内核。最基本的功能由中央内核（微内核）实现。所有其他的功能都委托给一些独立进程，这些进程通过明确定义的通信接口与中心内核通信。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>宏内核。内核的所有代码，包括子系统（如内存管理、文件管理、设备驱动程序）都打包到一个文件中。内核中的每一个函数都可以访问到内核中所有其他部分。目前支持模块的动态装卸 (裁剪)。Linux 内核就是基于这个策略实现的。&lt;br>
哪些地方用到了内核机制？&lt;/p>
&lt;/li>
&lt;li>
&lt;p>进程（在 cpu 的虚拟内存中分配地址空间，各个进程的地址空间完全独立; 同时执行的进程数最多不超过 cpu 数目）之间进行通   信，需要使用特定的内核机制。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>进程间切换 (同时执行的进程数最多不超过 cpu 数目)，也需要用到内核机制。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>进程切换也需要像 FreeRTOS 任务切换一样保存状态，并将进程置于闲置状态 / 恢复状态。&lt;/p>
&lt;ol start="3">
&lt;li>
&lt;p>进程的调度。确认哪个进程运行多长的时间。&lt;br>
Linux 进程&lt;/p></description></item><item><title>「转」「译」Face Detection – OpenCV, Dlib and Deep Learning ( C++ / Python )</title><link>https://example.com/post/c2-robotics/cv/facedetectioncomparison/</link><pubDate>Mon, 12 Nov 2018 18:00:00 +0000</pubDate><guid>https://example.com/post/c2-robotics/cv/facedetectioncomparison/</guid><description>&lt;p>&lt;strong>前言&lt;/strong>
本文为翻译文章。原文地址 &lt;a href="https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/">https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/&lt;/a>&lt;/p>
&lt;p>在这篇文章中，作者讨论使用了OpenCV或Dlib的多种人脸检测的代码，并给出性能分析。作者使用的 Face Detector 包括以下四个，后面分别给出 c++ 和 python 实现。&lt;/p>
&lt;ol>
&lt;li>OpenCV 的 Haar Cascade Face Detector&lt;/li>
&lt;li>OpenCV 的 Deep Learning based Face Detector&lt;/li>
&lt;li>Dlib 的 HoG Face Detector&lt;/li>
&lt;li>Dlib 的 Deep Learning based Face Detector&lt;/li>
&lt;/ol>
&lt;p>作者限于篇幅没有对对理论进行深入解读，只讨论框架的使用，同时分享一些应用上的选择权衡的经验。&lt;/p>
&lt;p>结论：在多数场景中，我们提前不知道图片大小，因此 选用 OpenCV – DNN 相当快也很精确，甚至对于小人脸也不错，各种人脸角度也可以。选用这个在大多情况下是最优的。&lt;/p>
&lt;p>&lt;a href="https://github.com/spmallick/learnopencv/tree/master/FaceDetectionComparison">code FaceDetectionComparison&lt;/a> 说明：为了使文章显得简洁一些，在文中只提供关键的代码片段。在github项目中详细代码，包括每个方法独立的代码和整合在一起的cpp和py文件（run-all.py 和 run-all.cpp），同时里面也有运行代码所使用的人脸检测模型。&lt;/p>
&lt;!-- more -->
&lt;center>&lt;iframe width="100%" height="360" frameborder=0 src="http://v.qq.com/iframe/player.html?vid=k07615vrzj8&amp;tiny=0&amp;auto=0" allowfullscreen="">&lt;/iframe>&lt;/center>
> 实验的图片尺寸是 image size 300×300
&lt;h2 id="1-opencv-haar">1. OpenCV-Haar&lt;/h2>
&lt;p>在2001年，Viola 和 Jones提出Haar Cascade 特征为基础的 Face Detector，在以后的多年内都是最优的人脸检测算法。以他们的算法为基础人们做了很多改进。OpenCV提供了很多Haar特征的模型算法，更多的Haar特征模型 &lt;strong>&lt;a href="https://github.com/opencv/opencv/tree/master/data/haarcascades">here&lt;/a>&lt;/strong>&lt;/p>
&lt;h3 id="代码">代码&lt;/h3>
&lt;h4 id="python">Python&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>faceCascade &lt;span style="color:#f92672">=&lt;/span> cv2&lt;span style="color:#f92672">.&lt;/span>CascadeClassifier(&lt;span style="color:#e6db74">&amp;#39;./haarcascade_frontalface_default.xml&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>faces &lt;span style="color:#f92672">=&lt;/span> faceCascade&lt;span style="color:#f92672">.&lt;/span>detectMultiScale(frameGray)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> face &lt;span style="color:#f92672">in&lt;/span> faces:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x1, y1, w, h &lt;span style="color:#f92672">=&lt;/span> face
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x2 &lt;span style="color:#f92672">=&lt;/span> x1 &lt;span style="color:#f92672">+&lt;/span> w
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y2 &lt;span style="color:#f92672">=&lt;/span> y1 &lt;span style="color:#f92672">+&lt;/span> h
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="c">C++&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cpp" data-lang="cpp">&lt;span style="display:flex;">&lt;span>faceCascadePath &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;./haarcascade_frontalface_default.xml&amp;#34;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>faceCascade.load( faceCascadePath )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>std&lt;span style="color:#f92672">::&lt;/span>vector&lt;span style="color:#f92672">&amp;lt;&lt;/span>Rect&lt;span style="color:#f92672">&amp;gt;&lt;/span> faces;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>faceCascade.detectMultiScale(frameGray, faces);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> ( size_t i &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>; i &lt;span style="color:#f92672">&amp;lt;&lt;/span> faces.size(); i&lt;span style="color:#f92672">++&lt;/span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> x1 &lt;span style="color:#f92672">=&lt;/span> faces[i].x;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> y1 &lt;span style="color:#f92672">=&lt;/span> faces[i].y;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> x2 &lt;span style="color:#f92672">=&lt;/span> faces[i].x &lt;span style="color:#f92672">+&lt;/span> faces[i].width;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> y2 &lt;span style="color:#f92672">=&lt;/span> faces[i].y &lt;span style="color:#f92672">+&lt;/span> faces[i].height;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>对图片灰度变化（grayscale）后，再应用 haar cascade 特征，输出是脸的list。list中每个item有四个element 分别为 top-left corner的(x, y) 、检测出来脸的大小(width, height) 。&lt;/p></description></item></channel></rss>